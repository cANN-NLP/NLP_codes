{"cells":[{"cell_type":"markdown","metadata":{"id":"R-OfUts2p8Ma"},"source":["**Prediction of the next word by the preceeding 16 words**    \n","\n","This preprocessing is based on Dict 2.5 (Keiko updated).\n"," \n"]},{"cell_type":"markdown","source":["updated 6/10 14:05"],"metadata":{"id":"Y9RIBZDgIO-q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wMp0fbdVGYiH"},"outputs":[],"source":["ver = 21045; "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18330,"status":"ok","timestamp":1654885845979,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"Sr0DfhFhnhqH","outputId":"56305e98-425f-4808-8932-8c932490e73e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Colab/NLP\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd \"gdrive/My Drive/Colab/NLP\" "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoMaz7q5mPnI"},"outputs":[],"source":["import numpy as np\n","np.set_printoptions(threshold=np.inf)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4585,"status":"ok","timestamp":1654885850561,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"b3UbWGUYnLa6","outputId":"72e4eb4f-7e9f-4166-f6e2-13e96a5d251a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"]}],"source":["!pip install gensim\n","from gensim.models import KeyedVectors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xuu-UKoFjDRU"},"outputs":[],"source":["# !wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7t9B8lVjDab"},"outputs":[],"source":["# ##### Loading word2vec #####\n","# EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' \n","# word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NmHt2njjnLjd"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654885852821,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"vVXEnE2SLO6O","outputId":"a7ae892b-6358-430b-8e59-ea4841080c8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.2\n"]}],"source":["print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzZRus3Tq7Ky"},"outputs":[],"source":["#### load text data file #####\n","import nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1654885853950,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"_nTGKPljLFCL","outputId":"2cb198f8-4ea7-4548-deac-2473cb4e86f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/gutenberg.zip.\n"]}],"source":["nltk.download('gutenberg')\n","text_=[]\n","text_.append( nltk.corpus.gutenberg.raw('carroll-alice.txt') )\n","text_.append( nltk.corpus.gutenberg.raw('austen-emma.txt') )\n","text_.append( nltk.corpus.gutenberg.raw('austen-persuasion.txt') )\n","text_.append( nltk.corpus.gutenberg.raw('austen-sense.txt') )\n","text_.append( nltk.corpus.gutenberg.raw('melville-moby_dick.txt') )\n","text_.append( nltk.corpus.gutenberg.raw('burgess-busterbrown.txt') ) # children's book, \"The Adventures of Buster Bear\" \"Fun with Farmer Brown's Boy\"\n","text_.append( nltk.corpus.gutenberg.raw('edgeworth-parents.txt') ) # children's book, \"The Parent's Assistant\", 1796 \n","text_br = nltk.corpus.gutenberg.raw('bryant-stories.txt')  # \"Stories to Tell to Children\", by Sara Cone Bryant 1918"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhyLLdrODYh8"},"outputs":[],"source":["# nltk.corpus.gutenberg.fileids()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZeb48thbhbx"},"outputs":[],"source":["txt_1 = \"\"\"My name is Anne. I am a Japanese high school student. I came to live in America with my family two weeks ago. One day Mother asked me about my school life. I answered that I enjoyed it very much. But that was not true. I didn't want Mother to worry about me. I always said to myself, \"I live in two worlds, one at home and the other at school. They are very different. At home I speak Japanese and live a happy Japanese life with my family. I feel that school is far away when I am at home. In class at school teachers sometimes speak English so fast that I don't understand them. I want to talk with a friend about that, but I don't have any friends. Every day I wait for a student who will talk to me.\" The next day in art class the teacher stopped at my desk and said, \"Akiko, your picture is very wonderful! \" Then many students came to see my picture. After the art class one girl student came to me. At last a student talked to me! She said, \"Hi, Anne. I'm Suzzan. I would like to talk with you after school.\" I was very happy. I said, \"Yes, of course.\" After school we went to Mary's house and began to talk. Mary was also interested in drawing pictures. We talked about a lot of things. When I talked about my idea of the two worlds, Mary said, \"I didn't know that. But you can ask teachers to speak more slowly. If you want to make your school life happy, you should try to say something to us. We will help you any time.\" I had a very good time with Mary. I ran home to tell Mother about my new friend, but she was not there. Soon Mother came home. \"Mother, where have you been? \"I asked. \"I have been to English school. I began to learn English, \" answered Mother. \"You don't have to learn English so hard because you stay home every day, \" I said. \"I want to make friends to learn about America and tell them a lot about Japan, \" said Mother. \"Mary and Mother have the same idea, \" I thought. \" Today I learned an important thing from Mary and Mother. It is not good to stay in our small world when we are in a foreign culture. I will try hard to make my school life happy.\"\n","Relearning the art of seeing the world around us is quite simple, although it takes practice and requires breaking some bad abits. And \"relearn\" is the correct word. Most of us observed much more as children than we do as adults. A child's day is filled with newness and wonder. The desire to explore, to have an adventure, gave us all a natural ability to be aware of the world around us. \n","But as adults we are slow to be stimulated by new ideas and new situations. We fail to see the wonder of the things around us. The first step in awakening our senses is to rediscover the ability to observe that we had as children. To do so we need to stop anticipating what we are going to see and feel before it happens. Such anticipation blocks our ability to feel. For example, one chilly night I was on a mountain hike with some students. I told them that we were going to have to cross a mountain stream. They began to grumble about how cold it would be. We reached the stream and they reluctantly plunged ahead. They were almost up to their knees in the water when they realized that I had led them into a hot spring. Later they all said that they had felt cold water at first. We also need to notice signs which can help us see more. Once I was on a hike, following about six meters behind my Indian friend named John. As we passed under a huge pine tree. he turned around and said, \"Don't disturb it.\" Surprised, I looked everywhere. Was there a deer, a fox, or something else that I had missed seeing? Finally I looked into the branches of the tree and saw a beautiful owl not three meters from us. I was amazed that Stalking Wolf had known it was there without looking up. When I asked him how he had known the owl was there, he replied, \"Go ask the mice.\" By looking down he had seen the tracks of the mice that had run away from their dreaded enemy, the owl. The next time you take a walk, no matter where it is, open up your eyes. Be aware of all the sights, sounds and sensations. You will be surprised at the many beautiful and interesting things you have been missing. \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbRXkjv8q46t"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOpdD2uiJo3A"},"outputs":[],"source":["text_br = text_br.replace(\"Here's\", \"Here is\");   text_br = text_br.replace(\"here's\", \"here is\");   text_br = text_br.replace(\"I'm\", \"I am\");   text_br = text_br.replace(\"I'd\", \"I would\");   text_br = text_br.replace(\"I've\", \"I have\");   text_br = text_br.replace(\"I'll\", \"I will\");    text_br = text_br.replace(\"that's\", \"that is\");   text_br = text_br.replace(\"That's\", \"That is\");     text_br = text_br.replace(\"What's\", \"What is\");   text_br = text_br.replace(\"You'll\", \"You will\");   text_br = text_br.replace(\"you'll\", \"you will\");  text_br = text_br.replace(\"It's\", \"It is\");   text_br = text_br.replace(\"it's\", \"it is\");  text_br = text_br.replace(\"It'll\", \"It will\");   text_br = text_br.replace(\"it'll\", \"it will\");  text_br = text_br.replace(\"You're\", \"You are\");  text_br = text_br.replace(\"you're\", \"you are\");   text_br = text_br.replace(\"You've\", \"You have\");  text_br = text_br.replace(\"you've\", \"you have\");   text_br = text_br.replace(\"You've\", \"You have\");  \n","text_br = text_br.replace(\"We'll\", \"We will\");   text_br = text_br.replace(\"we'll\", \"we will\");  text_br = text_br.replace(\"She'll\", \"She will\");   text_br = text_br.replace(\"she'll\", \"she will\");  text_br = text_br.replace(\"He'll\", \"He will\");  text_br = text_br.replace(\"he'll\", \"he will\");  text_br = text_br.replace(\"They'll\", \"They will\");  text_br = text_br.replace(\"they'll\", \"they will\");   text_br = text_br.replace(\"They're\", \"They are\");  text_br = text_br.replace(\"they're\", \"they are\");  text_br = text_br.replace(\"They've\", \"They have\");  text_br = text_br.replace(\"they've\", \"they have\"); \n","text_br = text_br.replace(\"don't\", \"do not\");   text_br = text_br.replace(\"doesn't\", \"does not\");   text_br = text_br.replace(\"didn't\", \"did not\");   text_br = text_br.replace(\"isn't\", \"is not\");   text_br = text_br.replace(\"wasn't\", \"was not\");   text_br = text_br.replace(\"aren't\", \"are not\");  text_br = text_br.replace(\"hasn't\", \"has not\");    text_br = text_br.replace(\"haven't\", \"have not\");  text_br = text_br.replace(\"hadn't\", \"had not\");   text_br = text_br.replace(\"won't\", \"will not\");  \n","text_br = text_br.replace(\"can't\", \"can not\");  text_br = text_br.replace(\"cannot\", \"can not\");  text_br = text_br.replace(\"shouldn't\", \"should not\");  text_br = text_br.replace(\"wouldn't\", \"would not\");  text_br = text_br.replace(\" Miss \", \" dr \");    text_br = text_br.replace(\" Pip \", \" john \");  \n","text_br = text_br.replace(\"'\", \"\");     # for 'bryant-stories.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMgAXhCdY9TF"},"outputs":[],"source":["text = ''\n","for i in range(len(text_)):     text = text + text_[i]\n","text = text + text_br + txt_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-M4KX6b6QsG"},"outputs":[],"source":["text = text.replace('\\r\\n', ' ');  text = text.replace('\\n', ' ');   # \\n is inserted not at the end of sentence.\n","text = text.replace(\"Here's\", \"Here is\");   text = text.replace(\"here's\", \"here is\");   text = text.replace(\"I'm\", \"I am\");   text = text.replace(\"I'd\", \"I would\");   text = text.replace(\"I've\", \"I have\");   text = text.replace(\"I'll\", \"I will\");    text = text.replace(\"that's\", \"that is\");   text = text.replace(\"That's\", \"That is\");     text = text.replace(\"What's\", \"What is\"); \n","text = text.replace(\"We'll\", \"We will\");   text = text.replace(\"we'll\", \"we will\");  text = text.replace(\"You'll\", \"You will\");   text = text.replace(\"you'll\", \"you will\");  text = text.replace(\"It's\", \"It is\");   text = text.replace(\"it's\", \"it is\");  text = text.replace(\"It'll\", \"It will\");   text = text.replace(\"it'll\", \"it will\");  text = text.replace(\"You're\", \"You are\");  text = text.replace(\"you're\", \"you are\");   text = text.replace(\"You've\", \"You have\");  text = text.replace(\"you've\", \"you have\");   text = text.replace(\"You've\", \"You have\");  \n","text = text.replace(\"She'll\", \"She will\");   text = text.replace(\"she'll\", \"she will\");  text = text.replace(\"He'll\", \"He will\");  text = text.replace(\"he'll\", \"he will\");  text = text.replace(\"They'll\", \"They will\");  text = text.replace(\"they'll\", \"they will\");   text = text.replace(\"They're\", \"They are\");  text = text.replace(\"they're\", \"they are\");  text = text.replace(\"They've\", \"They have\");  text = text.replace(\"they've\", \"they have\"); \n","text = text.replace(\"don't\", \"do not\");   text = text.replace(\"doesn't\", \"does not\");   text = text.replace(\"didn't\", \"did not\");   text = text.replace(\"isn't\", \"is not\");   text = text.replace(\"wasn't\", \"was not\");   text = text.replace(\"aren't\", \"are not\");  text = text.replace(\"hasn't\", \"has not\");    text = text.replace(\"haven't\", \"have not\");  text = text.replace(\"hadn't\", \"had not\");   text = text.replace(\"won't\", \"will not\");  text = text.replace(\"can't\", \"can not\");  text = text.replace(\"cannot\", \"can not\");  text = text.replace(\"shouldn't\", \"should not\");  text = text.replace(\"wouldn't\", \"would not\");\n","text = text.replace(\"gonna\", \"going to\");   text = text.replace(\"wanna\", \"want to\");   text = text.replace(\" Miss \", \" dr \");   text = text.replace(\" Pip \", \" john \");\n","# text = text.replace(\"'\", \"\");  # for 'bryant-stories.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2064,"status":"ok","timestamp":1654885856429,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"VctdBi3BM_2r","outputId":"b9b44f84-70fb-4227-ab57-71db5d6f4d4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["nltk.download('punkt')\n","text = nltk.tokenize.sent_tokenize(text) ## generating sentenses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dK9EoE6G6hAr"},"outputs":[],"source":["# text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUHLTpodnLmU"},"outputs":[],"source":["##### preprocessing: selecting sentences #####\n","import re \n","sents1 = [];\n","for line in range(len(text)):\n","    words = text[line].split()    # text[line] will be converted to lists of words\n","    if (len(words) >= 3):\n","        line_s = re.split(r'[:;]',text[line]);\n","        if len(line_s)>1:        ## finding multiple sentenses in one line\n","            for i in range(len(line_s)):    \n","                if len(line_s[i])>4:    sents1.append(line_s[i])\n","        else:  sents1.append(text[line]);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbsXd7FZ39vA"},"outputs":[],"source":["# nltk.corpus.brown.categories()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4123,"status":"ok","timestamp":1654885860735,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"zOnoqGJbrpUa","outputId":"5c3d52aa-84b1-4d50-a3af-198eba81e69b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"]}],"source":["nltk.download('brown')\n","text_b,sents2=[],[]\n","text_b.append( nltk.corpus.brown.sents(categories='adventure') )\n","text_b.append( nltk.corpus.brown.sents(categories='news') )\n","text_b.append( nltk.corpus.brown.sents(categories='belles_lettres') )\n","text_b.append( nltk.corpus.brown.sents(categories='humor') )\n","text_b.append( nltk.corpus.brown.sents(categories='hobbies') )\n","text_b.append( nltk.corpus.brown.sents(categories='reviews') )\n","text_b.append( nltk.corpus.brown.sents(categories='romance') )\n","text_b.append( nltk.corpus.brown.sents(categories='science_fiction') )\n","text_b.append( nltk.corpus.brown.sents(categories='mystery') )\n","text_b.append( nltk.corpus.brown.sents(categories='fiction') )\n","\n","for i in range(len(text_b)): \n","    for ln in range(len(text_b[i])):\n","        line = ' '.join(text_b[i][ln]) ## text_b is lists of words (in brown corpus) \n","        line = line.replace(\"Here's\", \"Here is\");   line = line.replace(\"here's\", \"here is\");   line = line.replace(\"I'm\", \"I am\");   line = line.replace(\"I'd\", \"I would\");   line = line.replace(\"I've\", \"I have\");   line = line.replace(\"I'll\", \"I will\");    line = line.replace(\"that's\", \"that is\");   line = line.replace(\"That's\", \"That is\");     line = line.replace(\"What's\", \"What is\");   line = line.replace(\"there's\", \"there is\");   line = line.replace(\"There's\", \"There is\");\n","        line = line.replace(\"We'll\", \"We will\");   line = line.replace(\"we'll\", \"we will\");  line = line.replace(\"You'll\", \"You will\");   line = line.replace(\"you'll\", \"you will\");  line = line.replace(\"It's\", \"It is\");   line = line.replace(\"it's\", \"it is\");  line = line.replace(\"It'll\", \"It will\");   line = line.replace(\"it'll\", \"it will\");  line = line.replace(\"You're\", \"You are\");  line = line.replace(\"you're\", \"you are\");   line = line.replace(\"You've\", \"You have\");  line = line.replace(\"you've\", \"you have\");   line = line.replace(\"You've\", \"You have\");  \n","        line = line.replace(\"She'll\", \"She will\");   line = line.replace(\"she'll\", \"she will\");  line = line.replace(\"He'll\", \"He will\");  line = line.replace(\"he'll\", \"he will\");  line = line.replace(\"They'll\", \"They will\");  line = line.replace(\"they'll\", \"they will\");   line = line.replace(\"They're\", \"They are\");  line = line.replace(\"they're\", \"they are\");  line = line.replace(\"They've\", \"They have\");  line = line.replace(\"they've\", \"they have\"); \n","        line = line.replace(\"don't\", \"do not\");   line = line.replace(\"doesn't\", \"does not\");   line = line.replace(\"didn't\", \"did not\");   line = line.replace(\"isn't\", \"is not\");   line = line.replace(\"wasn't\", \"was not\");   line = line.replace(\"aren't\", \"are not\");  line = line.replace(\"hasn't\", \"has not\");    line = line.replace(\"haven't\", \"have not\");  line = line.replace(\"hadn't\", \"had not\");   line = line.replace(\"won't\", \"will not\");  line = line.replace(\"can't\", \"can not\");  line = line.replace(\"cannot\", \"can not\");  line = line.replace(\"shouldn't\", \"should not\");  line = line.replace(\"couldn't\", \"could not\");  line = line.replace(\"wouldn't\", \"would not\");\n","        line = line.replace(\"gonna\", \"going to\");   line = line.replace(\"wanna\", \"want to\");     line = line.replace(\" Miss \", \" dr \");   line = line.replace(\" Pip \", \" john \");\n","        sents2.append(line)\n","\n","sents = sents2 + sents1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRhUn0N00FZY"},"outputs":[],"source":["# text_b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INyrA-08Hdw1"},"outputs":[],"source":["# sents[24000:24020]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GhqyPWLorQJW"},"outputs":[],"source":["######## remove text within parentheses ############\n","for i in range(len(sents)):     \n","    sents[i] = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", sents[i])\n","    sents[i] = re.sub(r\"[0-9]+\", \"0\", sents[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NKqpaQNIgzXR"},"outputs":[],"source":["for i in range(len(sents)): \n","    if (type(sents[i]) != str):  continue\n","    sents[i] = sents[i].lower()\n","    sents[i] = ' ' + sents[i]\n","    sents[i] = sents[i].replace(\"'s\", \"s \");  sents[i] = sents[i].replace(\"'twas\", \" it was \");   \n","    sents[i] = sents[i].replace(\"have'n't\", \" have not \");   sents[i] = sents[i].replace(\"ev'n\", \" even \"); \n","    sents[i] = sents[i].replace(\"o'er\", \" over \");   sents[i] = sents[i].replace(\"sha'n't\", \" shall not \"); \n","    sents[i] = sents[i].replace(\"\"\"'\"\"\", \"\"); \n","    sents[i] = sents[i].replace(\".\", \" \"); sents[i] = sents[i].replace(\"?\", \" \");  sents[i] = sents[i].replace(\"!\", \" \");    sents[i] = sents[i].replace(\"\"\" \" \"\"\", \"\"\" \"\"\");  sents[i] = sents[i].replace(\"&\", \" and \"); \n","    sents[i] = sents[i].replace('''\"''', ' \" ');\n","    sents[i] = sents[i].replace(\"*\", \" \");  sents[i] = sents[i].replace(\"_\", \" \");sents[i] = sents[i].replace(\"`\", \" \");  sents[i] = sents[i].replace(\",\", \" \");  sents[i] = sents[i].replace(\".\", \" \");   sents[i] = sents[i].replace(\";\", \" \");  sents[i] = sents[i].replace(\":\", \" \");  sents[i] = sents[i].replace(\"?\", \" \");  sents[i] = sents[i].replace(\"!\", \" \");    \n","    sents[i] = sents[i].replace(\"&\", \" and \"); sents[i] = sents[i].replace('''\"''', ' \" ');   sents[i] = sents[i].replace(\"\"\" \" \" \"\"\", \"\"\" \" \"\"\");  \n","\n","    sents[i] = sents[i].replace(\"- -\", \"--\");  sents[i] = sents[i].replace(\"----\", \"--\");  sents[i] = sents[i].replace(\"--\", \" -- \");  \n","    sents[i] = sents[i].replace(\" 0-\", \" 0 \");  sents[i] = sents[i].replace(\"0\", \" 0 \");  sents[i] = sents[i].replace(\"  \", \" \");  sents[i] = sents[i].replace(\"  \", \" \");  sents[i] = sents[i].replace(\" 0 d \", \" 0 \");  sents[i] = sents[i].replace(\" 0 s \", \" 0 \");  sents[i] = sents[i].replace(\" 0 st \", \" 0 \");  sents[i] = sents[i].replace(\" 0 th \", \" 0 \");  sents[i] = sents[i].replace(\" 0 0 \", \" 0 \");  sents[i] = sents[i].replace(\" 0 0 \", \" 0 \");  sents[i] = sents[i].replace(\" 0 0 \", \" 0 \");  sents[i] = sents[i].replace(\" $ 0 0 \", \" 0 dollar \");  sents[i] = sents[i].replace(\" $ 0 \", \" 0 dollar \");  \n","    sents[i] = sents[i].replace(\"   \", \" \");  sents[i] = sents[i].replace(\"   \", \" \");  sents[i] = sents[i].replace(\"   \", \" \");  sents[i] = sents[i].replace(\" 0 \", \" zero \");\n","    sents[i] = sents[i].replace(\" b \", \" \");   sents[i] = sents[i].replace(\" c \", \" \");  sents[i] = sents[i].replace(\" d \", \" \");  sents[i] = sents[i].replace(\" e \", \" \");  sents[i] = sents[i].replace(\" f \", \" \");  sents[i] = sents[i].replace(\" g \", \" \");  sents[i] = sents[i].replace(\" h \", \" \");  sents[i] = sents[i].replace(\" j \", \" \");  sents[i] = sents[i].replace(\" k \", \" \");  sents[i] = sents[i].replace(\" l \", \" \");  sents[i] = sents[i].replace(\" m \", \" \");   sents[i] = sents[i].replace(\" n \", \" \");   sents[i] = sents[i].replace(\" o \", \" \");   sents[i] = sents[i].replace(\" p \", \" \");  sents[i] = sents[i].replace(\" q \", \" \");  sents[i] = sents[i].replace(\" r \", \" \");  sents[i] = sents[i].replace(\" s \", \" \");   sents[i] = sents[i].replace(\" t \", \" \");  sents[i] = sents[i].replace(\" u \", \" \");   sents[i] = sents[i].replace(\" v \", \" \");  sents[i] = sents[i].replace(\" w \", \" \");  sents[i] = sents[i].replace(\" z \", \" \");  \n","    \n","    sents[i] = sents[i].replace(\" pre-\", \" pre\"); sents[i] = sents[i].replace(\" mama \", \" mother \"); sents[i] = sents[i].replace(\" em \", \" them \");  sents[i] = sents[i].replace(\" morrow \", \" tomorrow \"); sents[i] = sents[i].replace(\" to-morrow\", \" tomorrow\")\n","    sents[i] = sents[i].replace(\" de \", \"  \");  sents[i] = sents[i].replace(\" don \", \"  \");  sents[i] = sents[i].replace(\" jr \", \"  \");  sents[i] = sents[i].replace(\" mr \", \" dr \");  sents[i] = sents[i].replace(\" mrs \", \" dr \");  sents[i] = sents[i].replace(\" sir \", \" dr \");  sents[i] = sents[i].replace(\" st \", \" dr \");  sents[i] = sents[i].replace(\" ah \", \"  \");  sents[i] = sents[i].replace(\" anneounced \", \" announced \");  sents[i] = sents[i].replace(\" anti-\", \" anti\");  sents[i] = sents[i].replace(\" co \", \" cooperation \");  sents[i] = sents[i].replace(\" damn it \", \" damnit \");  sents[i] = sents[i].replace(\" damn war \", \" war \");  sents[i] = sents[i].replace(\" good bye \", \" goodbye \");  sents[i] = sents[i].replace(\" hey \", \" hi \");  sents[i] = sents[i].replace(\" o \", \" of \");  sents[i] = sents[i].replace(\" oh \", \"  \");  sents[i] = sents[i].replace(\" re-\", \" re\");  sents[i] = sents[i].replace(\" san \", \" san\");   sents[i] = sents[i].replace(\" sperm whale\", \" whale\");   \n","    sents[i] = sents[i].replace(\" aint \", \" are not \");  sents[i] = sents[i].replace(\" aj \", \"  \");  sents[i] = sents[i].replace(\" ann \", \" anne \");   sents[i] = sents[i].replace(\" ay \", \" yes \");  sents[i] = sents[i].replace(\" aye \", \" yes \");  sents[i] = sents[i].replace(\" by the bye \", \"  \");  sents[i] = sents[i].replace(\" couldnt \", \" could not \");  sents[i] = sents[i].replace(\" damndue to \", \" because of \");  sents[i] = sents[i].replace(\" dont \", \" do not \");  sents[i] = sents[i].replace(\" em  \", \" them \");  sents[i] = sents[i].replace(\" ere \", \" before \");  sents[i] = sents[i].replace(\" hitherto \", \" until now \");  sents[i] = sents[i].replace(\" nay \", \" no \"); sents[i] = sents[i].replace(\" nigh \", \" near \");  sents[i] = sents[i].replace(\" re \", \" about \");   sents[i] = sents[i].replace(\" till \", \" until \");  sents[i] = sents[i].replace(\" tis \", \" it is \");  sents[i] = sents[i].replace(\" whats \", \" what is \");  sents[i] = sents[i].replace(\" ye \", \" you \");  sents[i] = sents[i].replace(\" yes aye \", \"  \");  sents[i] = sents[i].replace(\" your majesty \", \" you \");  sents[i] = sents[i].replace(\" thou canst \", \" you can \");  sents[i] = sents[i].replace(\" thou hast \", \" you have \");  sents[i] = sents[i].replace(\" thee \", \" you \");  sents[i] = sents[i].replace(\" thou \", \" you \");  sents[i] = sents[i].replace(\" thoust \", \" you have \");  sents[i] = sents[i].replace(\" thy \", \" your \");  \n","    sents[i] = sents[i].replace(\" hed be \", \" he would be \");  sents[i] = sents[i].replace(\" hed been \", \" he had been \");  sents[i] = sents[i].replace(\" hed come \", \" he would come \");  sents[i] = sents[i].replace(\" hed creep \", \" he would  creep \");  sents[i] = sents[i].replace(\" hed decided \", \" he had decided \");  sents[i] = sents[i].replace(\" hed do \", \" he would  do \");  sents[i] = sents[i].replace(\" hed give \", \" he would give \");  sents[i] = sents[i].replace(\" hed got \", \" he had got \");  sents[i] = sents[i].replace(\" hed had \", \" he had had \");  sents[i] = sents[i].replace(\" hed have \", \" he would have \");  sents[i] = sents[i].replace(\" hed leave \", \" he would leave \");  sents[i] = sents[i].replace(\" hed left \", \" he had left \");  sents[i] = sents[i].replace(\" hed meet \", \" he would meet \");  sents[i] = sents[i].replace(\" hed not care \", \" he would not care \");  sents[i] = sents[i].replace(\" hed take \", \" he would take \");  sents[i] = sents[i].replace(\" hed tell \", \" he would tell \");  sents[i] = sents[i].replace(\" hed told \", \" he had told \");  sents[i] = sents[i].replace(\" youd decided \", \" you had decided \");  sents[i] = sents[i].replace(\" youd learned \", \" you had learned \");  sents[i] = sents[i].replace(\" youd missed \", \" you had missed \");  \n","    sents[i] = sents[i].replace(\" abra \", \" smith \");  sents[i] = sents[i].replace(\" ada \", \" johnson \");  sents[i] = sents[i].replace(\" adams \", \" smith \");  sents[i] = sents[i].replace(\" baker \", \" smith \");  sents[i] = sents[i].replace(\" barton \", \" smith \");  sents[i] = sents[i].replace(\" batess \", \" williams \");  sents[i] = sents[i].replace(\" benwick \", \" williams \");  sents[i] = sents[i].replace(\" bildad \", \" smith \");  sents[i] = sents[i].replace(\" burke \", \" williams \");  sents[i] = sents[i].replace(\" bursal \", \" williams \");  sents[i] = sents[i].replace(\" captain harville \", \" johnson \");  sents[i] = sents[i].replace(\" captain wentworth \", \" johnson \");  sents[i] = sents[i].replace(\" carlo \", \" johnson \");  sents[i] = sents[i].replace(\" celies \", \" johnson \");  sents[i] = sents[i].replace(\" clayton \", \" williams \");  sents[i] = sents[i].replace(\" dashwood \", \" smith \");  sents[i] = sents[i].replace(\" dashwoods \", \" johnson \");  sents[i] = sents[i].replace(\" donwell \", \" williams \");  sents[i] = sents[i].replace(\" doyle \", \" williams \");  sents[i] = sents[i].replace(\" edwards \", \" williams \");  sents[i] = sents[i].replace(\" eltons \", \" smith \");  sents[i] = sents[i].replace(\" estherson \", \" johnson \");  sents[i] = sents[i].replace(\" fairfax \", \" williams \");  sents[i] = sents[i].replace(\" felix \", \" williams \");  sents[i] = sents[i].replace(\" frederick \", \" johnson \");  sents[i] = sents[i].replace(\" garland \", \" smith \");  sents[i] = sents[i].replace(\" gresham \", \" johnson \");  sents[i] = sents[i].replace(\" grey \", \" williams \");  sents[i] = sents[i].replace(\" hardwick \", \" smith \");  sents[i] = sents[i].replace(\" hartfield \", \" johnson \");  sents[i] = sents[i].replace(\" jennings \", \" smith \");  sents[i] = sents[i].replace(\" jones \", \" smith \");  sents[i] = sents[i].replace(\" joseph \", \" smith \");  sents[i] = sents[i].replace(\" kennedy \", \" johnson \");  sents[i] = sents[i].replace(\" kiz \", \" smith \");  sents[i] = sents[i].replace(\" kizzie \", \" johnson \");  sents[i] = sents[i].replace(\" knightley \", \" johnson \");  sents[i] = sents[i].replace(\" langford \", \" williams \");  sents[i] = sents[i].replace(\" lee \", \" smith \");  sents[i] = sents[i].replace(\" lewis \", \" smith \");  sents[i] = sents[i].replace(\" loveit \", \" williams \");  sents[i] = sents[i].replace(\" martin \", \" williams \");  sents[i] = sents[i].replace(\" maude \", \" smith \");  sents[i] = sents[i].replace(\" middleton \", \" smith \");  sents[i] = sents[i].replace(\" miss johnson \", \" dr johnson \");  sents[i] = sents[i].replace(\" miss smith \", \" dr smith \");  sents[i] = sents[i].replace(\" miss williams \", \" dr williams \");  sents[i] = sents[i].replace(\" morgan \", \" johnson \");  sents[i] = sents[i].replace(\" murphy \", \" johnson \");  sents[i] = sents[i].replace(\" musgrove \", \" williams \");  sents[i] = sents[i].replace(\" musgroves \", \" williams \");  sents[i] = sents[i].replace(\" norland \", \" williams \");  sents[i] = sents[i].replace(\" palmer \", \" johnson \");  sents[i] = sents[i].replace(\" peleg \", \" johnson \");  sents[i] = sents[i].replace(\" piedro \", \" smith \");  sents[i] = sents[i].replace(\" pulova \", \" smith \");  sents[i] = sents[i].replace(\" queequeg \", \" williams \");  sents[i] = sents[i].replace(\" roberts \", \" johnson \");  sents[i] = sents[i].replace(\" rossoff \", \" williams \");  sents[i] = sents[i].replace(\" russell \", \" johnson \");  sents[i] = sents[i].replace(\" schwarzkopf \", \" johnson \");  sents[i] = sents[i].replace(\" shirley \", \" williams \");  sents[i] = sents[i].replace(\" stuart \", \" johnson \");  sents[i] = sents[i].replace(\" sutherland \", \" williams \");  sents[i] = sents[i].replace(\" talbot \", \" williams \");  sents[i] = sents[i].replace(\" tamiris \", \" smith \");  sents[i] = sents[i].replace(\" tarlton \", \" johnson \");  sents[i] = sents[i].replace(\" taylor \", \" smith \");  sents[i] = sents[i].replace(\" vaughan \", \" johnson \");  sents[i] = sents[i].replace(\" vieth \", \" williams \");  sents[i] = sents[i].replace(\" walter \", \" williams \");  sents[i] = sents[i].replace(\" watson \", \" johnson \");  sents[i] = sents[i].replace(\" wentworth \", \" williams \");  sents[i] = sents[i].replace(\" weston \", \" smith \");  sents[i] = sents[i].replace(\" westons \", \" smiths \");  sents[i] = sents[i].replace(\" wheeler \", \" smith \");  sents[i] = sents[i].replace(\" willoughby \", \" johnson \");  sents[i] = sents[i].replace(\" wilson \", \" williams \");  sents[i] = sents[i].replace(\" winston \", \" williams \");  sents[i] = sents[i].replace(\" woodhouse \", \" smith \");  sents[i] = sents[i].replace(\" xydis \", \" johnson \");  \n","    sents[i] = sents[i].replace(\" annee \", \" jane \");  sents[i] = sents[i].replace(\" annees \", \" janes \");  sents[i] = sents[i].replace(\" barbara \", \" jane \");  sents[i] = sents[i].replace(\" bates \", \" emma \");  sents[i] = sents[i].replace(\" betsy \", \" alice \");  sents[i] = sents[i].replace(\" cecilia \", \" alice \");  sents[i] = sents[i].replace(\" eileen \", \" emma \");  sents[i] = sents[i].replace(\" elinor \", \" jane \");  sents[i] = sents[i].replace(\" elinors \", \" janes \");  sents[i] = sents[i].replace(\" folly \", \" emma \");  sents[i] = sents[i].replace(\" glenda \", \" alice \");  sents[i] = sents[i].replace(\" harriet \", \" jane \");  sents[i] = sents[i].replace(\" harriets \", \" janes \");  sents[i] = sents[i].replace(\" henrietta \", \" jane \");  sents[i] = sents[i].replace(\" isabella \", \" emma \");  sents[i] = sents[i].replace(\" jen \", \" jane \");  sents[i] = sents[i].replace(\" joan \", \" alice \");  sents[i] = sents[i].replace(\" julia \", \" emma \");  sents[i] = sents[i].replace(\" kate \", \" jane \");  sents[i] = sents[i].replace(\" katherine \", \" alice \");  sents[i] = sents[i].replace(\" laura \", \" emma \");  sents[i] = sents[i].replace(\" leonora \", \" alice \");  sents[i] = sents[i].replace(\" linda \", \" jane \");  sents[i] = sents[i].replace(\" louisa \", \" jane \");  sents[i] = sents[i].replace(\" margaret \", \" alice \");  sents[i] = sents[i].replace(\" mariannee \", \" alice \");  sents[i] = sents[i].replace(\" mariannee \", \" jane \");  sents[i] = sents[i].replace(\" mariannees \", \" janes \");  sents[i] = sents[i].replace(\" mary \", \" jane \");  sents[i] = sents[i].replace(\" miss alice \", \" dr alice \");  sents[i] = sents[i].replace(\" miss emma \", \" dr emma \");  sents[i] = sents[i].replace(\" miss jane \", \" dr jane \");  sents[i] = sents[i].replace(\" rachel \", \" alice \");  sents[i] = sents[i].replace(\" rosamond \", \" alice \");  sents[i] = sents[i].replace(\" sophy \", \" alice \");  sents[i] = sents[i].replace(\" susan \", \" emma \");  sents[i] = sents[i].replace(\" susans \", \" emmas \");  sents[i] = sents[i].replace(\" theresa \", \" emma \");  \n","    sents[i] = sents[i].replace(\" ahab \", \" elliot \");  sents[i] = sents[i].replace(\" ahabs \", \" elliots \");  sents[i] = sents[i].replace(\" ahalexander \", \" elton \");  sents[i] = sents[i].replace(\" ahtom \", \" elliot \");  sents[i] = sents[i].replace(\" alfred \", \" elliot \");  sents[i] = sents[i].replace(\" bildad \", \" elton \");  sents[i] = sents[i].replace(\" billy \", \" edward \");  sents[i] = sents[i].replace(\" captain benwick \", \" edward \");  sents[i] = sents[i].replace(\" captain bildad \", \" elton \");  sents[i] = sents[i].replace(\" captain peleg \", \" elliot \");  sents[i] = sents[i].replace(\" charles \", \" elton \");  sents[i] = sents[i].replace(\" charlie \", \" elton \");  sents[i] = sents[i].replace(\" churchill \", \" elliot \");  sents[i] = sents[i].replace(\" david \", \" elton \");  sents[i] = sents[i].replace(\" francisco \", \" edward \");  sents[i] = sents[i].replace(\" franklin \", \" edward \");  sents[i] = sents[i].replace(\" george \", \" elton \");  sents[i] = sents[i].replace(\" hal \", \" elton \");  sents[i] = sents[i].replace(\" hans \", \" elliot \");  sents[i] = sents[i].replace(\" hartfield \", \" smith \");  sents[i] = sents[i].replace(\" jack \", \" edward \");  sents[i] = sents[i].replace(\" james \", \" edward \");  sents[i] = sents[i].replace(\" jem \", \" elliot \");  sents[i] = sents[i].replace(\" jonah \", \" elliot \");  sents[i] = sents[i].replace(\" lawrence \", \" elton \");  sents[i] = sents[i].replace(\" louis \", \" edward \");  sents[i] = sents[i].replace(\" mike \", \" elton \");  sents[i] = sents[i].replace(\" nayopeleg \", \" elliot \");  sents[i] = sents[i].replace(\" paul \", \" edward \");  sents[i] = sents[i].replace(\" perry \", \" elton \");  sents[i] = sents[i].replace(\" peter \", \" eliot \");  sents[i] = sents[i].replace(\" phil \", \" elliot \");  sents[i] = sents[i].replace(\" philip \", \" edward \");  sents[i] = sents[i].replace(\" richard \", \" elton \");  sents[i] = sents[i].replace(\" robert \", \" elliot \");  sents[i] = sents[i].replace(\" sam \", \" edward \");  sents[i] = sents[i].replace(\" sammy \", \" edward \");  sents[i] = sents[i].replace(\" starbuck \", \" elton \");  sents[i] = sents[i].replace(\" tashtego \", \" elliot \");  sents[i] = sents[i].replace(\" the hatter \", \" eliot \");  sents[i] = sents[i].replace(\" the tailor \", \" elton \");  sents[i] = sents[i].replace(\" thomas \", \" elliot \");  sents[i] = sents[i].replace(\"  \", \" \");  \n","    sents[i] = sents[i].replace(\" brahmin \", \" man \");  sents[i] = sents[i].replace(\" britain \", \" england \");  sents[i] = sents[i].replace(\" british \", \" english \");  sents[i] = sents[i].replace(\" dormouse \", \" mouse \");  sents[i] = sents[i].replace(\" gingerbread boy \", \" gingerbreadboy \");  sents[i] = sents[i].replace(\" guinea-\", \"guinea\");  sents[i] = sents[i].replace(\" guinea pig \", \" guineapig \");  sents[i] = sents[i].replace(\" guineahatter \", \" man \");  sents[i] = sents[i].replace(\" harpooneer \", \" man \");  sents[i] = sents[i].replace(\" harpooneers \", \" men \");  sents[i] = sents[i].replace(\" highbury \", \" paris \");  sents[i] = sents[i].replace(\" leviathan \", \" monster \");  sents[i] = sents[i].replace(\" little fir tree \", \" little tree \");  sents[i] = sents[i].replace(\" look-outs \", \" lookouts \");  sents[i] = sents[i].replace(\" maam \", \" madam \");  sents[i] = sents[i].replace(\" mamma \", \" mother \");  sents[i] = sents[i].replace(\" mast-heads \", \" mastheads \");  sents[i] = sents[i].replace(\" moby dick \", \" the whale \");  sents[i] = sents[i].replace(\" morrow \", \" tomorrow \");  sents[i] = sents[i].replace(\" new guinea \", \" newguinea \");  sents[i] = sents[i].replace(\" papa \", \" father \");  sents[i] = sents[i].replace(\" pequods \", \" ships \");  sents[i] = sents[i].replace(\" pequods boats \", \" ships \");  sents[i] = sents[i].replace(\" randalls \", \" paris \");  sents[i] = sents[i].replace(\" san francisco \", \" sanfrancisco \");  sents[i] = sents[i].replace(\" seamen \", \" men \");  sents[i] = sents[i].replace(\" soviet union \", \" soviet \");  sents[i] = sents[i].replace(\" the guinea \", \" the dollar \");  sents[i] = sents[i].replace(\" the pequod \", \" the ship \");  sents[i] = sents[i].replace(\" whaleman \", \" man \");  sents[i] = sents[i].replace(\" whalemen \", \" men \");  sents[i] = sents[i].replace(\" young gentleman \", \" young man \");  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8Pew95hrEOh"},"outputs":[],"source":["#### removing chapter header ###\n","for i in range(len(sents)): \n","     if (type(sents[i]) != str):  continue\n","     if sents[i][:8].find('chapter') != -1:  sents[i] = \"\";\n","     elif sents[i].find(') chapter ') != -1:  sents[i] = \"\";\n","     elif sents[i][:6].find('page ') != -1:  sents[i] = \"\";\n","     elif sents[i].find('[illustration') != -1:  sents[i] = \"\";"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLFLk2U5Mslp"},"outputs":[],"source":["#### removing afer (\" said), (e.g. \"I will do\" said alice.) ###\n","for i in range(len(sents)): \n","     if (type(sents[i]) != str):  continue\n","     if sents[i].find('\" said ') != -1:  sents[i] = sents[i][:sents[i].find('\" said ')];\n","     # if sents[i].find('\" answered ') != -1:  sents[i] = sents[i][:sents[i].find('\" answered ')];"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-x47ErGrKAm"},"outputs":[],"source":["#### removing French sentences ###\n","for i in range(len(sents)): \n","     if (type(sents[i]) != str):  continue\n","     if sents[i].find(' la ') != -1:  sents[i] = \"\";\n","     elif sents[i].find(' non ') != -1:  sents[i] = \"\";"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffaGOyQKrM-e"},"outputs":[],"source":["#### removing sentences contains hi gentlemen/gentleman sir damn or af ###\n","for i in range(len(sents)): \n","     if (type(sents[i]) != str):  continue\n","     if sents[i].find(' hi ') != -1:  sents[i] = \"\";  ## <40 sentences\n","     elif sents[i].find(' gentlemen ') != -1:  sents[i] = \"\";\n","     elif sents[i].find(' a d 0 ') != -1:  sents[i] = \"\";\n","     elif sents[i].find(' af ') != -1:  sents[i] = \"\";\n","     elif sents[i][:6].find('said ') != -1:  sents[i] = \"\";\n","    #  elif sents[i].find(' damn ') != -1:  sents[i] = \"\";"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIzjb24kxJ9D"},"outputs":[],"source":["# for i in range(len(sents)): \n","#      if (type(sents[i]) != str):  continue\n","#      if sents[i].find(' thou ') != -1:    print(sents[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQkBCPWNnLpU"},"outputs":[],"source":["##### preprocessing: tokenizing #####\n","num_words = 3000\n","tokenizer = preprocessing.text.Tokenizer(oov_token='unk')\n","tokenizer.fit_on_texts(sents)\n","tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= num_words} ####\n","tokenizer.word_index[tokenizer.oov_token] = num_words + 1 #### These two lines are necessary to remove rare words \n","w_idx = tokenizer.word_index\n","w_idx['_'] = 0;   w_idx['unk'] = 1;   \n","idx_to_word = dict([(value, key) for (key, value) in w_idx.items()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1654885873293,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"7pyie4KB_F_B","outputId":"d3b514a1-72c1-46c3-f4be-f7e36be303ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'unk': 1, 'the': 2, 'and': 3, 'of': 4, 'to': 5, 'a': 6, 'in': 7, 'was': 8, 'i': 9, 'he': 10, 'it': 11, 'that': 12, 'not': 13, 'his': 14, 'for': 15, 'you': 16, 'is': 17, 'as': 18, 'her': 19, 'with': 20, 'had': 21, 'be': 22, 'she': 23, 'but': 24, 'at': 25, 'on': 26, 'have': 27, 'dr': 28, 'all': 29, 'this': 30, 'him': 31, 'by': 32, 'they': 33, 'from': 34, 'so': 35, 'would': 36, 'were': 37, 'one': 38, 'which': 39, 'no': 40, 'will': 41, 'there': 42, 'are': 43, 'or': 44, 'my': 45, 'could': 46, 'do': 47, 'an': 48, 'what': 49, 'been': 50, 'when': 51, 'zero': 52, 'me': 53, 'their': 54, 'them': 55, 'very': 56, 'if': 57, 'more': 58, 'out': 59, 'who': 60, 'up': 61, 'said': 62, 'we': 63, 'now': 64, 'can': 65, 'little': 66, 'did': 67, 'your': 68, 'than': 69, 'then': 70, 'any': 71, 'some': 72, 'into': 73, 'time': 74, 'about': 75, 'only': 76, 'like': 77, 'has': 78, 'man': 79, 'such': 80, 'must': 81, 'much': 82, 'well': 83, 'other': 84, 'smith': 85, 'good': 86, 'how': 87, 'before': 88, 'know': 89, 'jane': 90, 'am': 91, 'two': 92, 'over': 93, 'never': 94, 'see': 95, 'its': 96, 'down': 97, 'first': 98, 'after': 99, 'should': 100, 'own': 101, 'johnson': 102, 'williams': 103, 'upon': 104, 'great': 105, 'every': 106, 'too': 107, 'made': 108, 'most': 109, 'old': 110, 'these': 111, 'being': 112, 'here': 113, 'might': 114, 'way': 115, 'think': 116, 'long': 117, 'may': 118, 'just': 119, 'say': 120, 'day': 121, 'again': 122, 'go': 123, 'elliot': 124, 'even': 125, 'back': 126, 'come': 127, 'came': 128, 'make': 129, 'emma': 130, 'thought': 131, 'elton': 132, 'though': 133, 'where': 134, 'last': 135, 'himself': 136, 'thing': 137, 'still': 138, 'new': 139, 'off': 140, 'without': 141, 'our': 142, 'nothing': 143, 'many': 144, 'us': 145, 'whale': 146, 'those': 147, 'away': 148, 'ever': 149, 'through': 150, 'while': 151, 'men': 152, 'house': 153, 'get': 154, 'take': 155, 'went': 156, 'always': 157, 'head': 158, 'same': 159, 'look': 160, 'yet': 161, 'saw': 162, 'until': 163, 'sure': 164, 'because': 165, 'herself': 166, 'seemed': 167, 'another': 168, 'give': 169, 'three': 170, 'edward': 171, 'soon': 172, 'right': 173, 'home': 174, 'years': 175, 'life': 176, 'once': 177, 'something': 178, 'people': 179, 'world': 180, 'found': 181, 'place': 182, 'quite': 183, 'shall': 184, 'young': 185, 'looked': 186, 'going': 187, 'enough': 188, 'better': 189, 'heard': 190, 'let': 191, 'father': 192, 'mother': 193, 'hand': 194, 'however': 195, 'eyes': 196, 'tell': 197, 'few': 198, 'why': 199, 'room': 200, 'left': 201, 'both': 202, 'half': 203, 'almost': 204, 'knew': 205, 'each': 206, 'got': 207, 'work': 208, 'felt': 209, 'night': 210, 'under': 211, 'put': 212, 'mind': 213, 'does': 214, 'yes': 215, 'side': 216, 'done': 217, 'against': 218, 'alice': 219, 'told': 220, 'also': 221, 'between': 222, 'took': 223, 'white': 224, 'indeed': 225, 'moment': 226, 'far': 227, 'morning': 228, 'things': 229, 'cried': 230, 'door': 231, 'part': 232, 'seen': 233, 'dear': 234, 'rather': 235, 'since': 236, 'poor': 237, 'next': 238, 'perhaps': 239, 'find': 240, 'called': 241, 'having': 242, 'water': 243, 'began': 244, 'want': 245, 'lady': 246, 'whole': 247, 'ship': 248, 'set': 249, 'sea': 250, 'face': 251, 'year': 252, 'round': 253, 'boy': 254, 'small': 255, 'best': 256, 'really': 257, 'friend': 258, 'around': 259, 'end': 260, 'present': 261, 'hear': 262, 'gave': 263, 'woman': 264, 'high': 265, 'days': 266, 'together': 267, 'nor': 268, 'asked': 269, 'anne': 270, 'body': 271, 'heart': 272, 'love': 273, 'word': 274, 'course': 275, 'turned': 276, 'hope': 277, 'hands': 278, 'captain': 279, 'often': 280, 'kind': 281, 'least': 282, 'john': 283, 'among': 284, 'myself': 285, 'voice': 286, 'marianne': 287, 'wish': 288, 'others': 289, 'four': 290, 'family': 291, 'less': 292, 'full': 293, 'anything': 294, 'used': 295, 'name': 296, 'sort': 297, 'looking': 298, 'open': 299, 'along': 300, 'believe': 301, 'children': 302, 'gone': 303, 'near': 304, 'happy': 305, 'given': 306, 'state': 307, 'use': 308, 'feel': 309, 'air': 310, 'matter': 311, 'stood': 312, 'known': 313, 'business': 314, 'brought': 315, 'big': 316, 'else': 317, 'general': 318, 'keep': 319, 'money': 320, 'friends': 321, 'speak': 322, 'coming': 323, 'leave': 324, 'whether': 325, 'help': 326, 'large': 327, 'evening': 328, 'party': 329, 'wanted': 330, 'whom': 331, 'case': 332, 'five': 333, 'short': 334, 'sister': 335, 'possible': 336, 'times': 337, 'taken': 338, 'behind': 339, 'fine': 340, 'wife': 341, 'mean': 342, 'within': 343, 'point': 344, 'whose': 345, 'reason': 346, 'true': 347, 'whales': 348, 'light': 349, 'themselves': 350, 'making': 351, 'boat': 352, 'feet': 353, 'dollar': 354, 'idea': 355, 'either': 356, 'passed': 357, 'second': 358, 'replied': 359, 'call': 360, 'words': 361, 'certainly': 362, 'letter': 363, 'sat': 364, 'company': 365, 'therefore': 366, 'during': 367, 'line': 368, 'hour': 369, 'rest': 370, 'town': 371, 'early': 372, 'hard': 373, 'brother': 374, 'towards': 375, 'several': 376, 'person': 377, 'american': 378, 'girl': 379, 'talk': 380, 'god': 381, 'care': 382, 'bear': 383, 'sometimes': 384, 'fact': 385, 'war': 386, 'country': 387, 'certain': 388, 'ready': 389, 'deal': 390, 'need': 391, 'kept': 392, 'ran': 393, 'able': 394, 'sense': 395, 'run': 396, 'interest': 397, 'death': 398, 'child': 399, 'seem': 400, 'turn': 401, 'longer': 402, 'minutes': 403, 'live': 404, 'manner': 405, 'answer': 406, 'pretty': 407, 'son': 408, 'show': 409, 'already': 410, 'power': 411, 'immediately': 412, 'pleasure': 413, 'hold': 414, 'eye': 415, 'green': 416, 'bed': 417, 'ago': 418, 'thus': 419, 'week': 420, 'order': 421, 'means': 422, 'suppose': 423, 'alone': 424, 'sight': 425, 'walked': 426, 'stand': 427, 'hardly': 428, 'real': 429, 'black': 430, 'english': 431, 'saying': 432, 'street': 433, 'become': 434, 'added': 435, 'school': 436, 'feelings': 437, 'story': 438, 'across': 439, 'subject': 440, 'ask': 441, 'different': 442, 'city': 443, 'understand': 444, 'thinking': 445, 'feeling': 446, 'says': 447, 'strong': 448, 'everything': 449, 'play': 450, 'above': 451, 'change': 452, 'itself': 453, 'held': 454, 'bad': 455, 'fire': 456, 'king': 457, 'hours': 458, 'six': 459, 'ground': 460, 'visit': 461, 'doubt': 462, 'past': 463, 'table': 464, 'later': 465, 'top': 466, 'living': 467, 'ten': 468, 'read': 469, 'remember': 470, 'seems': 471, 'doing': 472, 'lost': 473, 'afraid': 474, 'dark': 475, 'tried': 476, 'attention': 477, 'close': 478, 'taking': 479, 'question': 480, 'cut': 481, 'truth': 482, 'window': 483, 'dead': 484, 'ought': 485, 'music': 486, 'return': 487, 'cold': 488, 'became': 489, 'public': 490, 'lay': 491, 'form': 492, 'fish': 493, 'sent': 494, 'stay': 495, 'red': 496, 'seeing': 497, 'character': 498, 'continued': 499, 'happened': 500, 'yourself': 501, 'madam': 502, 'late': 503, 'neither': 504, 'received': 505, 'book': 506, 'nature': 507, 'returned': 508, 'try': 509, 'sound': 510, 'number': 511, 'boys': 512, 'account': 513, 'suddenly': 514, 'toward': 515, 'beyond': 516, 'please': 517, 'president': 518, 'lived': 519, 'walk': 520, 'land': 521, 'common': 522, 'paris': 523, 'hes': 524, 'appeared': 525, 'history': 526, 'car': 527, 'colonel': 528, 'particular': 529, 'situation': 530, 'ships': 531, 'started': 532, 'spoke': 533, 'probably': 534, 'glad': 535, 'ill': 536, 'frank': 537, 'wonder': 538, 'forward': 539, 'sun': 540, 'followed': 541, 'nobody': 542, 'front': 543, 'pay': 544, 'important': 545, 'arm': 546, 'talking': 547, 'road': 548, 'law': 549, 'society': 550, 'dinner': 551, 'twenty': 552, 'except': 553, 'human': 554, 'stopped': 555, 'bring': 556, 'low': 557, 'board': 558, 'natural': 559, 'fast': 560, 'chance': 561, 'self': 562, 'expected': 563, 'instead': 564, 'opened': 565, 'caught': 566, 'hair': 567, 'strange': 568, 'art': 569, 'getting': 570, 'standing': 571, 'lord': 572, 'comes': 573, 'age': 574, 'beautiful': 575, 'hall': 576, 'states': 577, 'reached': 578, 'meet': 579, 'tomorrow': 580, 'opinion': 581, 'clear': 582, 'exactly': 583, 'obliged': 584, 'sitting': 585, 'spirits': 586, 'months': 587, 'giving': 588, 'free': 589, 'perfectly': 590, 'sorry': 591, 'none': 592, 'met': 593, 'meeting': 594, 'buster': 595, 'usual': 596, 'fear': 597, 'blue': 598, 'deep': 599, 'moved': 600, 'daughter': 601, 'especially': 602, 'wait': 603, 'makes': 604, 'wished': 605, 'directly': 606, 'field': 607, 'york': 608, 'women': 609, 'deck': 610, 'office': 611, 'boats': 612, 'stubb': 613, 'meant': 614, 'ones': 615, 'horse': 616, 'trying': 617, 'plan': 618, 'pleased': 619, 'happiness': 620, 'mouth': 621, 'weeks': 622, 'easy': 623, 'beginning': 624, 'hundred': 625, 'wrong': 626, 'everybody': 627, 'future': 628, 'talked': 629, 'whatever': 630, 'bit': 631, 'thousand': 632, 'group': 633, 'church': 634, 'acquaintance': 635, 'married': 636, 'necessary': 637, 'piece': 638, 'fellow': 639, 'mans': 640, 'service': 641, 'proper': 642, 'fell': 643, 'view': 644, 'sisters': 645, 'south': 646, 'minute': 647, 'trouble': 648, 'garden': 649, 'comfort': 650, 'besides': 651, 'answered': 652, 'running': 653, 'struck': 654, 'husband': 655, 'mine': 656, 'tree': 657, 'carried': 658, 'earth': 659, 'stop': 660, 'length': 661, 'farmer': 662, 'ladies': 663, 'lucy': 664, 'waiting': 665, 'turning': 666, 'england': 667, 'rose': 668, 'watch': 669, 'determined': 670, 'nearly': 671, 'third': 672, 'box': 673, 'single': 674, 'today': 675, 'particularly': 676, 'united': 677, 'degree': 678, 'slowly': 679, 'paid': 680, 'further': 681, 'worth': 682, 'eat': 683, 'act': 684, 'instant': 685, 'figure': 686, 'greater': 687, 'spirit': 688, 'foot': 689, 'job': 690, 'floor': 691, 'knowledge': 692, 'effect': 693, 'carriage': 694, 'social': 695, 'arms': 696, 'william': 697, 'london': 698, 'purpose': 699, 'although': 700, 'decided': 701, 'object': 702, 'move': 703, 'looks': 704, 'fair': 705, 'knows': 706, 'likely': 707, 'private': 708, 'silent': 709, 'wide': 710, 'wall': 711, 'national': 712, 'afterwards': 713, 'wind': 714, 'entirely': 715, 'speaking': 716, 'thoughts': 717, 'impossible': 718, 'miles': 719, 'silence': 720, 'entered': 721, 'experience': 722, 'program': 723, 'distance': 724, 'remained': 725, 'sit': 726, 'court': 727, 'summer': 728, 'girls': 729, 'finally': 730, 'blood': 731, 'wrote': 732, 'written': 733, 'picture': 734, 'letters': 735, 'conversation': 736, 'janes': 737, 'broken': 738, 'straight': 739, 'settled': 740, 'considered': 741, 'spent': 742, 'regard': 743, 'gentleman': 744, 'former': 745, 'yesterday': 746, 'weather': 747, 'placed': 748, 'led': 749, 'fresh': 750, 'inside': 751, 'heavy': 752, 'gold': 753, 'hat': 754, 'bill': 755, 'fathers': 756, 'taste': 757, 'per': 758, 'assure': 759, 'fortune': 760, 'lines': 761, 'fall': 762, 'merely': 763, 'complete': 764, 'warm': 765, 'ball': 766, 'fixed': 767, 'simple': 768, 'thank': 769, 'outside': 770, 'circumstances': 771, 'century': 772, 'special': 773, 'trees': 774, 'smile': 775, 'game': 776, 'master': 777, 'eight': 778, 'area': 779, 'leg': 780, 'dare': 781, 'actually': 782, 'example': 783, 'period': 784, 'system': 785, 'hot': 786, 'spring': 787, 'repeated': 788, 'seven': 789, 'soul': 790, 'government': 791, 'news': 792, 'paper': 793, 'drawing': 794, 'marriage': 795, 'middle': 796, 'crew': 797, 'sweet': 798, 'difference': 799, 'quick': 800, 'mothers': 801, 'finished': 802, 'walking': 803, 'worse': 804, 'consider': 805, 'write': 806, 'affection': 807, 'believed': 808, 'horses': 809, 'tone': 810, 'pass': 811, 'hill': 812, 'excellent': 813, 'equal': 814, 'wild': 815, 'goes': 816, 'following': 817, 'exclaimed': 818, 'generally': 819, 'fancy': 820, 'action': 821, 'oil': 822, 'secret': 823, 'health': 824, 'forget': 825, 'start': 826, 'bottom': 827, 'respect': 828, 'pray': 829, 'north': 830, 'send': 831, 'clay': 832, 'corner': 833, 'chief': 834, 'surprise': 835, 'moments': 836, 'couple': 837, 'dropped': 838, 'thirty': 839, 'dance': 840, 'drew': 841, 'joe': 842, 'west': 843, 'problem': 844, 'pool': 845, 'village': 846, 'leaving': 847, 'honour': 848, 'bath': 849, 'nice': 850, 'meaning': 851, 'position': 852, 'judge': 853, 'hearing': 854, 'education': 855, 'appear': 856, 'conduct': 857, 'filled': 858, 'pain': 859, 'grew': 860, 'follow': 861, 'notice': 862, 'university': 863, 'manners': 864, 'greatest': 865, 'working': 866, 'breakfast': 867, 'note': 868, 'sleep': 869, 'completely': 870, 'quiet': 871, 'shot': 872, 'handsome': 873, 'farther': 874, 'glass': 875, 'arthur': 876, 'sudden': 877, 'sake': 878, 'center': 879, 'appearance': 880, 'serious': 881, 'wood': 882, 'worked': 883, 'engaged': 884, 'force': 885, 'command': 886, 'bright': 887, 'imagine': 888, 'strength': 889, 'easily': 890, 'laughed': 891, 'cause': 892, 'writing': 893, 'college': 894, 'supposed': 895, 'understanding': 896, 'carry': 897, 'joy': 898, 'rich': 899, 'monster': 900, 'allow': 901, 'mark': 902, 'danger': 903, 'value': 904, 'begin': 905, 'political': 906, 'extremely': 907, 'maybe': 908, 'hit': 909, 'anyone': 910, 'ideas': 911, 'opportunity': 912, 'advantage': 913, 'promise': 914, 'usually': 915, 'satisfied': 916, 'expect': 917, 'personal': 918, 'works': 919, 'drive': 920, 'mentioned': 921, 'fond': 922, 'beauty': 923, 'modern': 924, 'beneath': 925, 'learned': 926, 'reading': 927, 'marry': 928, 'loved': 929, 'river': 930, 'step': 931, 'knowing': 932, 'scarcely': 933, 'final': 934, 'key': 935, 'archer': 936, 'places': 937, 'safe': 938, 'style': 939, 'needed': 940, 'forced': 941, 'playing': 942, 'spite': 943, 'books': 944, 'result': 945, 'guess': 946, 'sharp': 947, 'dog': 948, 'entire': 949, 'curious': 950, 'month': 951, 'observed': 952, 'individual': 953, 'creature': 954, 'engagement': 955, 'pleasant': 956, 'lot': 957, 'influence': 958, 'hole': 959, 'quarter': 960, 'born': 961, 'below': 962, 'lead': 963, 'lower': 964, 'forth': 965, 'mouse': 966, 'whaling': 967, 'food': 968, 'terms': 969, 'hurry': 970, 'occasion': 971, 'surprised': 972, 'liked': 973, 'sign': 974, 'honest': 975, 'superior': 976, 'famous': 977, 'agreeable': 978, 'building': 979, 'duty': 980, 'sides': 981, 'level': 982, 'class': 983, 'consequence': 984, 'various': 985, 'french': 986, 'clothes': 987, 'drink': 988, 'size': 989, 'pulled': 990, 'higher': 991, 'market': 992, 'season': 993, 'cottage': 994, 'angry': 995, 'quickly': 996, 'touch': 997, 'east': 998, 'iron': 999, 'broad': 1000, 'fit': 1001, 'comfortable': 1002, 'miss': 1003, 'plain': 1004, 'convinced': 1005, 'watched': 1006, 'nations': 1007, 'square': 1008, 'growing': 1009, 'died': 1010, 'direction': 1011, 'interesting': 1012, 'vast': 1013, 'allowed': 1014, 'waited': 1015, 'thin': 1016, 'hoped': 1017, 'spot': 1018, 'tail': 1019, 'park': 1020, 'spoken': 1021, 'buy': 1022, 'cook': 1023, 'steps': 1024, 'showed': 1025, 'played': 1026, 'aware': 1027, 'somehow': 1028, 'gun': 1029, 'instantly': 1030, 'unless': 1031, 'rain': 1032, 'grand': 1033, 'members': 1034, 'according': 1035, 'afternoon': 1036, 'dress': 1037, 'neck': 1038, 'join': 1039, 'charge': 1040, 'song': 1041, 'smiled': 1042, 'watching': 1043, 'promised': 1044, 'justice': 1045, 'southern': 1046, 'changed': 1047, 'laid': 1048, 'break': 1049, 'reach': 1050, 'main': 1051, 'pull': 1052, 'fifty': 1053, 'equally': 1054, 'curiosity': 1055, 'brandon': 1056, 'march': 1057, 'share': 1058, 'catch': 1059, 'shut': 1060, 'cousin': 1061, 'study': 1062, 'simply': 1063, 'moving': 1064, 'kitchen': 1065, 'beside': 1066, 'closed': 1067, 'sky': 1068, 'remembered': 1069, 'heads': 1070, 'rate': 1071, 'brown': 1072, 'confidence': 1073, 'otherwise': 1074, 'circumstance': 1075, 'club': 1076, 'agreed': 1077, 'winter': 1078, 'kindness': 1079, 'hung': 1080, 'spread': 1081, 'soft': 1082, 'declared': 1083, 'concern': 1084, 'bow': 1085, 'youth': 1086, 'ways': 1087, 'lives': 1088, 'persons': 1089, 'emmas': 1090, 'countenance': 1091, 'remain': 1092, 'supper': 1093, 'killed': 1094, 'raised': 1095, 'lets': 1096, 'twice': 1097, 'temper': 1098, 'perfect': 1099, 'scene': 1100, 'laughing': 1101, 'information': 1102, 'america': 1103, 'anxious': 1104, 'shook': 1105, 'broke': 1106, 'vain': 1107, 'telling': 1108, 'questions': 1109, 'difficult': 1110, 'seat': 1111, 'police': 1112, 'laugh': 1113, 'washington': 1114, 'queen': 1115, 'beat': 1116, 'attempt': 1117, 'report': 1118, 'cost': 1119, 'evil': 1120, 'doctor': 1121, 'county': 1122, 'nine': 1123, 'hopes': 1124, 'mad': 1125, 'nose': 1126, 'forest': 1127, 'major': 1128, 'arrived': 1129, 'offer': 1130, 'delight': 1131, 'desire': 1132, 'luck': 1133, 'legs': 1134, 'waters': 1135, 'understood': 1136, 'shop': 1137, 'feed': 1138, 'elliots': 1139, 'tired': 1140, 'ahead': 1141, 'circle': 1142, 'passing': 1143, 'peace': 1144, 'match': 1145, 'pocket': 1146, 'learn': 1147, 'teeth': 1148, 'mere': 1149, 'pieces': 1150, 'loss': 1151, 'whenever': 1152, 'required': 1153, 'development': 1154, 'fight': 1155, 'grow': 1156, 'happen': 1157, 'opening': 1158, 'cry': 1159, 'smiling': 1160, 'escape': 1161, 'battle': 1162, 'altogether': 1163, 'attorney': 1164, 'local': 1165, 'carefully': 1166, 'eager': 1167, 'formed': 1168, 'event': 1169, 'attachment': 1170, 'performance': 1171, 'tears': 1172, 'post': 1173, 'joined': 1174, 'rolled': 1175, 'tall': 1176, 'drawn': 1177, 'design': 1178, 'earlier': 1179, 'cross': 1180, 'chair': 1181, 'coat': 1182, 'hotel': 1183, 'measure': 1184, 'involved': 1185, 'die': 1186, 'thrown': 1187, 'busy': 1188, 'concerned': 1189, 'acquainted': 1190, 'due': 1191, 'delighted': 1192, 'military': 1193, 'stage': 1194, 'anybody': 1195, 'voyage': 1196, 'pity': 1197, 'sail': 1198, 'somebody': 1199, 'breath': 1200, 'listen': 1201, 'rooms': 1202, 'satisfaction': 1203, 'highly': 1204, 'price': 1205, 'wonderful': 1206, 'uncle': 1207, 'judgment': 1208, 'mast': 1209, 'offered': 1210, 'frightened': 1211, 'weight': 1212, 'stairs': 1213, 'fat': 1214, 'island': 1215, 'proved': 1216, 'difficulty': 1217, 'takes': 1218, 'students': 1219, 'community': 1220, 'produced': 1221, 'lips': 1222, 'burst': 1223, 'pointed': 1224, 'thick': 1225, 'cabin': 1226, 'problems': 1227, 'mistaken': 1228, 'dancing': 1229, 'forgotten': 1230, 'threw': 1231, 'color': 1232, 'surface': 1233, 'mistress': 1234, 'passage': 1235, 'literature': 1236, 'favour': 1237, 'ferrars': 1238, 'snow': 1239, 'bread': 1240, 'covered': 1241, 'stone': 1242, 'control': 1243, 'mistake': 1244, 'proud': 1245, 'forty': 1246, 'pale': 1247, 'similar': 1248, 'possibly': 1249, 'presently': 1250, 'considerable': 1251, 'committee': 1252, 'union': 1253, 'eliot': 1254, 'hell': 1255, 'named': 1256, 'companions': 1257, 'sing': 1258, 'maid': 1259, 'browns': 1260, 'kill': 1261, 'grown': 1262, 'bag': 1263, 'rise': 1264, 'names': 1265, 'gives': 1266, 'spend': 1267, 'latter': 1268, 'parts': 1269, 'tea': 1270, 'civil': 1271, 'brothers': 1272, 'shoulder': 1273, 'oclock': 1274, 'previous': 1275, 'mention': 1276, 'draw': 1277, 'somewhat': 1278, 'twelve': 1279, 'space': 1280, 'resolved': 1281, 'basket': 1282, 'support': 1283, 'ocean': 1284, 'calm': 1285, 'edge': 1286, 'prepared': 1287, 'leaves': 1288, 'yours': 1289, 'baby': 1290, 'houses': 1291, 'enter': 1292, 'press': 1293, 'immediate': 1294, 'regular': 1295, 'aunt': 1296, 'firm': 1297, 'jazz': 1298, 'dry': 1299, 'quietly': 1300, 'bell': 1301, 'putting': 1302, 'central': 1303, 'frequently': 1304, 'welcome': 1305, 'evidence': 1306, 'finding': 1307, 'memory': 1308, 'glance': 1309, 'events': 1310, 'listened': 1311, 'charming': 1312, 'servants': 1313, 'resolution': 1314, 'negro': 1315, 'stock': 1316, 'faces': 1317, 'lie': 1318, 'peculiar': 1319, 'inch': 1320, 'prevent': 1321, 'interested': 1322, 'crowd': 1323, 'wise': 1324, 'provide': 1325, 'moral': 1326, 'race': 1327, 'elizabeth': 1328, 'favourite': 1329, 'built': 1330, 'mighty': 1331, 'aside': 1332, 'movement': 1333, 'considering': 1334, 'points': 1335, 'parties': 1336, 'fingers': 1337, 'recent': 1338, 'bridge': 1339, 'audience': 1340, 'pounds': 1341, 'seas': 1342, 'friendship': 1343, 'picked': 1344, 'heaven': 1345, 'cast': 1346, 'mile': 1347, 'carrying': 1348, 'holding': 1349, 'attack': 1350, 'calling': 1351, 'alive': 1352, 'opposite': 1353, 'larger': 1354, 'decision': 1355, 'yellow': 1356, 'schools': 1357, 'delightful': 1358, 'behaviour': 1359, 'needs': 1360, 'loose': 1361, 'pride': 1362, 'orders': 1363, 'ring': 1364, 'constant': 1365, 'affair': 1366, 'bottle': 1367, 'sunday': 1368, 'increased': 1369, 'effort': 1370, 'total': 1371, 'material': 1372, 'musical': 1373, 'reply': 1374, 'cool': 1375, 'quality': 1376, 'servant': 1377, 'laws': 1378, 'thinks': 1379, 'sensible': 1380, 'nantucket': 1381, 'skin': 1382, 'touched': 1383, 'taught': 1384, 'bank': 1385, 'discovered': 1386, 'apparently': 1387, 'truly': 1388, 'somewhere': 1389, 'western': 1390, 'including': 1391, 'rule': 1392, 'fully': 1393, 'bar': 1394, 'shoes': 1395, 'terrible': 1396, 'heat': 1397, 'using': 1398, 'save': 1399, 'sad': 1400, 'trust': 1401, 'explained': 1402, 'receive': 1403, 'hospital': 1404, 'science': 1405, 'speech': 1406, 'whilst': 1407, 'flask': 1408, 'helped': 1409, 'army': 1410, 'drove': 1411, 'nation': 1412, 'ordered': 1413, 'million': 1414, 'add': 1415, 'clean': 1416, 'equipment': 1417, 'station': 1418, 'noise': 1419, 'pushed': 1420, 'announced': 1421, 'leading': 1422, 'approach': 1423, 'coast': 1424, 'flowers': 1425, 'surely': 1426, 'officers': 1427, 'instance': 1428, 'europe': 1429, 'daily': 1430, 'invitation': 1431, 'persuaded': 1432, 'amongst': 1433, 'available': 1434, 'bought': 1435, 'wore': 1436, 'importance': 1437, 'sooner': 1438, 'stranger': 1439, 'original': 1440, 'beg': 1441, 'success': 1442, 'rising': 1443, 'double': 1444, 'doors': 1445, 'crown': 1446, 'faith': 1447, 'praise': 1448, 'tax': 1449, 'apartment': 1450, 'naturally': 1451, 'companion': 1452, 'drop': 1453, 'rock': 1454, 'yards': 1455, 'knife': 1456, 'choice': 1457, 'returning': 1458, 'shed': 1459, 'assured': 1460, 'served': 1461, 'cases': 1462, 'sales': 1463, 'lovely': 1464, 'odd': 1465, 'suffered': 1466, 'attend': 1467, 'member': 1468, 'asking': 1469, 'plenty': 1470, 'lose': 1471, 'mass': 1472, 'windows': 1473, 'advice': 1474, 'matters': 1475, 'type': 1476, 'wants': 1477, 'nevertheless': 1478, 'separate': 1479, 'streets': 1480, 'jury': 1481, 'range': 1482, 'ease': 1483, 'cars': 1484, 'monday': 1485, 'interrupted': 1486, 'excuse': 1487, 'royal': 1488, 'smiths': 1489, 'grass': 1490, 'fool': 1491, 'empty': 1492, 'valley': 1493, 'begun': 1494, 'turns': 1495, 'existence': 1496, 'distant': 1497, 'shore': 1498, 'explain': 1499, 'increase': 1500, 'imagination': 1501, 'farm': 1502, 'federal': 1503, 'credit': 1504, 'reasons': 1505, 'afford': 1506, 'ashamed': 1507, 'chest': 1508, 'yard': 1509, 'gray': 1510, 'careful': 1511, 'blind': 1512, 'supply': 1513, 'addition': 1514, 'steady': 1515, 'lying': 1516, 'headed': 1517, 'avoid': 1518, 'forces': 1519, 'coffee': 1520, 'anywhere': 1521, 'salt': 1522, 'strike': 1523, 'language': 1524, 'slightly': 1525, 'bone': 1526, 'hurried': 1527, 'ears': 1528, 'stayed': 1529, 'informed': 1530, 'removed': 1531, 'address': 1532, 'everyone': 1533, 'ancient': 1534, 'volume': 1535, 'property': 1536, 'reasonable': 1537, 'throw': 1538, 'arrival': 1539, 'presented': 1540, 'speed': 1541, 'check': 1542, 'daughters': 1543, 'staff': 1544, 'extraordinary': 1545, 'disposed': 1546, 'youd': 1547, 'shape': 1548, 'pair': 1549, 'sick': 1550, 'willing': 1551, 'birds': 1552, 'message': 1553, 'listening': 1554, 'record': 1555, 'marked': 1556, 'creatures': 1557, 'occurred': 1558, 'expressed': 1559, 'whispered': 1560, 'someone': 1561, 'employed': 1562, 'suit': 1563, 'trial': 1564, 'direct': 1565, 'refused': 1566, 'gay': 1567, 'relations': 1568, 'secretary': 1569, 'wishes': 1570, 'gratitude': 1571, 'shoulders': 1572, 'condition': 1573, 'sounds': 1574, 'relief': 1575, 'pick': 1576, 'observe': 1577, 'moreover': 1578, 'proof': 1579, 'singing': 1580, 'silver': 1581, 'ended': 1582, 'capable': 1583, 'administration': 1584, 'continue': 1585, 'loud': 1586, 'expression': 1587, 'eagerly': 1588, 'throat': 1589, 'bound': 1590, 'shown': 1591, 'stands': 1592, 'recently': 1593, 'entrance': 1594, 'hers': 1595, 'setting': 1596, 'unknown': 1597, 'enemy': 1598, 'beach': 1599, 'areas': 1600, 'successful': 1601, 'liberty': 1602, 'distress': 1603, 'cheerful': 1604, 'plans': 1605, 'gate': 1606, 'department': 1607, 'nearer': 1608, 'presence': 1609, 'powers': 1610, 'eating': 1611, 'dream': 1612, 'suggested': 1613, 'failed': 1614, 'absolutely': 1615, 'guests': 1616, 'henry': 1617, 'economic': 1618, 'list': 1619, 'highest': 1620, 'desired': 1621, 'hurt': 1622, 'tom': 1623, 'nights': 1624, 'flew': 1625, 'serve': 1626, 'attached': 1627, 'wondered': 1628, 'older': 1629, 'manager': 1630, 'slight': 1631, 'solid': 1632, 'consciousness': 1633, 'upper': 1634, 'base': 1635, 'pictures': 1636, 'confusion': 1637, 'series': 1638, 'poet': 1639, 'driving': 1640, 'seated': 1641, 'bringing': 1642, 'bench': 1643, 'religious': 1644, 'income': 1645, 'conscious': 1646, 'darkness': 1647, 'blow': 1648, 'signs': 1649, 'accept': 1650, 'brain': 1651, 'amount': 1652, 'depend': 1653, 'pressed': 1654, 'wanting': 1655, 'wet': 1656, 'tiny': 1657, 'golden': 1658, 'accepted': 1659, 'stern': 1660, 'voices': 1661, 'begged': 1662, 'provided': 1663, 'produce': 1664, 'grant': 1665, 'remains': 1666, 'harpoon': 1667, 'slow': 1668, 'anger': 1669, 'buildings': 1670, 'camp': 1671, 'trade': 1672, 'indian': 1673, 'dressed': 1674, 'hanging': 1675, 'foreign': 1676, 'numbers': 1677, 'narrow': 1678, 'contrary': 1679, 'officer': 1680, 'gods': 1681, 'seek': 1682, 'intended': 1683, 'proposed': 1684, 'jumped': 1685, 'hint': 1686, 'useful': 1687, 'disposition': 1688, 'industry': 1689, 'saturday': 1690, 'prize': 1691, 'christmas': 1692, 'smallest': 1693, 'extreme': 1694, 'exceedingly': 1695, 'lucky': 1696, 'possibility': 1697, 'treated': 1698, 'motion': 1699, 'cover': 1700, 'handle': 1701, 'ear': 1702, 'build': 1703, 'cutting': 1704, 'issue': 1705, 'properly': 1706, 'enjoyment': 1707, 'ben': 1708, 'literary': 1709, 'fault': 1710, 'cent': 1711, 'research': 1712, 'international': 1713, 'generous': 1714, 'abbey': 1715, 'clever': 1716, 'mariannes': 1717, 'sell': 1718, 'features': 1719, 'savage': 1720, 'shouted': 1721, 'worst': 1722, 'noticed': 1723, 'murder': 1724, 'affairs': 1725, 'fashion': 1726, 'rope': 1727, 'ourselves': 1728, 'countries': 1729, 'progress': 1730, 'liberal': 1731, 'aid': 1732, 'democratic': 1733, 'fears': 1734, 'mercer': 1735, 'suffering': 1736, 'plainly': 1737, 'lion': 1738, 'uppercross': 1739, 'hills': 1740, 'crossed': 1741, 'walls': 1742, 'smoke': 1743, 'pardon': 1744, 'huge': 1745, 'prove': 1746, 'keeping': 1747, 'dogs': 1748, 'noble': 1749, 'unhappy': 1750, 'passion': 1751, 'introduced': 1752, 'ivory': 1753, 'stories': 1754, 'sugar': 1755, 'kings': 1756, 'principle': 1757, 'necessity': 1758, 'amiable': 1759, 'conscience': 1760, 'consideration': 1761, 'natured': 1762, 'precious': 1763, 'sought': 1764, 'intelligence': 1765, 'tongue': 1766, 'tied': 1767, 'foolish': 1768, 'imagined': 1769, 'forgot': 1770, 'devil': 1771, 'friendly': 1772, 'sold': 1773, 'concerning': 1774, 'pressure': 1775, 'castle': 1776, 'steel': 1777, 'rabbit': 1778, 'won': 1779, 'flying': 1780, 'sex': 1781, 'artist': 1782, 'german': 1783, 'craft': 1784, 'jaw': 1785, 'throughout': 1786, 'lad': 1787, 'junior': 1788, 'americans': 1789, 'described': 1790, 'prince': 1791, 'developed': 1792, 'plays': 1793, 'secure': 1794, 'queer': 1795, 'spare': 1796, 'finger': 1797, 'flat': 1798, 'rear': 1799, 'frame': 1800, 'harm': 1801, 'confess': 1802, 'popular': 1803, 'express': 1804, 'seldom': 1805, 'conviction': 1806, 'chosen': 1807, 'claims': 1808, 'project': 1809, 'earnest': 1810, 'statement': 1811, 'wooden': 1812, 'fly': 1813, 'fourth': 1814, 'attitude': 1815, 'mate': 1816, 'cousins': 1817, 'parents': 1818, 'assistance': 1819, 'student': 1820, 'difficulties': 1821, 'opinions': 1822, 'included': 1823, 'grave': 1824, 'kellynch': 1825, 'figures': 1826, 'hate': 1827, 'swung': 1828, 'warmth': 1829, 'gained': 1830, 'showing': 1831, 'chase': 1832, 'disappointed': 1833, 'forms': 1834, 'physical': 1835, 'violent': 1836, 'thoroughly': 1837, 'fields': 1838, 'funny': 1839, 'related': 1840, 'tuesday': 1841, 'technical': 1842, 'estate': 1843, 'concluded': 1844, 'labor': 1845, 'plant': 1846, 'saved': 1847, 'active': 1848, 'christian': 1849, 'lamb': 1850, 'fairly': 1851, 'becomes': 1852, 'dreadful': 1853, 'admiration': 1854, 'stared': 1855, 'flesh': 1856, 'absence': 1857, 'regret': 1858, 'clearly': 1859, 'authority': 1860, 'impression': 1861, 'dollars': 1862, 'dangerous': 1863, 'regarded': 1864, 'scheme': 1865, 'fifteen': 1866, 'signal': 1867, 'agree': 1868, 'admitted': 1869, 'policy': 1870, 'poetry': 1871, 'enjoy': 1872, 'occupied': 1873, 'invited': 1874, 'collection': 1875, 'severe': 1876, 'exercise': 1877, 'anxiety': 1878, 'sailors': 1879, 'knees': 1880, 'bones': 1881, 'drinking': 1882, 'hero': 1883, 'succeeded': 1884, 'wholly': 1885, 'process': 1886, 'chose': 1887, 'aspect': 1888, 'songs': 1889, 'train': 1890, 'ends': 1891, 'swimming': 1892, 'grounds': 1893, 'sailor': 1894, 'sending': 1895, 'impatient': 1896, 'leaders': 1897, 'calls': 1898, 'valuable': 1899, 'pattern': 1900, 'concert': 1901, 'observation': 1902, 'lifted': 1903, 'shes': 1904, 'bent': 1905, 'ride': 1906, 'rolling': 1907, 'fill': 1908, 'hearts': 1909, 'waves': 1910, 'admit': 1911, 'softly': 1912, 'gentle': 1913, 'indifference': 1914, 'choose': 1915, 'fun': 1916, 'date': 1917, 'fruit': 1918, 'worship': 1919, 'principal': 1920, 'fate': 1921, 'divided': 1922, 'striking': 1923, 'writers': 1924, 'milk': 1925, 'declare': 1926, 'lively': 1927, 'dignity': 1928, 'landlord': 1929, 'habit': 1930, 'lyme': 1931, 'ordinary': 1932, 'asleep': 1933, 'leaned': 1934, 'rifle': 1935, 'suspicion': 1936, 'nodded': 1937, 'stepped': 1938, 'search': 1939, 'dust': 1940, 'despite': 1941, 'pipe': 1942, 'receiving': 1943, 'block': 1944, 'journey': 1945, 'path': 1946, 'lately': 1947, 'texas': 1948, 'rapidly': 1949, 'medical': 1950, 'greatly': 1951, 'objects': 1952, 'fox': 1953, 'views': 1954, 'vessel': 1955, 'utmost': 1956, 'melancholy': 1957, 'fishery': 1958, 'studied': 1959, 'june': 1960, 'leaning': 1961, 'faced': 1962, 'grateful': 1963, 'handed': 1964, 'safety': 1965, 'meanwhile': 1966, 'uniform': 1967, 'kid': 1968, 'pause': 1969, 'operation': 1970, 'hed': 1971, 'suspect': 1972, 'becoming': 1973, 'plants': 1974, 'row': 1975, 'chicago': 1976, 'caused': 1977, 'applied': 1978, 'tells': 1979, 'additional': 1980, 'notion': 1981, 'hence': 1982, 'reality': 1983, 'touching': 1984, 'misery': 1985, 'disappointment': 1986, 'closer': 1987, 'sleeping': 1988, 'paused': 1989, 'defense': 1990, 'brief': 1991, 'gradually': 1992, 'height': 1993, 'deeply': 1994, 'teach': 1995, 'mountain': 1996, 'indifferent': 1997, 'shooting': 1998, 'association': 1999, 'terror': 2000, 'count': 2001, 'method': 2002, 'visible': 2003, 'freedom': 2004, 'inches': 2005, 'religion': 2006, 'enjoyed': 2007, 'election': 2008, 'term': 2009, 'attended': 2010, 'affected': 2011, 'soldiers': 2012, 'settle': 2013, 'elegant': 2014, 'pains': 2015, 'france': 2016, 'reflection': 2017, 'ice': 2018, 'neighbours': 2019, 'jackal': 2020, 'connected': 2021, 'activity': 2022, 'raise': 2023, 'driven': 2024, 'papers': 2025, 'truck': 2026, 'desk': 2027, 'forehead': 2028, 'advance': 2029, 'perceived': 2030, 'possession': 2031, 'younger': 2032, 'rights': 2033, 'roll': 2034, 'midst': 2035, 'hardy': 2036, 'sink': 2037, 'turtle': 2038, 'forgive': 2039, 'production': 2040, 'minds': 2041, 'sufficient': 2042, 'precisely': 2043, 'chimney': 2044, 'proceeded': 2045, 'belong': 2046, 'costs': 2047, 'basic': 2048, 'non': 2049, 'library': 2050, 'pleasing': 2051, 'likewise': 2052, 'spout': 2053, 'families': 2054, 'stretched': 2055, 'hungry': 2056, 'mock': 2057, 'fallen': 2058, 'wake': 2059, 'firmly': 2060, 'description': 2061, 'delay': 2062, 'grace': 2063, 'familiar': 2064, 'league': 2065, 'storm': 2066, 'dull': 2067, 'accident': 2068, 'apparent': 2069, 'safely': 2070, 'effects': 2071, 'security': 2072, 'native': 2073, 'emotion': 2074, 'aloft': 2075, 'friday': 2076, 'organization': 2077, 'explanation': 2078, 'score': 2079, 'bid': 2080, 'inn': 2081, 'gets': 2082, 'standard': 2083, 'bows': 2084, 'furniture': 2085, 'profession': 2086, 'desirable': 2087, 'theory': 2088, 'animal': 2089, 'guard': 2090, 'pink': 2091, 'hunting': 2092, 'sounded': 2093, 'painful': 2094, 'obvious': 2095, 'alarm': 2096, 'powerful': 2097, 'unable': 2098, 'directed': 2099, 'smooth': 2100, 'feels': 2101, 'suffer': 2102, 'gathered': 2103, 'stuff': 2104, 'staying': 2105, 'stick': 2106, 'instrument': 2107, 'basis': 2108, 'designed': 2109, 'respectable': 2110, 'services': 2111, 'management': 2112, 'source': 2113, 'subjects': 2114, 'acting': 2115, 'changes': 2116, 'lies': 2117, 'habits': 2118, 'jacket': 2119, 'dozen': 2120, 'push': 2121, 'team': 2122, 'lake': 2123, 'director': 2124, 'belonged': 2125, 'occasionally': 2126, 'closely': 2127, 'professional': 2128, 'pulling': 2129, 'section': 2130, 'seriously': 2131, 'orchestra': 2132, 'expense': 2133, 'leader': 2134, 'variety': 2135, 'established': 2136, 'mates': 2137, 'practice': 2138, 'jet': 2139, 'independence': 2140, 'values': 2141, 'captains': 2142, 'admiral': 2143, 'missed': 2144, 'moon': 2145, 'drunk': 2146, 'clouds': 2147, 'tossed': 2148, 'starting': 2149, 'excited': 2150, 'limited': 2151, 'visited': 2152, 'unusual': 2153, 'astonishment': 2154, 'wear': 2155, 'card': 2156, 'worlds': 2157, 'horn': 2158, 'image': 2159, 'shake': 2160, 'efforts': 2161, 'shame': 2162, 'remarkable': 2163, 'obviously': 2164, 'wretched': 2165, 'recommended': 2166, 'council': 2167, 'accounts': 2168, 'district': 2169, 'reported': 2170, 'cape': 2171, 'runs': 2172, 'lane': 2173, 'historical': 2174, 'unfortunate': 2175, 'sharks': 2176, 'recollect': 2177, 'reaching': 2178, 'courage': 2179, 'shadow': 2180, 'bitter': 2181, 'sigh': 2182, 'radio': 2183, 'lights': 2184, 'remaining': 2185, 'escaped': 2186, 'locked': 2187, 'growth': 2188, 'delicate': 2189, 'smart': 2190, 'expectation': 2191, 'penny': 2192, 'campaign': 2193, 'bore': 2194, 'wine': 2195, 'deserve': 2196, 'sons': 2197, 'facts': 2198, 'content': 2199, 'essential': 2200, 'pointing': 2201, 'dallas': 2202, 'site': 2203, 'connection': 2204, 'gain': 2205, 'average': 2206, 'victory': 2207, 'principles': 2208, 'treatment': 2209, 'venture': 2210, 'charm': 2211, 'nonsense': 2212, 'arranged': 2213, 'smaller': 2214, 'bedroom': 2215, 'slipped': 2216, 'wagon': 2217, 'seized': 2218, 'fighting': 2219, 'swift': 2220, 'tender': 2221, 'annual': 2222, 'lack': 2223, 'bills': 2224, 'hidden': 2225, 'disappeared': 2226, 'worthy': 2227, 'agitation': 2228, 'career': 2229, 'arts': 2230, 'patient': 2231, 'newspaper': 2232, 'rank': 2233, 'intervals': 2234, 'instances': 2235, 'fisher': 2236, 'annes': 2237, 'materials': 2238, 'enormous': 2239, 'happily': 2240, 'sang': 2241, 'continually': 2242, 'fortunate': 2243, 'discovery': 2244, 'carpenter': 2245, 'coffin': 2246, 'rid': 2247, 'awake': 2248, 'intention': 2249, 'gently': 2250, 'pace': 2251, 'cap': 2252, 'brave': 2253, 'interior': 2254, 'string': 2255, 'wheel': 2256, 'dared': 2257, 'fail': 2258, 'rough': 2259, 'rules': 2260, 'claim': 2261, 'plane': 2262, 'trip': 2263, 'previously': 2264, 'midnight': 2265, 'telephone': 2266, 'benefit': 2267, 'cooperation': 2268, 'leadership': 2269, 'attending': 2270, 'inclination': 2271, 'merit': 2272, 'win': 2273, 'rome': 2274, 'abroad': 2275, 'intellectual': 2276, 'shows': 2277, 'numerous': 2278, 'steele': 2279, 'otter': 2280, 'pigeon': 2281, 'obliging': 2282, 'refuse': 2283, 'bold': 2284, 'flight': 2285, 'realized': 2286, 'largest': 2287, 'indicated': 2288, 'bodies': 2289, 'apart': 2290, 'pure': 2291, 'thanks': 2292, 'wearing': 2293, 'climbed': 2294, 'demand': 2295, 'woods': 2296, 'belief': 2297, 'substance': 2298, 'test': 2299, 'pot': 2300, 'cup': 2301, 'finish': 2302, 'virginia': 2303, 'games': 2304, 'cat': 2305, 'kick': 2306, 'november': 2307, 'brow': 2308, 'conference': 2309, 'italian': 2310, 'intimate': 2311, 'domestic': 2312, 'deeper': 2313, 'shade': 2314, 'chairman': 2315, 'constitution': 2316, 'independent': 2317, 'reference': 2318, 'brilliant': 2319, 'mantle': 2320, 'breaking': 2321, 'compared': 2322, 'collected': 2323, 'pike': 2324, 'communication': 2325, 'contrast': 2326, 'colour': 2327, 'struggle': 2328, 'dirty': 2329, 'approached': 2330, 'burning': 2331, 'parted': 2332, 'heavily': 2333, 'wound': 2334, 'band': 2335, 'bare': 2336, 'humor': 2337, 'phone': 2338, 'comparison': 2339, 'dislike': 2340, 'neat': 2341, 'dining': 2342, 'elegance': 2343, 'supported': 2344, 'hunter': 2345, 'store': 2346, 'palace': 2347, 'hastily': 2348, 'jump': 2349, 'evident': 2350, 'admired': 2351, 'mystery': 2352, 'suspected': 2353, 'film': 2354, 'meat': 2355, 'vice': 2356, 'actions': 2357, 'employment': 2358, 'persuade': 2359, 'soviet': 2360, 'remove': 2361, 'deny': 2362, 'prospect': 2363, 'triumph': 2364, 'particulars': 2365, 'butter': 2366, 'readily': 2367, 'species': 2368, 'bless': 2369, 'neighbourhood': 2370, 'crazy': 2371, 'favor': 2372, 'darted': 2373, 'roof': 2374, 'forming': 2375, 'unlike': 2376, 'lance': 2377, 'waste': 2378, 'patience': 2379, 'falling': 2380, 'grove': 2381, 'headquarters': 2382, 'worry': 2383, 'blame': 2384, 'shock': 2385, 'role': 2386, 'activities': 2387, 'painted': 2388, 'detail': 2389, 'deserved': 2390, 'holy': 2391, 'marine': 2392, 'teacher': 2393, 'distinguished': 2394, 'advanced': 2395, 'governor': 2396, 'vote': 2397, 'planning': 2398, 'obtained': 2399, 'proceed': 2400, 'latin': 2401, 'thousands': 2402, 'training': 2403, 'argument': 2404, 'overcome': 2405, 'tradition': 2406, 'silly': 2407, 'nightingale': 2408, 'vanity': 2409, 'affectionate': 2410, 'recollection': 2411, 'hen': 2412, 'humour': 2413, 'wishing': 2414, 'gryphon': 2415, 'alike': 2416, 'wondering': 2417, 'slept': 2418, 'blanket': 2419, 'stars': 2420, 'cattle': 2421, 'mounted': 2422, 'scenes': 2423, 'coach': 2424, 'knee': 2425, 'attempted': 2426, 'mud': 2427, 'bearing': 2428, 'positive': 2429, 'energy': 2430, 'innocent': 2431, 'shortly': 2432, 'thunder': 2433, 'determine': 2434, 'horror': 2435, 'aircraft': 2436, 'discover': 2437, 'model': 2438, 'wedding': 2439, 'stronger': 2440, 'responsibility': 2441, 'bay': 2442, 'nervous': 2443, 'birth': 2444, 'traffic': 2445, 'division': 2446, 'published': 2447, 'begins': 2448, 'improved': 2449, 'player': 2450, 'birthday': 2451, 'stones': 2452, 'miserable': 2453, 'interval': 2454, 'perceive': 2455, 'blacky': 2456, 'worn': 2457, 'dying': 2458, 'temple': 2459, 'startled': 2460, 'recovered': 2461, 'increasing': 2462, 'stroke': 2463, 'constantly': 2464, 'extra': 2465, 'anyway': 2466, 'idle': 2467, 'detective': 2468, 'owners': 2469, 'vision': 2470, 'task': 2471, 'holes': 2472, 'joke': 2473, 'painting': 2474, 'bird': 2475, 'fishing': 2476, 'china': 2477, 'congress': 2478, 'require': 2479, 'proposal': 2480, 'commission': 2481, 'april': 2482, 'request': 2483, 'widow': 2484, 'chiefly': 2485, 'guinea': 2486, 'eldest': 2487, 'emperor': 2488, 'fortnight': 2489, 'marrying': 2490, 'approbation': 2491, 'burned': 2492, 'created': 2493, 'stable': 2494, 'lighted': 2495, 'confused': 2496, 'methods': 2497, 'onto': 2498, 'smell': 2499, 'symbol': 2500, 'mission': 2501, 'berries': 2502, 'stupid': 2503, 'amusement': 2504, 'beef': 2505, 'september': 2506, 'writer': 2507, 'effective': 2508, 'lock': 2509, 'trembling': 2510, 'primary': 2511, 'finds': 2512, 'reward': 2513, 'commanded': 2514, 'cunning': 2515, 'cloth': 2516, 'occur': 2517, 'earnestly': 2518, 'accompanied': 2519, 'ate': 2520, 'sheet': 2521, 'recommend': 2522, 'companies': 2523, 'elements': 2524, 'sailing': 2525, 'status': 2526, 'retired': 2527, 'warren': 2528, 'appears': 2529, 'include': 2530, 'observing': 2531, 'clock': 2532, 'delivered': 2533, 'opera': 2534, 'greek': 2535, 'piano': 2536, 'extent': 2537, 'leisure': 2538, 'universe': 2539, 'cruel': 2540, 'hearted': 2541, 'hearst': 2542, 'churchills': 2543, 'attentions': 2544, 'stream': 2545, 'faint': 2546, 'sighed': 2547, 'cleared': 2548, 'wherever': 2549, 'mountains': 2550, 'decide': 2551, 'title': 2552, 'absent': 2553, 'cow': 2554, 'noon': 2555, 'frequent': 2556, 'completed': 2557, 'strongly': 2558, 'insisted': 2559, 'giant': 2560, 'partly': 2561, 'stomach': 2562, 'purse': 2563, 'current': 2564, 'discussion': 2565, 'secured': 2566, 'missing': 2567, 'correct': 2568, 'astonished': 2569, 'plus': 2570, 'session': 2571, 'arrangement': 2572, 'womans': 2573, 'page': 2574, 'happens': 2575, 'mortal': 2576, 'remark': 2577, 'risk': 2578, 'characters': 2579, 'encouragement': 2580, 'unit': 2581, 'nuclear': 2582, 'critical': 2583, 'objection': 2584, 'pitch': 2585, 'goodness': 2586, 'wright': 2587, 'drawings': 2588, 'judged': 2589, 'scientific': 2590, 'revolution': 2591, 'eagerness': 2592, 'cole': 2593, 'fanny': 2594, 'compliment': 2595, 'somers': 2596, 'sailed': 2597, 'margery': 2598, 'torn': 2599, 'navy': 2600, 'evidently': 2601, 'weak': 2602, 'counter': 2603, 'crowded': 2604, 'prevented': 2605, 'virtue': 2606, 'comprehend': 2607, 'atmosphere': 2608, 'intimacy': 2609, 'mood': 2610, 'lightning': 2611, 'author': 2612, 'notes': 2613, 'armed': 2614, 'glory': 2615, 'pole': 2616, 'feared': 2617, 'bride': 2618, 'insurance': 2619, 'conclusion': 2620, 'corn': 2621, 'illness': 2622, 'specific': 2623, 'assist': 2624, 'formerly': 2625, 'swim': 2626, 'offering': 2627, 'inclined': 2628, 'strangers': 2629, 'motive': 2630, 'wit': 2631, 'puzzled': 2632, 'porch': 2633, 'stuck': 2634, 'lamp': 2635, 'rushed': 2636, 'animals': 2637, 'nearest': 2638, 'rush': 2639, 'hoping': 2640, 'despair': 2641, 'knocked': 2642, 'soil': 2643, 'dread': 2644, 'flow': 2645, 'pretend': 2646, 'lesson': 2647, 'easier': 2648, 'official': 2649, 'everywhere': 2650, 'pacific': 2651, 'destroyed': 2652, 'agent': 2653, 'paying': 2654, 'elsewhere': 2655, 'construction': 2656, 'meantime': 2657, 'legal': 2658, 'nurse': 2659, 'communist': 2660, 'seeking': 2661, 'maurice': 2662, 'bowed': 2663, 'campbell': 2664, 'qualities': 2665, 'russian': 2666, 'witness': 2667, 'totally': 2668, 'wealth': 2669, 'concept': 2670, 'inquiry': 2671, 'sorrow': 2672, 'exertion': 2673, 'wondrous': 2674, 'pail': 2675, 'sails': 2676, 'fired': 2677, 'weary': 2678, 'crying': 2679, 'riding': 2680, 'scattered': 2681, 'brush': 2682, 'suspended': 2683, 'appointed': 2684, 'upstairs': 2685, 'warmly': 2686, 'pursuit': 2687, 'sufficiently': 2688, 'openly': 2689, 'august': 2690, 'hammer': 2691, 'mount': 2692, 'pilot': 2693, 'skill': 2694, 'spanish': 2695, 'rare': 2696, 'destroy': 2697, 'travel': 2698, 'tiger': 2699, 'gross': 2700, 'learning': 2701, 'opposition': 2702, 'earned': 2703, 'crisis': 2704, 'port': 2705, 'doctors': 2706, 'atlantic': 2707, 'mutual': 2708, 'consent': 2709, 'factors': 2710, 'ability': 2711, 'distinction': 2712, 'accomplished': 2713, 'chapter': 2714, 'continuing': 2715, 'acknowledged': 2716, 'autumn': 2717, 'contemporary': 2718, 'interests': 2719, 'inferior': 2720, 'lazy': 2721, 'compassion': 2722, 'theirs': 2723, 'relation': 2724, 'fancied': 2725, 'candles': 2726, 'guineas': 2727, 'quit': 2728, 'demanded': 2729, 'alarmed': 2730, 'swept': 2731, 'naked': 2732, 'wings': 2733, 'charged': 2734, 'visits': 2735, 'ridiculous': 2736, 'violence': 2737, 'trusted': 2738, 'neighbors': 2739, 'flower': 2740, 'sixty': 2741, 'honor': 2742, 'display': 2743, 'slightest': 2744, 'appeal': 2745, 'holds': 2746, 'bars': 2747, 'awful': 2748, 'engine': 2749, 'japanese': 2750, 'approaching': 2751, 'throwing': 2752, 'husbands': 2753, 'sees': 2754, 'experienced': 2755, 'gardens': 2756, 'germany': 2757, 'minor': 2758, 'reserved': 2759, 'slave': 2760, 'alexander': 2761, 'guy': 2762, 'dramatic': 2763, 'eventually': 2764, 'boston': 2765, 'theater': 2766, 'remarks': 2767, 'encounter': 2768, 'fifth': 2769, 'vacation': 2770, 'jewish': 2771, 'johns': 2772, 'hull': 2773, 'formal': 2774, 'improvement': 2775, 'caution': 2776, 'indignation': 2777, 'rational': 2778, 'ideal': 2779, 'fiction': 2780, 'grandmother': 2781, 'persuasion': 2782, 'compliments': 2783, 'thanked': 2784, 'fetch': 2785, 'sir': 2786, 'weve': 2787, 'rode': 2788, 'balance': 2789, 'examine': 2790, 'letting': 2791, 'structure': 2792, 'rocks': 2793, 'invariably': 2794, 'lawyer': 2795, 'seeming': 2796, 'uncertain': 2797, 'thief': 2798, 'beloved': 2799, 'visiting': 2800, 'records': 2801, 'souls': 2802, 'romantic': 2803, 'beer': 2804, 'recognized': 2805, 'wisdom': 2806, 'professor': 2807, 'introduction': 2808, 'quantity': 2809, 'ceremony': 2810, 'lonely': 2811, 'capacity': 2812, 'whisper': 2813, 'harry': 2814, 'hunters': 2815, 'products': 2816, 'exact': 2817, 'distinct': 2818, 'european': 2819, 'welfare': 2820, 'homes': 2821, 'results': 2822, 'novel': 2823, 'northern': 2824, 'probable': 2825, 'brook': 2826, 'angel': 2827, 'yield': 2828, 'winds': 2829, 'trout': 2830, 'roots': 2831, 'guessed': 2832, 'pasture': 2833, 'jew': 2834, 'shillings': 2835, 'spencer': 2836, 'delicacy': 2837, 'wicked': 2838, 'dye': 2839, 'dragged': 2840, 'revealed': 2841, 'shadows': 2842, 'tenderness': 2843, 'undoubtedly': 2844, 'fed': 2845, 'silently': 2846, 'dim': 2847, 'sprang': 2848, 'background': 2849, 'solitary': 2850, 'snake': 2851, 'portion': 2852, 'outer': 2853, 'fix': 2854, 'jaws': 2855, 'planned': 2856, 'unnecessary': 2857, 'fury': 2858, 'cloud': 2859, 'chamber': 2860, 'occasional': 2861, 'urged': 2862, 'pound': 2863, 'strip': 2864, 'performed': 2865, 'roared': 2866, 'product': 2867, 'partner': 2868, 'based': 2869, 'poets': 2870, 'nineteenth': 2871, 'mild': 2872, 'acknowledge': 2873, 'permitted': 2874, 'competition': 2875, 'citizens': 2876, 'solicitude': 2877, 'groups': 2878, 'masters': 2879, 'musicians': 2880, 'fund': 2881, 'considerably': 2882, 'quarrel': 2883, 'demands': 2884, 'sum': 2885, 'remarkably': 2886, 'copy': 2887, 'unpleasant': 2888, 'sentence': 2889, 'ours': 2890, 'unfortunately': 2891, 'bang': 2892, 'sports': 2893, 'artists': 2894, 'tragedy': 2895, 'roman': 2896, 'brings': 2897, 'theatre': 2898, 'colors': 2899, 'satisfy': 2900, 'shell': 2901, 'bulk': 2902, 'describe': 2903, 'continual': 2904, 'admire': 2905, 'steeles': 2906, 'dine': 2907, 'cooling': 2908, 'sadly': 2909, 'woodhouses': 2910, 'shew': 2911, 'parlour': 2912, 'sperm': 2913, 'lowered': 2914, 'guilt': 2915, 'barn': 2916, 'dirt': 2917, 'contained': 2918, 'calmly': 2919, 'wildly': 2920, 'split': 2921, 'leaped': 2922, 'desperate': 2923, 'tonight': 2924, 'breeze': 2925, 'false': 2926, 'extended': 2927, 'entering': 2928, 'signed': 2929, 'contact': 2930, 'alongside': 2931, 'conditions': 2932, 'ignorance': 2933, 'hundreds': 2934, 'glasses': 2935, 'folks': 2936, 'tight': 2937, 'cards': 2938, 'cheeks': 2939, 'host': 2940, 'devoted': 2941, 'aloud': 2942, 'muttered': 2943, 'sheep': 2944, 'anxiously': 2945, 'female': 2946, 'mostly': 2947, 'loves': 2948, 'robinson': 2949, 'behaved': 2950, 'intense': 2951, 'reminded': 2952, 'ignorant': 2953, 'guest': 2954, 'politics': 2955, 'philadelphia': 2956, 'granted': 2957, 'modest': 2958, 'profound': 2959, 'chain': 2960, 'tendency': 2961, 'vital': 2962, 'panels': 2963, 'consequently': 2964, 'peoples': 2965, 'plate': 2966, 'players': 2967, 'concerns': 2968, 'talent': 2969, 'gown': 2970, 'fitted': 2971, 'presents': 2972, 'february': 2973, 'candle': 2974, 'institutions': 2975, 'ashore': 2976, 'probability': 2977, 'apt': 2978, 'precise': 2979, 'centuries': 2980, 'borne': 2981, 'sweep': 2982, 'manage': 2983, 'grief': 2984, 'corkscrew': 2985, 'croft': 2986, 'fence': 2987, 'horizon': 2988, 'visitors': 2989, 'crossing': 2990, 'expecting': 2991, 'kids': 2992, 'sank': 2993, 'shirt': 2994, 'sunk': 2995, 'managed': 2996, 'shouting': 2997, 'rapid': 2998, 'application': 2999, 'doubted': 3000, '_': 0}\n"]}],"source":["print(w_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1654885873294,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"T0VEZDnABmIl","outputId":"bbc8caa0-6e2a-4cf3-dca3-391d619db2de"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3001"]},"metadata":{},"execution_count":32}],"source":["len(w_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8yuFG7IrPsF"},"outputs":[],"source":["##### preprocessing: embedding #####\n","# null_word = np.zeros(300);    w2v_matrix = np.zeros((len(w_idx), 300));\n","# for id, word in idx_to_word.items():\n","#     try:\n","#         w2v_matrix[id] = word2vec[word]\n","#     except:\n","#         w2v_matrix[id] = null_word\n","# w2v_matrix[0] = null_word"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GIM-YWfInYpE"},"outputs":[],"source":["##### time steps of the preceeding words #####\n","time_step = 16;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mw7jI04apRM0"},"outputs":[],"source":["sents = tokenizer.texts_to_sequences(sents);      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LPktMazb1IV"},"outputs":[],"source":["seq_length = 2 * time_step;\n","sents = preprocessing.sequence.pad_sequences(sents, maxlen=seq_length-time_step+1, padding='pre', truncating='post')\n","sents = np.concatenate( (np.zeros((np.size(sents,0),time_step-1)),sents), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654885874836,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"0Y9h5R8JhM_q","outputId":"14d2568a-f284-4426-e742-b67ea2f36589"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(88711, 32)"]},"metadata":{},"execution_count":37}],"source":["sents_0 = sents\n","np.shape(sents_0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbS0r3-Roz-U"},"outputs":[],"source":["sents = sents[np.sum(sents>0,axis=1)>2,:]  # removing too short sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auifWEOdiFbe"},"outputs":[],"source":["sents = sents[np.sum(sents[:,0:time_step+12]==w_idx['unk'],axis=1)<4,:]  # excluding too many unk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1654885874837,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"wJQtmBMOkHk3","outputId":"c257c422-2b0b-4d68-e036-a11f9d94500f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(79444, 32)"]},"metadata":{},"execution_count":40}],"source":["np.shape(sents)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sa22sOr2lArS"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdrk_Fo2Kny1"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sppXrjneY_O"},"outputs":[],"source":["##### shuffling sentenses #####\n","sents = np.random.permutation(sents);         sent_2 = sents +0;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0UCjOYSKRAF"},"outputs":[],"source":["##### preparing training dataset #####\n","batch_size = 64;      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySaG-7qC3lJQ"},"outputs":[],"source":["##### training data and validation data #######\n","train_val_rate = 0.90; # 90% for training, 10% for validation\n","train_start = 0;                train_end = round(len(sents) * train_val_rate)\n","val_start = train_end + 1;      val_end = len(sents);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YxJnqQrynYrs"},"outputs":[],"source":["def sample_generator(start, end):\n","    # while True:\n","    for ep in range(10000):\n","        start0 = start + (ep%2)*(batch_size//2);  end0 = end - batch_size + (ep%2)*(batch_size//2);\n","        if ep%2 == 0 and start<train_end:     sent_2[train_start:train_end,:] = np.random.permutation(sent_2[train_start:train_end,:])\n","        elif ep> 0 and start>train_end:       sent_2[val_start:val_end,:] = np.random.permutation(sent_2[val_start:val_end,:])\n","        for step in range((end0 - start0) // batch_size):\n","            x, y = [],[]\n","            for line in range(batch_size):\n","                dataset = preprocessing.sequence.TimeseriesGenerator(\n","                    sent_2[start0+step*batch_size+line],\n","                    sent_2[start0+step*batch_size+line],  length=time_step,   batch_size=1)\n","                for batch in dataset:\n","                    X, Y = batch;      x.extend(X[0]);     y.extend(Y);\n","            x = np.reshape(x,((seq_length-time_step)*batch_size,time_step))\n","            y = keras.utils.to_categorical(y, len(w_idx))  \n","            # y = np.matmul(keras.utils.to_categorical(y, len(w_idx)), w2v_matrix)  # target in the embedding space \n","            yield x, y"]},{"cell_type":"markdown","metadata":{"id":"yweUijuOCeXs"},"source":[""]},{"cell_type":"code","source":["val_batch_size = batch_size;"],"metadata":{"id":"ah5XE6pIwN5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KiH5zHG4jyu1"},"outputs":[],"source":["def sample_generator_evaluation(start, end):\n","    for step in range((end - start) // val_batch_size):\n","        x, y = [],[]\n","        for line in range(val_batch_size):\n","            dataset = preprocessing.sequence.TimeseriesGenerator(\n","                sents[start+step*val_batch_size+line],   sents[start+step*val_batch_size+line],  length=time_step,   batch_size=1)\n","            for batch in dataset:     X, Y = batch;   x.extend(X[0]);   y.extend(Y);\n","        x = np.reshape(x,((seq_length-time_step)*val_batch_size,time_step))\n","        y = keras.utils.to_categorical(y, len(w_idx))  \n","        yield x, y"]},{"cell_type":"code","source":["###################### Buliding ANN Model #####################################################"],"metadata":{"id":"Ny0xxb1Zovmm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kyV_2rSdGCJt"},"outputs":[],"source":["dp_rate = 0.0; dp_through_rate = 0.0;\n","gr_scale = 1;   min_fb_gr_b = - 0.5;  max_fb_gr_b = 0.0;\n","p_cell = 192; \n","leaky_relu = 0.02;      sqrt_leak = 1; # (0 or 1) sqrt_leak should be 1, if gr_scale > 1\n","p_relu_on = 0; p_relu = 0.0;  "]},{"cell_type":"code","source":["if leaky_relu > 0 and sqrt_leak == 1:         leaky_relu_in = np.sqrt(leaky_relu);    leaky_relu_pc = np.sqrt(leaky_relu);\n","elif leaky_relu > 0:                          leaky_relu_in = 1.0;                    leaky_relu_pc = leaky_relu;\n","elif leaky_relu == 0 and p_relu_on == 1:      leaky_relu_in = 1.0;                    leaky_relu_pc = 0.0; # dummy (p-relu for pc),\n","else:                                         leaky_relu_in = 0.0;                    leaky_relu_pc = 0.0; # ReLU in PC and input cells,  ## when leaky_relu == 0 and p_relu_on == 0:\n","leaky_relu_out = 1.0;"],"metadata":{"id":"ukwrV_0GJI1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ind_pos = max_fb_gr_b // ((max_fb_gr_b-min_fb_gr_b) /gr_scale)"],"metadata":{"id":"QZieXm3dTkL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FF_Dropout(layers.Dropout):\n","  def __init__(self, rate, noise_shape=None, **kwargs):\n","    self.rate = rate\n","    super(FF_Dropout, self).__init__(rate, **kwargs)\n","  def build(self, input_shape):\n","      dp_mask_shape = input_shape[1:]\n","      self.dp_mask = self.add_weight( shape=dp_mask_shape,  initializer='ones', trainable=False, name=\"mask\")\n","      self.dp_mask = tf.concat([tf.ones((dp_mask_shape[0]-1,dp_mask_shape[1])), dp_through_rate *tf.ones((1,dp_mask_shape[1]))],0);    # self.dp_mask[-1,:] = 0\n","  def call(self, inputs, training):\n","    output = inputs\n","    if training == True and self.rate>0:\n","        if tf.random.uniform([]) < self.rate:      output = output * self.dp_mask\n","    return output"],"metadata":{"id":"Ednk4f5q8I1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FUsuqHZuSG8"},"outputs":[],"source":["class custom_RNNCell(layers.AbstractRNNCell):\n","    def __init__(self, units,  **kwargs):\n","        super(custom_RNNCell, self).__init__(**kwargs)\n","        self.units = units\n","        self.prelu = tf.keras.layers.PReLU(alpha_initializer=tf.initializers.constant(p_relu))\n","\n","    @property\n","    def state_size(self):\n","        return self.units\n","\n","    def build(self, input_shape):\n","        self.w_ff = self.add_weight( shape=(input_shape[-1], self.units),\n","            initializer='he_normal',     name='kernel') # glorot_uniform, he_normal, orthogonal,\n","        self.w_out2in = self.add_weight( shape=(self.units, self.units * gr_scale),\n","            initializer='identity', trainable=False,    name='recurrent_w1')\n","        self.w_out2in = tf.concat([tf.eye(self.units) for i in range(gr_scale)],1) # producing multiple copies of states in input layer\n","        self.b_r_in = self.add_weight( shape=(self.units * gr_scale,),\n","            name='recurrent_bias',  trainable=False,    initializer='zeros')   # for recurrent input cells\n","        self.b_r_in = tf.concat([tf.fill([self.units,], (min_fb_gr_b-max_fb_gr_b)*(i-ind_pos)/gr_scale) for i in range(gr_scale)],0) # multiple bias values for different gr populations\n","        self.w_in2pc = self.add_weight( shape=(self.units * gr_scale, self.units),\n","            initializer='he_normal',    name='recurrent_w2') #  # recurrent kernel\n","        # self.w_in2pc = tf.concat([ (1/gr_scale)*tf.eye(self.units) for i in range(gr_scale)],0)  # identity RNN\n","        self.bias = self.add_weight( shape=(self.units,),\n","            name='bias',     initializer='zeros')  # 'glorot_normal', 'zeros', 'he_normal' \n","        self.built = True\n","\n","    def call(self, inputs, states):\n","        # === recurrent activity (pc -> input cells) ======\n","        act_pc = states[0]\n","        act_out = tf.nn.leaky_relu(act_pc, alpha = leaky_relu_out)\n","        act_in = tf.matmul(act_out, self.w_out2in)\n","        act_in = act_in + self.b_r_in\n","        act_in = tf.nn.leaky_relu(act_in, alpha = leaky_relu_in)\n","        # ==== PC activity ====\n","        h = tf.matmul(inputs, self.w_ff);\n","        h = h + self.bias;\n","        pc = h + tf.matmul(act_in, self.w_in2pc);\n","        if leaky_relu == 0 and p_relu_on == 1:          pc = self.prelu(pc)  \n","        else:                                           pc = tf.nn.leaky_relu(pc, alpha = leaky_relu_pc)\n","        return pc, pc"]},{"cell_type":"code","source":[""],"metadata":{"id":"TzKB3UPx8WP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UG7nAaRuHoGt"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"w8B15OExUd71"},"source":["x(2048, 16), where (seq_length-time_step)*batch_size =2048 and time_step = 16     \n","y(2048, 3002)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cufKDuuanhc0"},"outputs":[],"source":["##### building the model ######\n","def seq2vec_model_builder(HIDDEN_DIM):\n","    ##### input and embedding (one-hot) ######\n","    encoder_inputs = layers.Input(shape=(time_step, ), dtype='int32',)\n","    encoder_embedding = layers.Embedding(len(w_idx), len(w_idx), embeddings_initializer='identity', mask_zero=True, trainable=False)(encoder_inputs)\n","    ##### dropout ######\n","    encoder_embedding = FF_Dropout(dp_rate)(encoder_embedding)\n","    ##### RNN ##########\n","    # encoder_RNN = layers.SimpleRNN(HIDDEN_DIM, activation=\"relu\", return_state=True, name='sRNN',kernel_initializer='glorot_normal' )\n","    c_cell = custom_RNNCell( HIDDEN_DIM )\n","    c_cell.initial_state = tf.zeros((1, HIDDEN_DIM), tf.float32)\n","    encoder_RNN = layers.RNN(c_cell, return_state=True,  name='sRNN')\n","    encoder_outputs, state_h = encoder_RNN(encoder_embedding)\n","    ##### output (dense) layer ##########\n","    dense_layer = layers.Dense(len(w_idx), \n","                     bias_initializer=keras.initializers.RandomNormal(stddev=0.00001), activation='softmax')\n","    outputs = dense_layer(encoder_outputs)\n","    model = keras.Model(encoder_inputs, outputs)\n","    return model\n","model = seq2vec_model_builder(HIDDEN_DIM = p_cell)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APoP0_WKMTAq"},"outputs":[],"source":["inter_output_model = keras.Model(model.input, model.get_layer('sRNN').output )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1654885878964,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"DMJ7TAtBOW8c","outputId":"bba657db-0f23-48eb-d5e6-268277ed22b1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.layers.recurrent.RNN at 0x7f77912c3dd0>"]},"metadata":{},"execution_count":54}],"source":["model.get_layer('sRNN')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1654885879108,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"kwdyHl8esu_F","outputId":"3e3c7ccb-64e8-4b55-ffaf-bea144807661"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 16)]              0         \n","                                                                 \n"," embedding (Embedding)       (None, 16, 3001)          9006001   \n","                                                                 \n"," ff__dropout (FF_Dropout)    (None, 16, 3001)          0         \n","                                                                 \n"," sRNN (RNN)                  [(None, 384),             1300224   \n","                              (None, 384)]                       \n","                                                                 \n"," dense (Dense)               (None, 3001)              1155385   \n","                                                                 \n","=================================================================\n","Total params: 11,461,610\n","Trainable params: 2,455,609\n","Non-trainable params: 9,006,001\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W4ywf4AFSdYb"},"outputs":[],"source":["increments = 32   ## split epoch (Equivalent to learning the whole sentence once) into XX"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMoDj5FoCVIY"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkCO3GgAJUN6"},"outputs":[],"source":["def my_loss(y_true, y_pred):\n","    row_wise_sum  = tf.reduce_sum(tf.gather(y_true,  [0,1], axis = 1),axis=1)\n","    valid = tf.reshape(tf.where(tf.equal(row_wise_sum,0)), [-1])    \n","    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","    return loss_fn(y_true=tf.gather(y_true,  valid, axis = 0),  y_pred=tf.gather(y_pred,  valid, axis = 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxSMfF0g4htp"},"outputs":[],"source":["def my_top_k_acc(y_true, y_pred):\n","    row_wise_sum  = tf.reduce_sum(tf.gather(y_true,  [0,1], axis = 1),axis=1)\n","    valid = tf.where(tf.equal(row_wise_sum,0))     # removing y_true = 0 or 'unk'\n","    values, y_ind = tf.nn.top_k(y_true, 1);    values, top_k_pred = tf.nn.top_k(y_pred, 5);\n","    to_top5 = tf.constant( [[ 1, 1, 1, 1, 1]] , dtype=tf.int32 )\n","    input_y_for_top5 = tf.matmul( tf.reshape(y_ind,[-1, 1]) , to_top5 )\n","    correct_preds = tf.cast( tf.equal( input_y_for_top5 , top_k_pred ) , dtype=tf.float16)\n","    suc_pred = tf.reduce_sum(correct_preds, axis=1);\n","    return tf.reduce_mean( tf.gather(suc_pred,  tf.squeeze(valid), axis = 0) )"]},{"cell_type":"markdown","metadata":{"id":"m9ijn7zyX0ct"},"source":["gatherUnknown   \n","y_true,y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYfjGQq6UhC-"},"outputs":[],"source":["#### optimizer ######\n","optimizer = keras.optimizers.Adam(learning_rate=0.0064, clipnorm=8.0) # Adam, Adadelta, RMSprop, Adagrad,\n","model.compile(loss=my_loss, optimizer=optimizer, run_eagerly=True, metrics=['categorical_crossentropy', my_top_k_acc])\n","# optimizer = keras.optimizers.Adam(learning_rate=0.0032) # Adam, Adadelta, RMSprop\n","# model.compile(loss='categorical_crossentropy', optimizer=optimizer,  metrics=[keras.metrics.TopKCategoricalAccuracy(k=5)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5XUeyJ-nhfn"},"outputs":[],"source":["EarlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=increments*10, mode='auto')\n","reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.84, patience=increments//4, min_lr=0.00002)  # faster reduce\n","# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.88, patience=increments//2, min_lr=0.00002)"]},{"cell_type":"code","source":[""],"metadata":{"id":"h-rmuYnpkK9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Knh0R4Ltr7Bs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"42m4cg4njjf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5610,"status":"ok","timestamp":1654885884959,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"9DF0x4DowL4l","outputId":"5324a69f-5b7e-4fb0-a4f5-959d74a1af86"},"outputs":[{"output_type":"stream","name":"stdout","text":["34/34 [==============================] - 5s 73ms/step - loss: 8.0103 - categorical_crossentropy: 8.0115 - my_top_k_acc: 0.0017\n"]}],"source":["h1 = model.evaluate(sample_generator_evaluation(train_start, train_start+(train_end - train_start) //increments))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4571,"status":"ok","timestamp":1654885889519,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"},"user_tz":300},"id":"4gfSNsmcigB7","outputId":"735e48c3-9359-4618-d046-dce42134088e"},"outputs":[{"output_type":"stream","name":"stdout","text":["62/62 [==============================] - 5s 73ms/step - loss: 8.0101 - categorical_crossentropy: 8.0114 - my_top_k_acc: 0.0015\n"]}],"source":["h2 = model.evaluate(sample_generator_evaluation(val_start, val_start+(val_end - val_start)//2) )"]},{"cell_type":"code","source":[""],"metadata":{"id":"JKUqKfsrq-aO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8uMRM1rnhiU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1423516-0e53-4857-87d9-0b2decdde605","executionInfo":{"status":"ok","timestamp":1654887433457,"user_tz":300,"elapsed":619340,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/256\n","34/34 [==============================] - 7s 181ms/step - loss: 7.1745 - categorical_crossentropy: 7.6681 - my_top_k_acc: 0.1395 - val_loss: 6.5611 - val_categorical_crossentropy: 7.3926 - val_my_top_k_acc: 0.1791 - lr: 0.0032\n","Epoch 2/256\n","34/34 [==============================] - 6s 179ms/step - loss: 6.3760 - categorical_crossentropy: 7.2506 - my_top_k_acc: 0.1884 - val_loss: 6.2580 - val_categorical_crossentropy: 7.1679 - val_my_top_k_acc: 0.1850 - lr: 0.0032\n","Epoch 3/256\n","34/34 [==============================] - 6s 179ms/step - loss: 6.2000 - categorical_crossentropy: 7.1499 - my_top_k_acc: 0.1916 - val_loss: 6.1202 - val_categorical_crossentropy: 7.0811 - val_my_top_k_acc: 0.1927 - lr: 0.0032\n","Epoch 4/256\n","34/34 [==============================] - 6s 179ms/step - loss: 6.0416 - categorical_crossentropy: 7.0678 - my_top_k_acc: 0.2063 - val_loss: 5.9749 - val_categorical_crossentropy: 7.0408 - val_my_top_k_acc: 0.2184 - lr: 0.0032\n","Epoch 5/256\n","34/34 [==============================] - 6s 180ms/step - loss: 5.9171 - categorical_crossentropy: 7.0277 - my_top_k_acc: 0.2328 - val_loss: 5.8577 - val_categorical_crossentropy: 6.9922 - val_my_top_k_acc: 0.2412 - lr: 0.0032\n","Epoch 6/256\n","34/34 [==============================] - 6s 180ms/step - loss: 5.8142 - categorical_crossentropy: 7.0061 - my_top_k_acc: 0.2507 - val_loss: 5.7560 - val_categorical_crossentropy: 6.9520 - val_my_top_k_acc: 0.2585 - lr: 0.0032\n","Epoch 7/256\n","34/34 [==============================] - 7s 195ms/step - loss: 5.7095 - categorical_crossentropy: 6.9424 - my_top_k_acc: 0.2671 - val_loss: 5.6990 - val_categorical_crossentropy: 6.9345 - val_my_top_k_acc: 0.2706 - lr: 0.0032\n","Epoch 8/256\n","34/34 [==============================] - 6s 178ms/step - loss: 5.6167 - categorical_crossentropy: 6.9141 - my_top_k_acc: 0.2827 - val_loss: 5.5918 - val_categorical_crossentropy: 6.8938 - val_my_top_k_acc: 0.2826 - lr: 0.0032\n","Epoch 9/256\n","34/34 [==============================] - 6s 175ms/step - loss: 5.5471 - categorical_crossentropy: 6.9033 - my_top_k_acc: 0.2892 - val_loss: 5.5341 - val_categorical_crossentropy: 6.9116 - val_my_top_k_acc: 0.2923 - lr: 0.0032\n","Epoch 10/256\n","34/34 [==============================] - 6s 184ms/step - loss: 5.5002 - categorical_crossentropy: 6.8960 - my_top_k_acc: 0.2930 - val_loss: 5.4929 - val_categorical_crossentropy: 6.8919 - val_my_top_k_acc: 0.2935 - lr: 0.0032\n","Epoch 11/256\n","34/34 [==============================] - 6s 180ms/step - loss: 5.4717 - categorical_crossentropy: 6.8808 - my_top_k_acc: 0.2984 - val_loss: 5.4615 - val_categorical_crossentropy: 6.8783 - val_my_top_k_acc: 0.3013 - lr: 0.0032\n","Epoch 12/256\n","34/34 [==============================] - 6s 179ms/step - loss: 5.4036 - categorical_crossentropy: 6.8846 - my_top_k_acc: 0.3060 - val_loss: 5.4089 - val_categorical_crossentropy: 6.8602 - val_my_top_k_acc: 0.3018 - lr: 0.0032\n","Epoch 13/256\n","34/34 [==============================] - 6s 180ms/step - loss: 5.3663 - categorical_crossentropy: 6.8560 - my_top_k_acc: 0.3116 - val_loss: 5.3418 - val_categorical_crossentropy: 6.8611 - val_my_top_k_acc: 0.3110 - lr: 0.0032\n","Epoch 14/256\n","34/34 [==============================] - 6s 179ms/step - loss: 5.3280 - categorical_crossentropy: 6.8703 - my_top_k_acc: 0.3156 - val_loss: 5.3420 - val_categorical_crossentropy: 6.8921 - val_my_top_k_acc: 0.3112 - lr: 0.0032\n","Epoch 15/256\n","34/34 [==============================] - 6s 179ms/step - loss: 5.3036 - categorical_crossentropy: 6.8333 - my_top_k_acc: 0.3130 - val_loss: 5.3240 - val_categorical_crossentropy: 6.8687 - val_my_top_k_acc: 0.3136 - lr: 0.0032\n","Epoch 16/256\n","34/34 [==============================] - 6s 178ms/step - loss: 5.2898 - categorical_crossentropy: 6.8995 - my_top_k_acc: 0.3182 - val_loss: 5.2921 - val_categorical_crossentropy: 6.8535 - val_my_top_k_acc: 0.3137 - lr: 0.0032\n","Epoch 17/256\n","34/34 [==============================] - 6s 178ms/step - loss: 5.2630 - categorical_crossentropy: 6.8545 - my_top_k_acc: 0.3223 - val_loss: 5.2564 - val_categorical_crossentropy: 6.8985 - val_my_top_k_acc: 0.3192 - lr: 0.0032\n","Epoch 18/256\n","34/34 [==============================] - 6s 177ms/step - loss: 5.2818 - categorical_crossentropy: 6.8899 - my_top_k_acc: 0.3153 - val_loss: 5.2483 - val_categorical_crossentropy: 6.8812 - val_my_top_k_acc: 0.3188 - lr: 0.0032\n","Epoch 19/256\n","34/34 [==============================] - 6s 176ms/step - loss: 5.2021 - categorical_crossentropy: 6.9041 - my_top_k_acc: 0.3271 - val_loss: 5.2157 - val_categorical_crossentropy: 6.9007 - val_my_top_k_acc: 0.3226 - lr: 0.0032\n","Epoch 20/256\n","34/34 [==============================] - 6s 176ms/step - loss: 5.2165 - categorical_crossentropy: 6.8920 - my_top_k_acc: 0.3274 - val_loss: 5.2125 - val_categorical_crossentropy: 6.8670 - val_my_top_k_acc: 0.3255 - lr: 0.0032\n","Epoch 21/256\n","34/34 [==============================] - 6s 175ms/step - loss: 5.1340 - categorical_crossentropy: 6.8040 - my_top_k_acc: 0.3346 - val_loss: 5.1627 - val_categorical_crossentropy: 6.8775 - val_my_top_k_acc: 0.3323 - lr: 0.0032\n","Epoch 22/256\n","34/34 [==============================] - 6s 177ms/step - loss: 5.1619 - categorical_crossentropy: 6.8758 - my_top_k_acc: 0.3292 - val_loss: 5.1936 - val_categorical_crossentropy: 6.9702 - val_my_top_k_acc: 0.3254 - lr: 0.0032\n","Epoch 23/256\n","34/34 [==============================] - 6s 184ms/step - loss: 5.1681 - categorical_crossentropy: 6.8956 - my_top_k_acc: 0.3310 - val_loss: 5.1593 - val_categorical_crossentropy: 6.9475 - val_my_top_k_acc: 0.3323 - lr: 0.0032\n","Epoch 24/256\n","34/34 [==============================] - 6s 178ms/step - loss: 5.0998 - categorical_crossentropy: 6.8830 - my_top_k_acc: 0.3424 - val_loss: 5.1307 - val_categorical_crossentropy: 6.9047 - val_my_top_k_acc: 0.3321 - lr: 0.0032\n","Epoch 25/256\n","34/34 [==============================] - 6s 179ms/step - loss: 5.0948 - categorical_crossentropy: 6.8785 - my_top_k_acc: 0.3361 - val_loss: 5.1437 - val_categorical_crossentropy: 6.9483 - val_my_top_k_acc: 0.3327 - lr: 0.0032\n","Epoch 26/256\n","34/34 [==============================] - 6s 177ms/step - loss: 5.1050 - categorical_crossentropy: 6.9204 - my_top_k_acc: 0.3386 - val_loss: 5.1180 - val_categorical_crossentropy: 6.8797 - val_my_top_k_acc: 0.3337 - lr: 0.0032\n","Epoch 27/256\n","34/34 [==============================] - 6s 178ms/step - loss: 5.0867 - categorical_crossentropy: 6.8976 - my_top_k_acc: 0.3376 - val_loss: 5.0879 - val_categorical_crossentropy: 6.9417 - val_my_top_k_acc: 0.3416 - lr: 0.0032\n","Epoch 28/256\n","34/34 [==============================] - 6s 176ms/step - loss: 5.0491 - categorical_crossentropy: 6.8967 - my_top_k_acc: 0.3459 - val_loss: 5.0707 - val_categorical_crossentropy: 6.9391 - val_my_top_k_acc: 0.3416 - lr: 0.0032\n","Epoch 29/256\n","34/34 [==============================] - 6s 177ms/step - loss: 5.0691 - categorical_crossentropy: 6.9363 - my_top_k_acc: 0.3444 - val_loss: 5.0969 - val_categorical_crossentropy: 6.9791 - val_my_top_k_acc: 0.3381 - lr: 0.0032\n","Epoch 30/256\n","34/34 [==============================] - 6s 179ms/step - loss: 5.0766 - categorical_crossentropy: 6.9542 - my_top_k_acc: 0.3367 - val_loss: 5.0716 - val_categorical_crossentropy: 6.9185 - val_my_top_k_acc: 0.3433 - lr: 0.0032\n","Epoch 31/256\n","34/34 [==============================] - 6s 178ms/step - loss: 5.0494 - categorical_crossentropy: 6.9316 - my_top_k_acc: 0.3421 - val_loss: 5.0715 - val_categorical_crossentropy: 7.0045 - val_my_top_k_acc: 0.3351 - lr: 0.0032\n","Epoch 32/256\n","34/34 [==============================] - 6s 177ms/step - loss: 5.0480 - categorical_crossentropy: 6.9501 - my_top_k_acc: 0.3437 - val_loss: 5.0397 - val_categorical_crossentropy: 6.9394 - val_my_top_k_acc: 0.3435 - lr: 0.0032\n","Epoch 33/256\n","34/34 [==============================] - 6s 178ms/step - loss: 5.0249 - categorical_crossentropy: 6.9425 - my_top_k_acc: 0.3448 - val_loss: 5.0308 - val_categorical_crossentropy: 6.9457 - val_my_top_k_acc: 0.3412 - lr: 0.0032\n","Epoch 34/256\n","34/34 [==============================] - 6s 175ms/step - loss: 5.0182 - categorical_crossentropy: 6.9716 - my_top_k_acc: 0.3461 - val_loss: 5.0349 - val_categorical_crossentropy: 6.9456 - val_my_top_k_acc: 0.3446 - lr: 0.0032\n","Epoch 35/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.9978 - categorical_crossentropy: 7.0101 - my_top_k_acc: 0.3432 - val_loss: 5.0581 - val_categorical_crossentropy: 7.0470 - val_my_top_k_acc: 0.3413 - lr: 0.0032\n","Epoch 36/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.9828 - categorical_crossentropy: 6.9623 - my_top_k_acc: 0.3508 - val_loss: 5.0248 - val_categorical_crossentropy: 7.0077 - val_my_top_k_acc: 0.3451 - lr: 0.0032\n","Epoch 37/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.9635 - categorical_crossentropy: 7.0142 - my_top_k_acc: 0.3502 - val_loss: 5.0173 - val_categorical_crossentropy: 7.0064 - val_my_top_k_acc: 0.3446 - lr: 0.0032\n","Epoch 38/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.9251 - categorical_crossentropy: 6.9854 - my_top_k_acc: 0.3568 - val_loss: 4.9958 - val_categorical_crossentropy: 6.9375 - val_my_top_k_acc: 0.3436 - lr: 0.0032\n","Epoch 39/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.9668 - categorical_crossentropy: 7.0240 - my_top_k_acc: 0.3502 - val_loss: 4.9828 - val_categorical_crossentropy: 7.0685 - val_my_top_k_acc: 0.3437 - lr: 0.0032\n","Epoch 40/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.9342 - categorical_crossentropy: 7.0199 - my_top_k_acc: 0.3502 - val_loss: 4.9754 - val_categorical_crossentropy: 7.0272 - val_my_top_k_acc: 0.3500 - lr: 0.0032\n","Epoch 41/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.9062 - categorical_crossentropy: 6.9783 - my_top_k_acc: 0.3561 - val_loss: 5.0085 - val_categorical_crossentropy: 6.9869 - val_my_top_k_acc: 0.3468 - lr: 0.0032\n","Epoch 42/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.9014 - categorical_crossentropy: 7.0070 - my_top_k_acc: 0.3547 - val_loss: 5.0087 - val_categorical_crossentropy: 7.0255 - val_my_top_k_acc: 0.3424 - lr: 0.0032\n","Epoch 43/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.9002 - categorical_crossentropy: 7.0072 - my_top_k_acc: 0.3501 - val_loss: 4.9575 - val_categorical_crossentropy: 7.0281 - val_my_top_k_acc: 0.3469 - lr: 0.0032\n","Epoch 44/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.9153 - categorical_crossentropy: 7.0175 - my_top_k_acc: 0.3549 - val_loss: 4.9674 - val_categorical_crossentropy: 7.0402 - val_my_top_k_acc: 0.3481 - lr: 0.0032\n","Epoch 45/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.8596 - categorical_crossentropy: 7.0062 - my_top_k_acc: 0.3624 - val_loss: 4.9634 - val_categorical_crossentropy: 7.0640 - val_my_top_k_acc: 0.3508 - lr: 0.0032\n","Epoch 46/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.8691 - categorical_crossentropy: 7.0007 - my_top_k_acc: 0.3571 - val_loss: 4.9617 - val_categorical_crossentropy: 7.1029 - val_my_top_k_acc: 0.3510 - lr: 0.0032\n","Epoch 47/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.8311 - categorical_crossentropy: 7.0084 - my_top_k_acc: 0.3610 - val_loss: 4.9559 - val_categorical_crossentropy: 7.0938 - val_my_top_k_acc: 0.3459 - lr: 0.0032\n","Epoch 48/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.8757 - categorical_crossentropy: 7.0074 - my_top_k_acc: 0.3526 - val_loss: 4.9415 - val_categorical_crossentropy: 7.0600 - val_my_top_k_acc: 0.3529 - lr: 0.0032\n","Epoch 49/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.8296 - categorical_crossentropy: 7.0563 - my_top_k_acc: 0.3614 - val_loss: 4.9510 - val_categorical_crossentropy: 7.0801 - val_my_top_k_acc: 0.3499 - lr: 0.0032\n","Epoch 50/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.8345 - categorical_crossentropy: 7.0254 - my_top_k_acc: 0.3605 - val_loss: 4.9550 - val_categorical_crossentropy: 7.1339 - val_my_top_k_acc: 0.3468 - lr: 0.0032\n","Epoch 51/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.8566 - categorical_crossentropy: 7.0439 - my_top_k_acc: 0.3553 - val_loss: 4.9439 - val_categorical_crossentropy: 7.0995 - val_my_top_k_acc: 0.3474 - lr: 0.0032\n","Epoch 52/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.8101 - categorical_crossentropy: 7.0619 - my_top_k_acc: 0.3625 - val_loss: 4.8940 - val_categorical_crossentropy: 7.0011 - val_my_top_k_acc: 0.3558 - lr: 0.0032\n","Epoch 53/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.8141 - categorical_crossentropy: 7.0254 - my_top_k_acc: 0.3676 - val_loss: 4.9234 - val_categorical_crossentropy: 7.1569 - val_my_top_k_acc: 0.3549 - lr: 0.0032\n","Epoch 54/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.7591 - categorical_crossentropy: 6.9867 - my_top_k_acc: 0.3683 - val_loss: 4.9490 - val_categorical_crossentropy: 7.1545 - val_my_top_k_acc: 0.3504 - lr: 0.0032\n","Epoch 55/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.8173 - categorical_crossentropy: 7.0617 - my_top_k_acc: 0.3625 - val_loss: 4.9603 - val_categorical_crossentropy: 7.1867 - val_my_top_k_acc: 0.3462 - lr: 0.0032\n","Epoch 56/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.8091 - categorical_crossentropy: 7.0800 - my_top_k_acc: 0.3632 - val_loss: 4.8711 - val_categorical_crossentropy: 7.1002 - val_my_top_k_acc: 0.3595 - lr: 0.0032\n","Epoch 57/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.7452 - categorical_crossentropy: 7.0527 - my_top_k_acc: 0.3729 - val_loss: 4.9276 - val_categorical_crossentropy: 7.1663 - val_my_top_k_acc: 0.3514 - lr: 0.0032\n","Epoch 58/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.7735 - categorical_crossentropy: 7.0582 - my_top_k_acc: 0.3669 - val_loss: 4.9033 - val_categorical_crossentropy: 7.2012 - val_my_top_k_acc: 0.3489 - lr: 0.0032\n","Epoch 59/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.7686 - categorical_crossentropy: 7.0944 - my_top_k_acc: 0.3676 - val_loss: 4.9094 - val_categorical_crossentropy: 7.2048 - val_my_top_k_acc: 0.3517 - lr: 0.0032\n","Epoch 60/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.7550 - categorical_crossentropy: 7.0770 - my_top_k_acc: 0.3664 - val_loss: 4.8976 - val_categorical_crossentropy: 7.1899 - val_my_top_k_acc: 0.3548 - lr: 0.0032\n","Epoch 61/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.7341 - categorical_crossentropy: 7.0797 - my_top_k_acc: 0.3744 - val_loss: 4.8916 - val_categorical_crossentropy: 7.1622 - val_my_top_k_acc: 0.3553 - lr: 0.0032\n","Epoch 62/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.7564 - categorical_crossentropy: 7.1128 - my_top_k_acc: 0.3683 - val_loss: 4.8931 - val_categorical_crossentropy: 7.1326 - val_my_top_k_acc: 0.3575 - lr: 0.0032\n","Epoch 63/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.7712 - categorical_crossentropy: 7.1084 - my_top_k_acc: 0.3640 - val_loss: 4.8816 - val_categorical_crossentropy: 7.2338 - val_my_top_k_acc: 0.3557 - lr: 0.0032\n","Epoch 64/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.7472 - categorical_crossentropy: 7.1082 - my_top_k_acc: 0.3703 - val_loss: 4.8855 - val_categorical_crossentropy: 7.2089 - val_my_top_k_acc: 0.3557 - lr: 0.0032\n","Epoch 65/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.7348 - categorical_crossentropy: 7.1181 - my_top_k_acc: 0.3735 - val_loss: 4.8962 - val_categorical_crossentropy: 7.2409 - val_my_top_k_acc: 0.3522 - lr: 0.0027\n","Epoch 66/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.7131 - categorical_crossentropy: 7.1083 - my_top_k_acc: 0.3671 - val_loss: 4.8246 - val_categorical_crossentropy: 7.1644 - val_my_top_k_acc: 0.3613 - lr: 0.0027\n","Epoch 67/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.5841 - categorical_crossentropy: 7.0625 - my_top_k_acc: 0.3820 - val_loss: 4.8895 - val_categorical_crossentropy: 7.2039 - val_my_top_k_acc: 0.3559 - lr: 0.0027\n","Epoch 68/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.6085 - categorical_crossentropy: 7.0640 - my_top_k_acc: 0.3851 - val_loss: 4.8831 - val_categorical_crossentropy: 7.2997 - val_my_top_k_acc: 0.3561 - lr: 0.0027\n","Epoch 69/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.6195 - categorical_crossentropy: 7.0858 - my_top_k_acc: 0.3803 - val_loss: 4.8454 - val_categorical_crossentropy: 7.2615 - val_my_top_k_acc: 0.3611 - lr: 0.0027\n","Epoch 70/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.6483 - categorical_crossentropy: 7.1725 - my_top_k_acc: 0.3778 - val_loss: 4.8779 - val_categorical_crossentropy: 7.2447 - val_my_top_k_acc: 0.3592 - lr: 0.0027\n","Epoch 71/256\n","34/34 [==============================] - 6s 185ms/step - loss: 4.6214 - categorical_crossentropy: 7.1474 - my_top_k_acc: 0.3847 - val_loss: 4.8297 - val_categorical_crossentropy: 7.2125 - val_my_top_k_acc: 0.3606 - lr: 0.0027\n","Epoch 72/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.5994 - categorical_crossentropy: 7.1531 - my_top_k_acc: 0.3886 - val_loss: 4.8679 - val_categorical_crossentropy: 7.2893 - val_my_top_k_acc: 0.3552 - lr: 0.0027\n","Epoch 73/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.6415 - categorical_crossentropy: 7.1695 - my_top_k_acc: 0.3813 - val_loss: 4.8459 - val_categorical_crossentropy: 7.3276 - val_my_top_k_acc: 0.3624 - lr: 0.0027\n","Epoch 74/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.6401 - categorical_crossentropy: 7.2221 - my_top_k_acc: 0.3828 - val_loss: 4.8453 - val_categorical_crossentropy: 7.2746 - val_my_top_k_acc: 0.3581 - lr: 0.0027\n","Epoch 75/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.6092 - categorical_crossentropy: 7.1323 - my_top_k_acc: 0.3800 - val_loss: 4.8698 - val_categorical_crossentropy: 7.2762 - val_my_top_k_acc: 0.3576 - lr: 0.0023\n","Epoch 76/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.6181 - categorical_crossentropy: 7.1875 - my_top_k_acc: 0.3790 - val_loss: 4.8440 - val_categorical_crossentropy: 7.3225 - val_my_top_k_acc: 0.3599 - lr: 0.0023\n","Epoch 77/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.6170 - categorical_crossentropy: 7.1751 - my_top_k_acc: 0.3832 - val_loss: 4.8107 - val_categorical_crossentropy: 7.2867 - val_my_top_k_acc: 0.3646 - lr: 0.0023\n","Epoch 78/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.6126 - categorical_crossentropy: 7.1851 - my_top_k_acc: 0.3820 - val_loss: 4.8225 - val_categorical_crossentropy: 7.2200 - val_my_top_k_acc: 0.3605 - lr: 0.0023\n","Epoch 79/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.6156 - categorical_crossentropy: 7.1032 - my_top_k_acc: 0.3834 - val_loss: 4.8228 - val_categorical_crossentropy: 7.2844 - val_my_top_k_acc: 0.3622 - lr: 0.0023\n","Epoch 80/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.6092 - categorical_crossentropy: 7.2536 - my_top_k_acc: 0.3846 - val_loss: 4.8228 - val_categorical_crossentropy: 7.3761 - val_my_top_k_acc: 0.3610 - lr: 0.0023\n","Epoch 81/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.6092 - categorical_crossentropy: 7.2121 - my_top_k_acc: 0.3847 - val_loss: 4.8645 - val_categorical_crossentropy: 7.3794 - val_my_top_k_acc: 0.3573 - lr: 0.0023\n","Epoch 82/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.5975 - categorical_crossentropy: 7.2064 - my_top_k_acc: 0.3882 - val_loss: 4.8139 - val_categorical_crossentropy: 7.3346 - val_my_top_k_acc: 0.3642 - lr: 0.0023\n","Epoch 83/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.6258 - categorical_crossentropy: 7.2231 - my_top_k_acc: 0.3797 - val_loss: 4.8335 - val_categorical_crossentropy: 7.3360 - val_my_top_k_acc: 0.3650 - lr: 0.0023\n","Epoch 84/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.6110 - categorical_crossentropy: 7.2339 - my_top_k_acc: 0.3840 - val_loss: 4.8423 - val_categorical_crossentropy: 7.3633 - val_my_top_k_acc: 0.3579 - lr: 0.0023\n","Epoch 85/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.5952 - categorical_crossentropy: 7.1847 - my_top_k_acc: 0.3824 - val_loss: 4.8403 - val_categorical_crossentropy: 7.4180 - val_my_top_k_acc: 0.3577 - lr: 0.0023\n","Epoch 86/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.6085 - categorical_crossentropy: 7.1499 - my_top_k_acc: 0.3806 - val_loss: 4.8105 - val_categorical_crossentropy: 7.3591 - val_my_top_k_acc: 0.3634 - lr: 0.0019\n","Epoch 87/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.5727 - categorical_crossentropy: 7.1918 - my_top_k_acc: 0.3897 - val_loss: 4.8135 - val_categorical_crossentropy: 7.3224 - val_my_top_k_acc: 0.3603 - lr: 0.0019\n","Epoch 88/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.5681 - categorical_crossentropy: 7.2147 - my_top_k_acc: 0.3871 - val_loss: 4.7954 - val_categorical_crossentropy: 7.3917 - val_my_top_k_acc: 0.3672 - lr: 0.0019\n","Epoch 89/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.5863 - categorical_crossentropy: 7.2528 - my_top_k_acc: 0.3865 - val_loss: 4.7894 - val_categorical_crossentropy: 7.3083 - val_my_top_k_acc: 0.3681 - lr: 0.0019\n","Epoch 90/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.5609 - categorical_crossentropy: 7.2354 - my_top_k_acc: 0.3887 - val_loss: 4.7813 - val_categorical_crossentropy: 7.3746 - val_my_top_k_acc: 0.3656 - lr: 0.0019\n","Epoch 91/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.5359 - categorical_crossentropy: 7.1901 - my_top_k_acc: 0.3921 - val_loss: 4.8002 - val_categorical_crossentropy: 7.3775 - val_my_top_k_acc: 0.3625 - lr: 0.0019\n","Epoch 92/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.5777 - categorical_crossentropy: 7.2238 - my_top_k_acc: 0.3855 - val_loss: 4.7991 - val_categorical_crossentropy: 7.4234 - val_my_top_k_acc: 0.3661 - lr: 0.0019\n","Epoch 93/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.5950 - categorical_crossentropy: 7.2179 - my_top_k_acc: 0.3843 - val_loss: 4.7958 - val_categorical_crossentropy: 7.3291 - val_my_top_k_acc: 0.3633 - lr: 0.0019\n","Epoch 94/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.5904 - categorical_crossentropy: 7.2522 - my_top_k_acc: 0.3858 - val_loss: 4.7789 - val_categorical_crossentropy: 7.3753 - val_my_top_k_acc: 0.3712 - lr: 0.0019\n","Epoch 95/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.6162 - categorical_crossentropy: 7.3082 - my_top_k_acc: 0.3835 - val_loss: 4.7730 - val_categorical_crossentropy: 7.4688 - val_my_top_k_acc: 0.3631 - lr: 0.0019\n","Epoch 96/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.6266 - categorical_crossentropy: 7.2757 - my_top_k_acc: 0.3783 - val_loss: 4.7948 - val_categorical_crossentropy: 7.3660 - val_my_top_k_acc: 0.3675 - lr: 0.0019\n","Epoch 97/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.5839 - categorical_crossentropy: 7.2719 - my_top_k_acc: 0.3886 - val_loss: 4.7858 - val_categorical_crossentropy: 7.4791 - val_my_top_k_acc: 0.3663 - lr: 0.0019\n","Epoch 98/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.5892 - categorical_crossentropy: 7.3371 - my_top_k_acc: 0.3812 - val_loss: 4.7726 - val_categorical_crossentropy: 7.3464 - val_my_top_k_acc: 0.3652 - lr: 0.0019\n","Epoch 99/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4994 - categorical_crossentropy: 7.2123 - my_top_k_acc: 0.3923 - val_loss: 4.7749 - val_categorical_crossentropy: 7.4419 - val_my_top_k_acc: 0.3654 - lr: 0.0019\n","Epoch 100/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.3943 - categorical_crossentropy: 7.1812 - my_top_k_acc: 0.4019 - val_loss: 4.8331 - val_categorical_crossentropy: 7.4177 - val_my_top_k_acc: 0.3613 - lr: 0.0019\n","Epoch 101/256\n","34/34 [==============================] - 6s 175ms/step - loss: 4.4014 - categorical_crossentropy: 7.2008 - my_top_k_acc: 0.4044 - val_loss: 4.8164 - val_categorical_crossentropy: 7.4564 - val_my_top_k_acc: 0.3636 - lr: 0.0019\n","Epoch 102/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4150 - categorical_crossentropy: 7.2227 - my_top_k_acc: 0.4040 - val_loss: 4.8438 - val_categorical_crossentropy: 7.4447 - val_my_top_k_acc: 0.3555 - lr: 0.0019\n","Epoch 103/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4252 - categorical_crossentropy: 7.2539 - my_top_k_acc: 0.3989 - val_loss: 4.7860 - val_categorical_crossentropy: 7.4324 - val_my_top_k_acc: 0.3668 - lr: 0.0019\n","Epoch 104/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.3950 - categorical_crossentropy: 7.2597 - my_top_k_acc: 0.4101 - val_loss: 4.7944 - val_categorical_crossentropy: 7.4773 - val_my_top_k_acc: 0.3611 - lr: 0.0019\n","Epoch 105/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.3902 - categorical_crossentropy: 7.2477 - my_top_k_acc: 0.4064 - val_loss: 4.8410 - val_categorical_crossentropy: 7.5046 - val_my_top_k_acc: 0.3592 - lr: 0.0019\n","Epoch 106/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.4307 - categorical_crossentropy: 7.2820 - my_top_k_acc: 0.4008 - val_loss: 4.8225 - val_categorical_crossentropy: 7.5296 - val_my_top_k_acc: 0.3603 - lr: 0.0019\n","Epoch 107/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.3973 - categorical_crossentropy: 7.2635 - my_top_k_acc: 0.4041 - val_loss: 4.7874 - val_categorical_crossentropy: 7.4640 - val_my_top_k_acc: 0.3645 - lr: 0.0016\n","Epoch 108/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4158 - categorical_crossentropy: 7.2757 - my_top_k_acc: 0.3994 - val_loss: 4.8189 - val_categorical_crossentropy: 7.4988 - val_my_top_k_acc: 0.3660 - lr: 0.0016\n","Epoch 109/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4243 - categorical_crossentropy: 7.3091 - my_top_k_acc: 0.3980 - val_loss: 4.8329 - val_categorical_crossentropy: 7.5173 - val_my_top_k_acc: 0.3549 - lr: 0.0016\n","Epoch 110/256\n","34/34 [==============================] - 6s 183ms/step - loss: 4.4168 - categorical_crossentropy: 7.2553 - my_top_k_acc: 0.4044 - val_loss: 4.7812 - val_categorical_crossentropy: 7.5080 - val_my_top_k_acc: 0.3707 - lr: 0.0016\n","Epoch 111/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.4068 - categorical_crossentropy: 7.2890 - my_top_k_acc: 0.4048 - val_loss: 4.8050 - val_categorical_crossentropy: 7.5606 - val_my_top_k_acc: 0.3645 - lr: 0.0016\n","Epoch 112/256\n","34/34 [==============================] - 6s 175ms/step - loss: 4.4227 - categorical_crossentropy: 7.2194 - my_top_k_acc: 0.4024 - val_loss: 4.7902 - val_categorical_crossentropy: 7.4672 - val_my_top_k_acc: 0.3651 - lr: 0.0016\n","Epoch 113/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.4093 - categorical_crossentropy: 7.3741 - my_top_k_acc: 0.4018 - val_loss: 4.8463 - val_categorical_crossentropy: 7.5578 - val_my_top_k_acc: 0.3565 - lr: 0.0016\n","Epoch 114/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.3951 - categorical_crossentropy: 7.3115 - my_top_k_acc: 0.4097 - val_loss: 4.8240 - val_categorical_crossentropy: 7.6041 - val_my_top_k_acc: 0.3633 - lr: 0.0016\n","Epoch 115/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.3951 - categorical_crossentropy: 7.2675 - my_top_k_acc: 0.4051 - val_loss: 4.7784 - val_categorical_crossentropy: 7.5108 - val_my_top_k_acc: 0.3672 - lr: 0.0013\n","Epoch 116/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.4206 - categorical_crossentropy: 7.3093 - my_top_k_acc: 0.4013 - val_loss: 4.7879 - val_categorical_crossentropy: 7.5537 - val_my_top_k_acc: 0.3607 - lr: 0.0013\n","Epoch 117/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4061 - categorical_crossentropy: 7.3543 - my_top_k_acc: 0.4027 - val_loss: 4.8058 - val_categorical_crossentropy: 7.5631 - val_my_top_k_acc: 0.3629 - lr: 0.0013\n","Epoch 118/256\n","34/34 [==============================] - 6s 175ms/step - loss: 4.3929 - categorical_crossentropy: 7.2198 - my_top_k_acc: 0.4018 - val_loss: 4.8025 - val_categorical_crossentropy: 7.5444 - val_my_top_k_acc: 0.3650 - lr: 0.0013\n","Epoch 119/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.4262 - categorical_crossentropy: 7.2537 - my_top_k_acc: 0.3978 - val_loss: 4.7799 - val_categorical_crossentropy: 7.5488 - val_my_top_k_acc: 0.3671 - lr: 0.0013\n","Epoch 120/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.3978 - categorical_crossentropy: 7.2771 - my_top_k_acc: 0.4043 - val_loss: 4.7656 - val_categorical_crossentropy: 7.5138 - val_my_top_k_acc: 0.3688 - lr: 0.0013\n","Epoch 121/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.3955 - categorical_crossentropy: 7.3129 - my_top_k_acc: 0.4073 - val_loss: 4.7530 - val_categorical_crossentropy: 7.5777 - val_my_top_k_acc: 0.3676 - lr: 0.0013\n","Epoch 122/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.3898 - categorical_crossentropy: 7.3387 - my_top_k_acc: 0.4085 - val_loss: 4.7999 - val_categorical_crossentropy: 7.5996 - val_my_top_k_acc: 0.3676 - lr: 0.0013\n","Epoch 123/256\n","34/34 [==============================] - 6s 174ms/step - loss: 4.3811 - categorical_crossentropy: 7.3470 - my_top_k_acc: 0.4054 - val_loss: 4.8291 - val_categorical_crossentropy: 7.5466 - val_my_top_k_acc: 0.3627 - lr: 0.0013\n","Epoch 124/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.3559 - categorical_crossentropy: 7.2809 - my_top_k_acc: 0.4121 - val_loss: 4.7685 - val_categorical_crossentropy: 7.5649 - val_my_top_k_acc: 0.3672 - lr: 0.0013\n","Epoch 125/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.3963 - categorical_crossentropy: 7.2754 - my_top_k_acc: 0.4048 - val_loss: 4.7845 - val_categorical_crossentropy: 7.5678 - val_my_top_k_acc: 0.3667 - lr: 0.0013\n","Epoch 126/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4454 - categorical_crossentropy: 7.3379 - my_top_k_acc: 0.3960 - val_loss: 4.7809 - val_categorical_crossentropy: 7.5543 - val_my_top_k_acc: 0.3650 - lr: 0.0013\n","Epoch 127/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.4205 - categorical_crossentropy: 7.3316 - my_top_k_acc: 0.4027 - val_loss: 4.7834 - val_categorical_crossentropy: 7.5672 - val_my_top_k_acc: 0.3688 - lr: 0.0013\n","Epoch 128/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4272 - categorical_crossentropy: 7.4023 - my_top_k_acc: 0.4025 - val_loss: 4.7621 - val_categorical_crossentropy: 7.5025 - val_my_top_k_acc: 0.3699 - lr: 0.0013\n","Epoch 129/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4681 - categorical_crossentropy: 7.3626 - my_top_k_acc: 0.3936 - val_loss: 4.7925 - val_categorical_crossentropy: 7.6301 - val_my_top_k_acc: 0.3661 - lr: 0.0013\n","Epoch 130/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.3794 - categorical_crossentropy: 7.3630 - my_top_k_acc: 0.4076 - val_loss: 4.7731 - val_categorical_crossentropy: 7.6014 - val_my_top_k_acc: 0.3647 - lr: 0.0011\n","Epoch 131/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.4043 - categorical_crossentropy: 7.3955 - my_top_k_acc: 0.4039 - val_loss: 4.7863 - val_categorical_crossentropy: 7.6480 - val_my_top_k_acc: 0.3647 - lr: 0.0011\n","Epoch 132/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.2883 - categorical_crossentropy: 7.3154 - my_top_k_acc: 0.4174 - val_loss: 4.7875 - val_categorical_crossentropy: 7.6170 - val_my_top_k_acc: 0.3685 - lr: 0.0011\n","Epoch 133/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2697 - categorical_crossentropy: 7.3121 - my_top_k_acc: 0.4167 - val_loss: 4.8241 - val_categorical_crossentropy: 7.6413 - val_my_top_k_acc: 0.3646 - lr: 0.0011\n","Epoch 134/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.2625 - categorical_crossentropy: 7.3237 - my_top_k_acc: 0.4222 - val_loss: 4.7632 - val_categorical_crossentropy: 7.5929 - val_my_top_k_acc: 0.3678 - lr: 0.0011\n","Epoch 135/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.2542 - categorical_crossentropy: 7.3363 - my_top_k_acc: 0.4222 - val_loss: 4.8182 - val_categorical_crossentropy: 7.6659 - val_my_top_k_acc: 0.3606 - lr: 0.0011\n","Epoch 136/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.2453 - categorical_crossentropy: 7.3048 - my_top_k_acc: 0.4184 - val_loss: 4.7874 - val_categorical_crossentropy: 7.6108 - val_my_top_k_acc: 0.3669 - lr: 0.0011\n","Epoch 137/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.2640 - categorical_crossentropy: 7.3708 - my_top_k_acc: 0.4165 - val_loss: 4.7931 - val_categorical_crossentropy: 7.6877 - val_my_top_k_acc: 0.3673 - lr: 0.0011\n","Epoch 138/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.2806 - categorical_crossentropy: 7.3857 - my_top_k_acc: 0.4163 - val_loss: 4.7938 - val_categorical_crossentropy: 7.6799 - val_my_top_k_acc: 0.3663 - lr: 9.4429e-04\n","Epoch 139/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.2732 - categorical_crossentropy: 7.2887 - my_top_k_acc: 0.4188 - val_loss: 4.8051 - val_categorical_crossentropy: 7.6741 - val_my_top_k_acc: 0.3674 - lr: 9.4429e-04\n","Epoch 140/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.2962 - categorical_crossentropy: 7.3942 - my_top_k_acc: 0.4146 - val_loss: 4.7846 - val_categorical_crossentropy: 7.7506 - val_my_top_k_acc: 0.3641 - lr: 9.4429e-04\n","Epoch 141/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.2692 - categorical_crossentropy: 7.3523 - my_top_k_acc: 0.4215 - val_loss: 4.8076 - val_categorical_crossentropy: 7.6723 - val_my_top_k_acc: 0.3659 - lr: 9.4429e-04\n","Epoch 142/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2437 - categorical_crossentropy: 7.3306 - my_top_k_acc: 0.4245 - val_loss: 4.7791 - val_categorical_crossentropy: 7.6322 - val_my_top_k_acc: 0.3709 - lr: 9.4429e-04\n","Epoch 143/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.2518 - categorical_crossentropy: 7.4258 - my_top_k_acc: 0.4205 - val_loss: 4.7577 - val_categorical_crossentropy: 7.6552 - val_my_top_k_acc: 0.3706 - lr: 9.4429e-04\n","Epoch 144/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2553 - categorical_crossentropy: 7.2849 - my_top_k_acc: 0.4230 - val_loss: 4.8140 - val_categorical_crossentropy: 7.7023 - val_my_top_k_acc: 0.3642 - lr: 9.4429e-04\n","Epoch 145/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.2632 - categorical_crossentropy: 7.3952 - my_top_k_acc: 0.4224 - val_loss: 4.8095 - val_categorical_crossentropy: 7.6808 - val_my_top_k_acc: 0.3640 - lr: 9.4429e-04\n","Epoch 146/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2506 - categorical_crossentropy: 7.3544 - my_top_k_acc: 0.4248 - val_loss: 4.7711 - val_categorical_crossentropy: 7.7161 - val_my_top_k_acc: 0.3713 - lr: 7.9320e-04\n","Epoch 147/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2668 - categorical_crossentropy: 7.3650 - my_top_k_acc: 0.4174 - val_loss: 4.7797 - val_categorical_crossentropy: 7.6349 - val_my_top_k_acc: 0.3693 - lr: 7.9320e-04\n","Epoch 148/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.2599 - categorical_crossentropy: 7.4093 - my_top_k_acc: 0.4172 - val_loss: 4.7780 - val_categorical_crossentropy: 7.6989 - val_my_top_k_acc: 0.3686 - lr: 7.9320e-04\n","Epoch 149/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.2641 - categorical_crossentropy: 7.3311 - my_top_k_acc: 0.4216 - val_loss: 4.7835 - val_categorical_crossentropy: 7.6909 - val_my_top_k_acc: 0.3676 - lr: 7.9320e-04\n","Epoch 150/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.2524 - categorical_crossentropy: 7.3786 - my_top_k_acc: 0.4236 - val_loss: 4.7837 - val_categorical_crossentropy: 7.7057 - val_my_top_k_acc: 0.3660 - lr: 7.9320e-04\n","Epoch 151/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2465 - categorical_crossentropy: 7.2787 - my_top_k_acc: 0.4230 - val_loss: 4.7810 - val_categorical_crossentropy: 7.7215 - val_my_top_k_acc: 0.3693 - lr: 7.9320e-04\n","Epoch 152/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2624 - categorical_crossentropy: 7.3971 - my_top_k_acc: 0.4186 - val_loss: 4.7756 - val_categorical_crossentropy: 7.6942 - val_my_top_k_acc: 0.3693 - lr: 7.9320e-04\n","Epoch 153/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.2477 - categorical_crossentropy: 7.3904 - my_top_k_acc: 0.4199 - val_loss: 4.8057 - val_categorical_crossentropy: 7.7439 - val_my_top_k_acc: 0.3617 - lr: 7.9320e-04\n","Epoch 154/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2522 - categorical_crossentropy: 7.3632 - my_top_k_acc: 0.4244 - val_loss: 4.7880 - val_categorical_crossentropy: 7.7171 - val_my_top_k_acc: 0.3652 - lr: 6.6629e-04\n","Epoch 155/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2478 - categorical_crossentropy: 7.3202 - my_top_k_acc: 0.4198 - val_loss: 4.7824 - val_categorical_crossentropy: 7.7096 - val_my_top_k_acc: 0.3667 - lr: 6.6629e-04\n","Epoch 156/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.2261 - categorical_crossentropy: 7.2732 - my_top_k_acc: 0.4274 - val_loss: 4.7651 - val_categorical_crossentropy: 7.7116 - val_my_top_k_acc: 0.3733 - lr: 6.6629e-04\n","Epoch 157/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.2284 - categorical_crossentropy: 7.3838 - my_top_k_acc: 0.4241 - val_loss: 4.7941 - val_categorical_crossentropy: 7.7474 - val_my_top_k_acc: 0.3645 - lr: 6.6629e-04\n","Epoch 158/256\n","34/34 [==============================] - 6s 176ms/step - loss: 4.2656 - categorical_crossentropy: 7.4096 - my_top_k_acc: 0.4220 - val_loss: 4.8034 - val_categorical_crossentropy: 7.7717 - val_my_top_k_acc: 0.3661 - lr: 6.6629e-04\n","Epoch 159/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.2462 - categorical_crossentropy: 7.3943 - my_top_k_acc: 0.4234 - val_loss: 4.7646 - val_categorical_crossentropy: 7.7151 - val_my_top_k_acc: 0.3713 - lr: 6.6629e-04\n","Epoch 160/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.2683 - categorical_crossentropy: 7.4531 - my_top_k_acc: 0.4162 - val_loss: 4.8042 - val_categorical_crossentropy: 7.7963 - val_my_top_k_acc: 0.3644 - lr: 6.6629e-04\n","Epoch 161/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.2519 - categorical_crossentropy: 7.4624 - my_top_k_acc: 0.4253 - val_loss: 4.7619 - val_categorical_crossentropy: 7.7158 - val_my_top_k_acc: 0.3699 - lr: 6.6629e-04\n","Epoch 162/256\n","34/34 [==============================] - 6s 187ms/step - loss: 4.2656 - categorical_crossentropy: 7.4049 - my_top_k_acc: 0.4212 - val_loss: 4.7803 - val_categorical_crossentropy: 7.7150 - val_my_top_k_acc: 0.3661 - lr: 5.5968e-04\n","Epoch 163/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.2747 - categorical_crossentropy: 7.4593 - my_top_k_acc: 0.4184 - val_loss: 4.7638 - val_categorical_crossentropy: 7.7435 - val_my_top_k_acc: 0.3697 - lr: 5.5968e-04\n","Epoch 164/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.2611 - categorical_crossentropy: 7.4160 - my_top_k_acc: 0.4229 - val_loss: 4.7625 - val_categorical_crossentropy: 7.7006 - val_my_top_k_acc: 0.3695 - lr: 5.5968e-04\n","Epoch 165/256\n","34/34 [==============================] - 6s 186ms/step - loss: 4.1475 - categorical_crossentropy: 7.4002 - my_top_k_acc: 0.4354 - val_loss: 4.7978 - val_categorical_crossentropy: 7.7842 - val_my_top_k_acc: 0.3668 - lr: 5.5968e-04\n","Epoch 166/256\n","34/34 [==============================] - 6s 184ms/step - loss: 4.1242 - categorical_crossentropy: 7.3312 - my_top_k_acc: 0.4336 - val_loss: 4.8434 - val_categorical_crossentropy: 7.8044 - val_my_top_k_acc: 0.3617 - lr: 5.5968e-04\n","Epoch 167/256\n","34/34 [==============================] - 6s 183ms/step - loss: 4.1137 - categorical_crossentropy: 7.4146 - my_top_k_acc: 0.4368 - val_loss: 4.7845 - val_categorical_crossentropy: 7.7540 - val_my_top_k_acc: 0.3677 - lr: 5.5968e-04\n","Epoch 168/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1119 - categorical_crossentropy: 7.3319 - my_top_k_acc: 0.4392 - val_loss: 4.8051 - val_categorical_crossentropy: 7.7858 - val_my_top_k_acc: 0.3664 - lr: 5.5968e-04\n","Epoch 169/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0864 - categorical_crossentropy: 7.3531 - my_top_k_acc: 0.4386 - val_loss: 4.7937 - val_categorical_crossentropy: 7.7652 - val_my_top_k_acc: 0.3672 - lr: 5.5968e-04\n","Epoch 170/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.1141 - categorical_crossentropy: 7.4219 - my_top_k_acc: 0.4381 - val_loss: 4.7957 - val_categorical_crossentropy: 7.8244 - val_my_top_k_acc: 0.3702 - lr: 4.7013e-04\n","Epoch 171/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1447 - categorical_crossentropy: 7.3877 - my_top_k_acc: 0.4339 - val_loss: 4.7781 - val_categorical_crossentropy: 7.7991 - val_my_top_k_acc: 0.3737 - lr: 4.7013e-04\n","Epoch 172/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1162 - categorical_crossentropy: 7.3307 - my_top_k_acc: 0.4387 - val_loss: 4.8370 - val_categorical_crossentropy: 7.8071 - val_my_top_k_acc: 0.3606 - lr: 4.7013e-04\n","Epoch 173/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1633 - categorical_crossentropy: 7.4571 - my_top_k_acc: 0.4310 - val_loss: 4.8169 - val_categorical_crossentropy: 7.8587 - val_my_top_k_acc: 0.3632 - lr: 4.7013e-04\n","Epoch 174/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.1202 - categorical_crossentropy: 7.3573 - my_top_k_acc: 0.4392 - val_loss: 4.8360 - val_categorical_crossentropy: 7.8079 - val_my_top_k_acc: 0.3648 - lr: 4.7013e-04\n","Epoch 175/256\n","34/34 [==============================] - 6s 185ms/step - loss: 4.0954 - categorical_crossentropy: 7.3882 - my_top_k_acc: 0.4427 - val_loss: 4.7886 - val_categorical_crossentropy: 7.7912 - val_my_top_k_acc: 0.3664 - lr: 4.7013e-04\n","Epoch 176/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.1003 - categorical_crossentropy: 7.4150 - my_top_k_acc: 0.4448 - val_loss: 4.7869 - val_categorical_crossentropy: 7.7779 - val_my_top_k_acc: 0.3647 - lr: 4.7013e-04\n","Epoch 177/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.1140 - categorical_crossentropy: 7.3459 - my_top_k_acc: 0.4394 - val_loss: 4.7974 - val_categorical_crossentropy: 7.8078 - val_my_top_k_acc: 0.3660 - lr: 4.7013e-04\n","Epoch 178/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.1065 - categorical_crossentropy: 7.4166 - my_top_k_acc: 0.4437 - val_loss: 4.7748 - val_categorical_crossentropy: 7.7785 - val_my_top_k_acc: 0.3684 - lr: 3.9491e-04\n","Epoch 179/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1296 - categorical_crossentropy: 7.3633 - my_top_k_acc: 0.4391 - val_loss: 4.7838 - val_categorical_crossentropy: 7.8655 - val_my_top_k_acc: 0.3683 - lr: 3.9491e-04\n","Epoch 180/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1266 - categorical_crossentropy: 7.4359 - my_top_k_acc: 0.4382 - val_loss: 4.8411 - val_categorical_crossentropy: 7.8140 - val_my_top_k_acc: 0.3609 - lr: 3.9491e-04\n","Epoch 181/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1388 - categorical_crossentropy: 7.4166 - my_top_k_acc: 0.4336 - val_loss: 4.8110 - val_categorical_crossentropy: 7.8050 - val_my_top_k_acc: 0.3667 - lr: 3.9491e-04\n","Epoch 182/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.1157 - categorical_crossentropy: 7.3237 - my_top_k_acc: 0.4404 - val_loss: 4.7977 - val_categorical_crossentropy: 7.7880 - val_my_top_k_acc: 0.3668 - lr: 3.9491e-04\n","Epoch 183/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.1305 - categorical_crossentropy: 7.4129 - my_top_k_acc: 0.4386 - val_loss: 4.8183 - val_categorical_crossentropy: 7.8300 - val_my_top_k_acc: 0.3647 - lr: 3.9491e-04\n","Epoch 184/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.1194 - categorical_crossentropy: 7.3341 - my_top_k_acc: 0.4373 - val_loss: 4.8154 - val_categorical_crossentropy: 7.8483 - val_my_top_k_acc: 0.3652 - lr: 3.9491e-04\n","Epoch 185/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.1172 - categorical_crossentropy: 7.4295 - my_top_k_acc: 0.4402 - val_loss: 4.8127 - val_categorical_crossentropy: 7.8461 - val_my_top_k_acc: 0.3617 - lr: 3.9491e-04\n","Epoch 186/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.1381 - categorical_crossentropy: 7.4219 - my_top_k_acc: 0.4395 - val_loss: 4.7967 - val_categorical_crossentropy: 7.7616 - val_my_top_k_acc: 0.3641 - lr: 3.3173e-04\n","Epoch 187/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1295 - categorical_crossentropy: 7.4045 - my_top_k_acc: 0.4386 - val_loss: 4.8013 - val_categorical_crossentropy: 7.8635 - val_my_top_k_acc: 0.3673 - lr: 3.3173e-04\n","Epoch 188/256\n","34/34 [==============================] - 6s 187ms/step - loss: 4.1324 - categorical_crossentropy: 7.3100 - my_top_k_acc: 0.4360 - val_loss: 4.7818 - val_categorical_crossentropy: 7.8464 - val_my_top_k_acc: 0.3709 - lr: 3.3173e-04\n","Epoch 189/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.1157 - categorical_crossentropy: 7.3205 - my_top_k_acc: 0.4419 - val_loss: 4.8182 - val_categorical_crossentropy: 7.8596 - val_my_top_k_acc: 0.3674 - lr: 3.3173e-04\n","Epoch 190/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.1256 - categorical_crossentropy: 7.4181 - my_top_k_acc: 0.4379 - val_loss: 4.7639 - val_categorical_crossentropy: 7.8442 - val_my_top_k_acc: 0.3699 - lr: 3.3173e-04\n","Epoch 191/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.1397 - categorical_crossentropy: 7.3853 - my_top_k_acc: 0.4362 - val_loss: 4.7926 - val_categorical_crossentropy: 7.8598 - val_my_top_k_acc: 0.3662 - lr: 3.3173e-04\n","Epoch 192/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.1446 - categorical_crossentropy: 7.4530 - my_top_k_acc: 0.4371 - val_loss: 4.8270 - val_categorical_crossentropy: 7.8315 - val_my_top_k_acc: 0.3641 - lr: 3.3173e-04\n","Epoch 193/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1538 - categorical_crossentropy: 7.4878 - my_top_k_acc: 0.4303 - val_loss: 4.8045 - val_categorical_crossentropy: 7.8422 - val_my_top_k_acc: 0.3630 - lr: 3.3173e-04\n","Epoch 194/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.1323 - categorical_crossentropy: 7.4839 - my_top_k_acc: 0.4401 - val_loss: 4.8014 - val_categorical_crossentropy: 7.8492 - val_my_top_k_acc: 0.3643 - lr: 2.7865e-04\n","Epoch 195/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1626 - categorical_crossentropy: 7.4486 - my_top_k_acc: 0.4343 - val_loss: 4.7881 - val_categorical_crossentropy: 7.8421 - val_my_top_k_acc: 0.3629 - lr: 2.7865e-04\n","Epoch 196/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.1811 - categorical_crossentropy: 7.5157 - my_top_k_acc: 0.4311 - val_loss: 4.8106 - val_categorical_crossentropy: 7.8186 - val_my_top_k_acc: 0.3698 - lr: 2.7865e-04\n","Epoch 197/256\n","34/34 [==============================] - 6s 177ms/step - loss: 4.1639 - categorical_crossentropy: 7.4410 - my_top_k_acc: 0.4341 - val_loss: 4.8071 - val_categorical_crossentropy: 7.8620 - val_my_top_k_acc: 0.3659 - lr: 2.7865e-04\n","Epoch 198/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0670 - categorical_crossentropy: 7.4290 - my_top_k_acc: 0.4460 - val_loss: 4.7990 - val_categorical_crossentropy: 7.8190 - val_my_top_k_acc: 0.3677 - lr: 2.7865e-04\n","Epoch 199/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0399 - categorical_crossentropy: 7.3363 - my_top_k_acc: 0.4511 - val_loss: 4.7941 - val_categorical_crossentropy: 7.8330 - val_my_top_k_acc: 0.3642 - lr: 2.7865e-04\n","Epoch 200/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0513 - categorical_crossentropy: 7.3951 - my_top_k_acc: 0.4496 - val_loss: 4.8019 - val_categorical_crossentropy: 7.8939 - val_my_top_k_acc: 0.3676 - lr: 2.7865e-04\n","Epoch 201/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0767 - categorical_crossentropy: 7.4445 - my_top_k_acc: 0.4428 - val_loss: 4.8109 - val_categorical_crossentropy: 7.8360 - val_my_top_k_acc: 0.3657 - lr: 2.7865e-04\n","Epoch 202/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0426 - categorical_crossentropy: 7.4213 - my_top_k_acc: 0.4458 - val_loss: 4.7880 - val_categorical_crossentropy: 7.8526 - val_my_top_k_acc: 0.3658 - lr: 2.3407e-04\n","Epoch 203/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0625 - categorical_crossentropy: 7.3926 - my_top_k_acc: 0.4495 - val_loss: 4.8066 - val_categorical_crossentropy: 7.8909 - val_my_top_k_acc: 0.3668 - lr: 2.3407e-04\n","Epoch 204/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.0556 - categorical_crossentropy: 7.3935 - my_top_k_acc: 0.4464 - val_loss: 4.8696 - val_categorical_crossentropy: 7.9092 - val_my_top_k_acc: 0.3591 - lr: 2.3407e-04\n","Epoch 205/256\n","34/34 [==============================] - 6s 185ms/step - loss: 4.0606 - categorical_crossentropy: 7.4383 - my_top_k_acc: 0.4499 - val_loss: 4.7825 - val_categorical_crossentropy: 7.8069 - val_my_top_k_acc: 0.3709 - lr: 2.3407e-04\n","Epoch 206/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0558 - categorical_crossentropy: 7.4255 - my_top_k_acc: 0.4461 - val_loss: 4.8014 - val_categorical_crossentropy: 7.8585 - val_my_top_k_acc: 0.3631 - lr: 2.3407e-04\n","Epoch 207/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0380 - categorical_crossentropy: 7.4107 - my_top_k_acc: 0.4480 - val_loss: 4.8212 - val_categorical_crossentropy: 8.0032 - val_my_top_k_acc: 0.3623 - lr: 2.3407e-04\n","Epoch 208/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0514 - categorical_crossentropy: 7.4242 - my_top_k_acc: 0.4512 - val_loss: 4.8541 - val_categorical_crossentropy: 7.9307 - val_my_top_k_acc: 0.3629 - lr: 2.3407e-04\n","Epoch 209/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0497 - categorical_crossentropy: 7.4343 - my_top_k_acc: 0.4468 - val_loss: 4.8055 - val_categorical_crossentropy: 7.9051 - val_my_top_k_acc: 0.3648 - lr: 2.3407e-04\n","Epoch 210/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0606 - categorical_crossentropy: 7.4960 - my_top_k_acc: 0.4464 - val_loss: 4.8234 - val_categorical_crossentropy: 7.8533 - val_my_top_k_acc: 0.3648 - lr: 1.9662e-04\n","Epoch 211/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0524 - categorical_crossentropy: 7.3558 - my_top_k_acc: 0.4462 - val_loss: 4.8160 - val_categorical_crossentropy: 7.9474 - val_my_top_k_acc: 0.3689 - lr: 1.9662e-04\n","Epoch 212/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0388 - categorical_crossentropy: 7.4133 - my_top_k_acc: 0.4504 - val_loss: 4.8223 - val_categorical_crossentropy: 7.8962 - val_my_top_k_acc: 0.3628 - lr: 1.9662e-04\n","Epoch 213/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0864 - categorical_crossentropy: 7.4719 - my_top_k_acc: 0.4432 - val_loss: 4.7926 - val_categorical_crossentropy: 7.8793 - val_my_top_k_acc: 0.3687 - lr: 1.9662e-04\n","Epoch 214/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.0853 - categorical_crossentropy: 7.5016 - my_top_k_acc: 0.4433 - val_loss: 4.8027 - val_categorical_crossentropy: 7.8697 - val_my_top_k_acc: 0.3660 - lr: 1.9662e-04\n","Epoch 215/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0636 - categorical_crossentropy: 7.4286 - my_top_k_acc: 0.4463 - val_loss: 4.8419 - val_categorical_crossentropy: 7.9458 - val_my_top_k_acc: 0.3631 - lr: 1.9662e-04\n","Epoch 216/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0497 - categorical_crossentropy: 7.4403 - my_top_k_acc: 0.4485 - val_loss: 4.8060 - val_categorical_crossentropy: 7.9264 - val_my_top_k_acc: 0.3695 - lr: 1.9662e-04\n","Epoch 217/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0386 - categorical_crossentropy: 7.4044 - my_top_k_acc: 0.4511 - val_loss: 4.8195 - val_categorical_crossentropy: 7.9123 - val_my_top_k_acc: 0.3661 - lr: 1.9662e-04\n","Epoch 218/256\n","34/34 [==============================] - 6s 183ms/step - loss: 4.0490 - categorical_crossentropy: 7.4116 - my_top_k_acc: 0.4502 - val_loss: 4.7951 - val_categorical_crossentropy: 7.8132 - val_my_top_k_acc: 0.3638 - lr: 1.6516e-04\n","Epoch 219/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0832 - categorical_crossentropy: 7.4653 - my_top_k_acc: 0.4411 - val_loss: 4.8291 - val_categorical_crossentropy: 7.9455 - val_my_top_k_acc: 0.3650 - lr: 1.6516e-04\n","Epoch 220/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0540 - categorical_crossentropy: 7.4480 - my_top_k_acc: 0.4495 - val_loss: 4.8357 - val_categorical_crossentropy: 7.9513 - val_my_top_k_acc: 0.3645 - lr: 1.6516e-04\n","Epoch 221/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0558 - categorical_crossentropy: 7.4130 - my_top_k_acc: 0.4464 - val_loss: 4.8375 - val_categorical_crossentropy: 7.8794 - val_my_top_k_acc: 0.3612 - lr: 1.6516e-04\n","Epoch 222/256\n","34/34 [==============================] - 6s 183ms/step - loss: 4.0710 - categorical_crossentropy: 7.4595 - my_top_k_acc: 0.4473 - val_loss: 4.8046 - val_categorical_crossentropy: 7.8658 - val_my_top_k_acc: 0.3641 - lr: 1.6516e-04\n","Epoch 223/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0711 - categorical_crossentropy: 7.5144 - my_top_k_acc: 0.4449 - val_loss: 4.7889 - val_categorical_crossentropy: 7.9387 - val_my_top_k_acc: 0.3702 - lr: 1.6516e-04\n","Epoch 224/256\n","34/34 [==============================] - 6s 183ms/step - loss: 4.0532 - categorical_crossentropy: 7.4495 - my_top_k_acc: 0.4482 - val_loss: 4.8313 - val_categorical_crossentropy: 7.9028 - val_my_top_k_acc: 0.3630 - lr: 1.6516e-04\n","Epoch 225/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0537 - categorical_crossentropy: 7.3966 - my_top_k_acc: 0.4518 - val_loss: 4.7765 - val_categorical_crossentropy: 7.9482 - val_my_top_k_acc: 0.3707 - lr: 1.6516e-04\n","Epoch 226/256\n","34/34 [==============================] - 6s 186ms/step - loss: 4.0506 - categorical_crossentropy: 7.4482 - my_top_k_acc: 0.4474 - val_loss: 4.8030 - val_categorical_crossentropy: 7.8756 - val_my_top_k_acc: 0.3669 - lr: 1.3873e-04\n","Epoch 227/256\n","34/34 [==============================] - 6s 189ms/step - loss: 4.0654 - categorical_crossentropy: 7.4248 - my_top_k_acc: 0.4461 - val_loss: 4.8736 - val_categorical_crossentropy: 7.9543 - val_my_top_k_acc: 0.3601 - lr: 1.3873e-04\n","Epoch 228/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0592 - categorical_crossentropy: 7.3794 - my_top_k_acc: 0.4424 - val_loss: 4.8154 - val_categorical_crossentropy: 7.8927 - val_my_top_k_acc: 0.3639 - lr: 1.3873e-04\n","Epoch 229/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0540 - categorical_crossentropy: 7.3811 - my_top_k_acc: 0.4463 - val_loss: 4.8229 - val_categorical_crossentropy: 7.9305 - val_my_top_k_acc: 0.3677 - lr: 1.3873e-04\n","Epoch 230/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0462 - categorical_crossentropy: 7.4058 - my_top_k_acc: 0.4507 - val_loss: 4.7924 - val_categorical_crossentropy: 7.9149 - val_my_top_k_acc: 0.3672 - lr: 1.3873e-04\n","Epoch 231/256\n","34/34 [==============================] - 6s 183ms/step - loss: 4.0118 - categorical_crossentropy: 7.4255 - my_top_k_acc: 0.4578 - val_loss: 4.8238 - val_categorical_crossentropy: 7.9339 - val_my_top_k_acc: 0.3642 - lr: 1.3873e-04\n","Epoch 232/256\n","34/34 [==============================] - 6s 181ms/step - loss: 3.9931 - categorical_crossentropy: 7.3958 - my_top_k_acc: 0.4586 - val_loss: 4.7773 - val_categorical_crossentropy: 7.9035 - val_my_top_k_acc: 0.3692 - lr: 1.3873e-04\n","Epoch 233/256\n","34/34 [==============================] - 6s 183ms/step - loss: 3.9848 - categorical_crossentropy: 7.3888 - my_top_k_acc: 0.4580 - val_loss: 4.8160 - val_categorical_crossentropy: 7.8935 - val_my_top_k_acc: 0.3642 - lr: 1.3873e-04\n","Epoch 234/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0311 - categorical_crossentropy: 7.4874 - my_top_k_acc: 0.4485 - val_loss: 4.8524 - val_categorical_crossentropy: 7.9239 - val_my_top_k_acc: 0.3625 - lr: 1.1653e-04\n","Epoch 235/256\n","34/34 [==============================] - 6s 184ms/step - loss: 4.0084 - categorical_crossentropy: 7.4332 - my_top_k_acc: 0.4519 - val_loss: 4.8322 - val_categorical_crossentropy: 7.9693 - val_my_top_k_acc: 0.3619 - lr: 1.1653e-04\n","Epoch 236/256\n","34/34 [==============================] - 6s 180ms/step - loss: 3.9947 - categorical_crossentropy: 7.3896 - my_top_k_acc: 0.4567 - val_loss: 4.8228 - val_categorical_crossentropy: 7.9703 - val_my_top_k_acc: 0.3681 - lr: 1.1653e-04\n","Epoch 237/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0191 - categorical_crossentropy: 7.4350 - my_top_k_acc: 0.4524 - val_loss: 4.8293 - val_categorical_crossentropy: 7.9301 - val_my_top_k_acc: 0.3650 - lr: 1.1653e-04\n","Epoch 238/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0112 - categorical_crossentropy: 7.4480 - my_top_k_acc: 0.4554 - val_loss: 4.8222 - val_categorical_crossentropy: 7.9438 - val_my_top_k_acc: 0.3623 - lr: 1.1653e-04\n","Epoch 239/256\n","34/34 [==============================] - 6s 179ms/step - loss: 3.9954 - categorical_crossentropy: 7.4451 - my_top_k_acc: 0.4540 - val_loss: 4.8057 - val_categorical_crossentropy: 7.8894 - val_my_top_k_acc: 0.3667 - lr: 1.1653e-04\n","Epoch 240/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0025 - categorical_crossentropy: 7.4495 - my_top_k_acc: 0.4530 - val_loss: 4.8185 - val_categorical_crossentropy: 7.9714 - val_my_top_k_acc: 0.3689 - lr: 1.1653e-04\n","Epoch 241/256\n","34/34 [==============================] - 6s 182ms/step - loss: 3.9894 - categorical_crossentropy: 7.4521 - my_top_k_acc: 0.4589 - val_loss: 4.8267 - val_categorical_crossentropy: 7.9588 - val_my_top_k_acc: 0.3669 - lr: 1.1653e-04\n","Epoch 242/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0113 - categorical_crossentropy: 7.4443 - my_top_k_acc: 0.4536 - val_loss: 4.8741 - val_categorical_crossentropy: 7.9683 - val_my_top_k_acc: 0.3558 - lr: 9.7889e-05\n","Epoch 243/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0254 - categorical_crossentropy: 7.5173 - my_top_k_acc: 0.4516 - val_loss: 4.8253 - val_categorical_crossentropy: 7.9657 - val_my_top_k_acc: 0.3649 - lr: 9.7889e-05\n","Epoch 244/256\n","34/34 [==============================] - 6s 180ms/step - loss: 3.9955 - categorical_crossentropy: 7.3434 - my_top_k_acc: 0.4551 - val_loss: 4.8296 - val_categorical_crossentropy: 7.9395 - val_my_top_k_acc: 0.3646 - lr: 9.7889e-05\n","Epoch 245/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0086 - categorical_crossentropy: 7.4361 - my_top_k_acc: 0.4535 - val_loss: 4.8260 - val_categorical_crossentropy: 7.9914 - val_my_top_k_acc: 0.3631 - lr: 9.7889e-05\n","Epoch 246/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0386 - categorical_crossentropy: 7.5212 - my_top_k_acc: 0.4488 - val_loss: 4.8227 - val_categorical_crossentropy: 7.9469 - val_my_top_k_acc: 0.3642 - lr: 9.7889e-05\n","Epoch 247/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.0419 - categorical_crossentropy: 7.5059 - my_top_k_acc: 0.4524 - val_loss: 4.8268 - val_categorical_crossentropy: 8.0163 - val_my_top_k_acc: 0.3611 - lr: 9.7889e-05\n","Epoch 248/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.0058 - categorical_crossentropy: 7.4042 - my_top_k_acc: 0.4539 - val_loss: 4.8310 - val_categorical_crossentropy: 8.0037 - val_my_top_k_acc: 0.3632 - lr: 9.7889e-05\n","Epoch 249/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0106 - categorical_crossentropy: 7.4838 - my_top_k_acc: 0.4535 - val_loss: 4.8226 - val_categorical_crossentropy: 7.9167 - val_my_top_k_acc: 0.3654 - lr: 9.7889e-05\n","Epoch 250/256\n","34/34 [==============================] - 6s 178ms/step - loss: 4.0046 - categorical_crossentropy: 7.4411 - my_top_k_acc: 0.4566 - val_loss: 4.8205 - val_categorical_crossentropy: 7.8638 - val_my_top_k_acc: 0.3683 - lr: 8.2227e-05\n","Epoch 251/256\n","34/34 [==============================] - 6s 179ms/step - loss: 4.0107 - categorical_crossentropy: 7.3939 - my_top_k_acc: 0.4552 - val_loss: 4.8506 - val_categorical_crossentropy: 8.0298 - val_my_top_k_acc: 0.3613 - lr: 8.2227e-05\n","Epoch 252/256\n","34/34 [==============================] - 6s 180ms/step - loss: 4.0450 - categorical_crossentropy: 7.4992 - my_top_k_acc: 0.4464 - val_loss: 4.7930 - val_categorical_crossentropy: 7.8899 - val_my_top_k_acc: 0.3697 - lr: 8.2227e-05\n","Epoch 253/256\n","34/34 [==============================] - 6s 182ms/step - loss: 4.0134 - categorical_crossentropy: 7.4757 - my_top_k_acc: 0.4550 - val_loss: 4.8283 - val_categorical_crossentropy: 7.9346 - val_my_top_k_acc: 0.3648 - lr: 8.2227e-05\n","Epoch 254/256\n","34/34 [==============================] - 6s 184ms/step - loss: 4.0233 - categorical_crossentropy: 7.4278 - my_top_k_acc: 0.4515 - val_loss: 4.8341 - val_categorical_crossentropy: 8.0166 - val_my_top_k_acc: 0.3653 - lr: 8.2227e-05\n","Epoch 255/256\n","34/34 [==============================] - 6s 183ms/step - loss: 4.0300 - categorical_crossentropy: 7.4972 - my_top_k_acc: 0.4515 - val_loss: 4.8198 - val_categorical_crossentropy: 7.9206 - val_my_top_k_acc: 0.3648 - lr: 8.2227e-05\n","Epoch 256/256\n","34/34 [==============================] - 6s 181ms/step - loss: 4.0337 - categorical_crossentropy: 7.5064 - my_top_k_acc: 0.4501 - val_loss: 4.8066 - val_categorical_crossentropy: 7.9241 - val_my_top_k_acc: 0.3652 - lr: 8.2227e-05\n"]}],"source":["##### training the model #######\n","history_callback = model.fit(\n","    sample_generator(train_start, train_end),\n","    steps_per_epoch=(train_end - train_start) //increments // batch_size,  # if //80, it comes full circle in increments of 80. \n","    validation_data=sample_generator(val_start, val_end),\n","    validation_steps=(val_end - val_start) // batch_size //4,\n","    initial_epoch=0,\n","    epochs=increments*8,    \n","    # epochs=4,\n","    verbose=1,\n","    callbacks=[ EarlyStopping, reduce_lr] )"]},{"cell_type":"code","source":[""],"metadata":{"id":"nuDZybWaLC_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrRW_H_JVhU0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654887433459,"user_tz":300,"elapsed":27,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"}},"outputId":"97b68ddd-d74a-4a73-fd5f-fa68c652d980"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['loss', 'categorical_crossentropy', 'my_top_k_acc', 'val_loss', 'val_categorical_crossentropy', 'val_my_top_k_acc', 'lr'])"]},"metadata":{},"execution_count":64}],"source":["history_callback.history.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4rjKNuiN8qK"},"outputs":[],"source":["lr = history_callback.history[\"lr\"];    lr = np.array(lr[:1]+lr);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQVxVFE0AlxG"},"outputs":[],"source":["loss_his = []\n","loss_his.append( np.array( h1[0:1]+ history_callback.history[\"loss\"] ) )\n","loss_his.append( np.array( h1[2:]+ history_callback.history[\"my_top_k_acc\"] ) )\n","loss_his.append( np.array( h2[0:1]+ history_callback.history[\"val_loss\"] ) )\n","loss_his.append( np.array( h2[2:]+ history_callback.history[\"val_my_top_k_acc\"] ) )"]},{"cell_type":"code","source":["##### Correct rate of validation in the training period  ######\n","print(loss_his[3][-4:].tolist()) \n","100*np.mean(loss_his[3][-4:])"],"metadata":{"id":"aD57CqL77zmF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654887433461,"user_tz":300,"elapsed":8,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"}},"outputId":"355e546d-0dfd-48bd-b0f9-dafcbc9a5f16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.3647933602333069, 0.36533674597740173, 0.3648090958595276, 0.36522650718688965]\n"]},{"output_type":"execute_result","data":{"text/plain":["36.504142731428146"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":[""],"metadata":{"id":"abXmptO8NdKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jd2TlrOoGdUW"},"outputs":[],"source":["# model.save('./saved_model/model_'+'{0:03d}'.format(ver))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8wLXnAMw8YP"},"outputs":[],"source":["model.save_weights('./saved_model/model_'+'{0:03d}'.format(ver) + '/checkpoint/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a8NTeaRpNmjy"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAflo4RVNjqx"},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pr5x-XRynhk3","colab":{"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"status":"ok","timestamp":1654887434096,"user_tz":300,"elapsed":471,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"}},"outputId":"01b9c554-83a7-4418-d413-3d260fe713b3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1152x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.figure(figsize=(16, 5)) # figure area\n","plt.subplot(1,2,1)\n","plt.plot(range(len(loss_his[0])),loss_his[0], color=[0.8, 0.8, 0.8])\n","plt.plot(range(len(loss_his[2])),loss_his[2], color=[0, 0, 0]);\n","plt.subplot(1,2,2)\n","plt.plot(range(len(loss_his[1])),loss_his[1], color=[0.8, 0.8, 0.8])\n","plt.plot(range(len(loss_his[3])),loss_his[3], color=[0, 0, 0]);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhU9d8khLKAO"},"outputs":[],"source":["x, y = [],[]\n","for line in range(batch_size):\n","# line = val_start + 3\n","# line = 1\n","    dataset = preprocessing.sequence.TimeseriesGenerator(\n","        sents[line],         sents[line],\n","        length=time_step,    batch_size=1)\n","    for batch in dataset:\n","        X, Y = batch;\n","        x.extend(X[0]);      y.extend(Y)\n","x = np.reshape(x,((seq_length-time_step)*batch_size,time_step))\n","y = keras.utils.to_categorical(y, len(w_idx))  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45_6eBZwUaQH"},"outputs":[],"source":["# x[:60,:]\n","# y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNqZ2Apm52z5"},"outputs":[],"source":["# valid = np.sum(y[:,[0,-1]],axis=1)<0.5\n","# x[valid,:], y[valid,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLcKTyZcrBBV"},"outputs":[],"source":["# row_wise_sum  = np.sum(y[:,[0,-1]],axis=1)\n","row_wise_sum  = tf.reduce_sum(tf.gather(y,  [0], axis = 1),axis=1)\n","valid = tf.where(tf.equal(row_wise_sum,0))\n","y0 = tf.gather(y,  tf.squeeze(valid), axis = 0); "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXLMRtOQMr9X"},"outputs":[],"source":["sents[line]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkZhf3DunhnO"},"outputs":[],"source":["x, y = [],[]\n","for line in range(len(sents)):\n","    for i in range(len(sents[line])-time_step):\n","        if np.sum(sents[line][i:i+time_step])==0:  continue\n","        x.append(sents[line][i:i+time_step])\n","        y.append(sents[line][i+time_step])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGNDeXlZLDKH"},"outputs":[],"source":["# idx_to_word"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"weA7BWxzSPuJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654887447109,"user_tz":300,"elapsed":6652,"user":{"displayName":"Shogo Ohmae","userId":"01179880965248715844"}},"outputId":"14db0cdb-9f13-4fcb-ebae-154a7ffc4ca7"},"outputs":[{"output_type":"stream","name":"stdout","text":["_ _ _ _ _ _ _ _ _ _ _ _ _ there was something\n","    answer:in\n","    prediction:about like in between of that to much wanting a \n","_ _ _ _ _ _ _ _ _ _ _ _ there was something in\n","    answer:her\n","    prediction:the a his such my that this her all an \n","_ _ _ _ _ _ _ _ _ _ _ there was something in her\n","    answer:style\n","    prediction:house life power place own in expectation to fathers and \n","_ _ _ _ _ _ _ _ _ _ there was something in her style\n","    answer:of\n","    prediction:of and in to with for on he but that \n","_ _ _ _ _ _ _ _ _ there was something in her style of\n","    answer:beauty\n","    prediction:the a mind being his having dr life her all \n","_ _ _ _ _ _ _ _ there was something in her style of beauty\n","    answer:to\n","    prediction:and or than as of which in at for to \n","_ _ _ _ _ _ _ there was something in her style of beauty to\n","    answer:please\n","    prediction:her be make dr him their the herself his whom \n","_ _ _ _ _ _ there was something in her style of beauty to please\n","    answer:them\n","    prediction:her the dr and his jane but that to in \n","_ _ _ _ _ there was something in her style of beauty to please them\n","    answer:particularly\n","    prediction:and to with all that as in by for she \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ he\n","    answer:looked\n","    prediction:was had is did would could said has looked will \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ he looked\n","    answer:around\n","    prediction:at up down as like very around back so surprised \n","_ _ _ _ _ _ _ _ _ _ _ _ _ he looked around\n","    answer:the\n","    prediction:at and with the her upon in on for his \n","_ _ _ _ _ _ _ _ _ _ _ _ he looked around the\n","    answer:room\n","    prediction:room back very window same bed smiling old first face \n","_ _ _ _ _ _ _ _ _ _ _ he looked around the room\n","    answer:and\n","    prediction:and with he the again in to when a she \n","_ _ _ _ _ _ _ _ _ _ he looked around the room and\n","    answer:then\n","    prediction:the went as then waited looked walked pulled found was \n","_ _ _ _ _ _ _ _ _ he looked around the room and then\n","    answer:called\n","    prediction:turned came turning looked looking the went he saw said \n","_ _ _ _ _ _ _ _ he looked around the room and then called\n","    answer:out\n","    prediction:the to out her on him them it for and \n","_ _ _ _ _ _ _ he looked around the room and then called out\n","    answer:come\n","    prediction:the a of to his her another in it half \n","_ _ _ _ _ _ he looked around the room and then called out come\n","    answer:here\n","    prediction:to in back before into at out down again and \n","_ _ _ _ _ he looked around the room and then called out come here\n","    answer:quick\n","    prediction:and in again before to at i for with on \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ look\n","    answer:here\n","    prediction:at you for what the up and sharp here my \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ look here\n","    answer:they\n","    prediction:here at he if for and in is lad i \n","_ _ _ _ _ _ _ _ _ _ _ _ _ look here they\n","    answer:unk\n","    prediction:are will have said do see go get were say \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ perhaps\n","    answer:he\n","    prediction:it he the you she i dr this if in \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ perhaps he\n","    answer:did\n","    prediction:was had has is would could did will can thought \n","_ _ _ _ _ _ _ _ _ _ _ _ _ perhaps he did\n","    answer:not\n","    prediction:not it do think and so but i have know \n","_ _ _ _ _ _ _ _ _ _ _ _ perhaps he did not\n","    answer:tell\n","    prediction:know want like mean see think have even care seem \n","_ _ _ _ _ _ _ _ _ _ _ perhaps he did not tell\n","    answer:it\n","    prediction:you me him her it the them what dr how \n","_ _ _ _ _ _ _ _ _ _ perhaps he did not tell it\n","    answer:quite\n","    prediction:is all was to he about that the she what \n","_ _ _ _ _ _ _ _ _ perhaps he did not tell it quite\n","    answer:exactly\n","    prediction:as so a the out an well right his very \n","_ _ _ _ _ _ _ _ perhaps he did not tell it quite exactly\n","    answer:as\n","    prediction:what how as the that a so like his who \n","_ _ _ _ _ _ _ perhaps he did not tell it quite exactly as\n","    answer:it\n","    prediction:you i she he if a the well it we \n","_ _ _ _ _ _ perhaps he did not tell it quite exactly as it\n","    answer:was\n","    prediction:was is does had has looks may ought seemed would \n","_ _ _ _ _ perhaps he did not tell it quite exactly as it was\n","    answer:but\n","    prediction:not to all too a the now that dr going \n","_ _ _ _ perhaps he did not tell it quite exactly as it was but\n","    answer:you\n","    prediction:that i he you the to she it for a \n","_ _ _ perhaps he did not tell it quite exactly as it was but you\n","    answer:know\n","    prediction:must would are could will can had were might know \n","_ _ perhaps he did not tell it quite exactly as it was but you know\n","    answer:he\n","    prediction:that how what i it the he bang very nothing \n","_ perhaps he did not tell it quite exactly as it was but you know he\n","    answer:was\n","    prediction:would will has might was did had must should said \n","perhaps he did not tell it quite exactly as it was but you know he was\n","    answer:very\n","    prediction:not a going so very just in sure always the \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ unk\n","    answer:was\n","    prediction:the was and is of had you said i in \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ unk was\n","    answer:one\n","    prediction:a not the in born all too to at on \n","_ _ _ _ _ _ _ _ _ _ _ _ _ unk was one\n","    answer:of\n","    prediction:of in hand more with and thing by half man \n","_ _ _ _ _ _ _ _ _ _ _ _ unk was one of\n","    answer:the\n","    prediction:the those his them these a her their its all \n","_ _ _ _ _ _ _ _ _ _ _ unk was one of the\n","    answer:unk\n","    prediction:most first best old little other great zero white largest \n","_ _ _ _ _ _ _ _ _ _ unk was one of the unk\n","    answer:of\n","    prediction:of and who in that he which at on crew \n","_ _ _ _ _ _ _ _ _ unk was one of the unk of\n","    answer:our\n","    prediction:the a his her their that this its an whom \n","_ _ _ _ _ _ _ _ unk was one of the unk of our\n","    answer:trip\n","    prediction:own house family crew work old opinions income man engagement \n","_ _ _ _ _ _ _ unk was one of the unk of our trip\n","    answer:but\n","    prediction:to and in when which that from the at with \n","_ _ _ _ _ _ unk was one of the unk of our trip but\n","    answer:beginning\n","    prediction:the it he a to there his that they as \n","_ _ _ _ _ unk was one of the unk of our trip but beginning\n","    answer:in\n","    prediction:to with in the and of was he his at \n","_ _ _ _ unk was one of the unk of our trip but beginning in\n","    answer:unk\n","    prediction:the a his zero one this fact an their sight \n","_ _ _ unk was one of the unk of our trip but beginning in unk\n","    answer:and\n","    prediction:of and the for to that but with so a \n","_ _ unk was one of the unk of our trip but beginning in unk and\n","    answer:continuing\n","    prediction:the his that he a said then i it all \n","_ unk was one of the unk of our trip but beginning in unk and continuing\n","    answer:around\n","    prediction:in the his to by at on as a of \n","unk was one of the unk of our trip but beginning in unk and continuing around\n","    answer:the\n","    prediction:the and a them in with his him her that \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ how\n","    answer:did\n","    prediction:can could do much it to did is many long \n","_ _ _ _ _ _ _ _ _ _ _ _ _ _ how did\n","    answer:this\n","    prediction:you he they it i she we the that this \n","_ _ _ _ _ _ _ _ _ _ _ _ _ how did this\n","    answer:unk\n","    prediction:poor man old he be i matter to whale work \n","_ _ _ _ _ _ _ _ _ _ _ _ how did this unk\n","    answer:come\n","    prediction:of be to the and on that have in like \n","_ _ _ _ _ _ _ _ _ _ _ how did this unk come\n","    answer:here\n","    prediction:to in into out on back a up over from \n"]}],"source":["num_ana = 60\n","\n","states, vocab = [],[]; n_0 = np.zeros(2);   first_w = np.zeros(num_ana);\n","for j in range(num_ana):\n","    k = len(x)-num_ana+j;  w_char = [];   \n","    # k = j+100;  w_char = [];   \n","    x_pred = x[k];   x_pred = np.reshape(x_pred,(1, time_step))\n","    for i in range(time_step):\n","        w_char.append(idx_to_word[x[k][i]])\n","    ##### RNN state prediction and converting it to str ###### \n","    rnn_output, rnn_states = inter_output_model.predict(x_pred)\n","    states.append(rnn_states)\n","    vocab.append(idx_to_word[x_pred[0,-1]])\n","    ##### model prediction and converting it to str ###### \n","    prediction = model.predict(x_pred, verbose=0)\n","    index = np.argsort(-prediction)[:,:10]\n","    result = ''\n","    for m in range(np.size(index)): \n","        result = result + idx_to_word[index[:,m].item()] + ' '\n","    #### first word detection #####\n","    n_0[0] = n_0[1];     n_0[1] = np.sum(x_pred == 0);\n","    if n_0[0] < n_0[1]:\n","        first_w[j] = 1; \n","    #### output ####\n","    char = ' '.join(w_char)\n","    print(char)\n","    print('    answer:'+str(idx_to_word[y[k]]))\n","    print('    prediction:'+str(result))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQH6vld4Ym-l"},"outputs":[],"source":["s_ori = np.concatenate(states,axis=0);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41LpyJzZNuKb"},"outputs":[],"source":["plt.hist(np.reshape(s_ori,[-1,]), bins=50);\n","plt.ylim(0,500)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vP7__GZxP-n7"},"outputs":[],"source":["from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Lrw47v1joU_"},"outputs":[],"source":["pca = PCA(n_components=2)\n","pca.fit(s_ori)\n","s_pca = pca.transform(s_ori)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYtSP00cF10I"},"outputs":[],"source":["s2_pca = np.NaN*np.zeros((2*len(first_w),2));  ii=0;\n","for i in range(len(first_w)):\n","    if first_w[i]==1:\n","        s2_pca[ii] = np.NaN;      ii = ii +1;\n","    s2_pca[ii,:] = s_pca[i,:];    ii = ii +1;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_c4_MQlZHE4_"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaaIU6X-jodY"},"outputs":[],"source":["plt.figure(figsize=(16, 10)) # figure area\n","plt.plot(s2_pca[:,0],s2_pca[:,1])\n","for label, x1, y1, i in zip(vocab, s_pca[:, 0], s_pca[:, 1], range(len(vocab))):\n","    plt.annotate(label, xy=(x1, y1), xytext=(0, 0), textcoords='offset points')\n","    if first_w[i] == 1:\n","        plt.annotate(label, xy=(x1, y1), xytext=(0, 0), textcoords='offset points',  color='b')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OfVPWu5mIfoF"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTszQR5IP-rS"},"outputs":[],"source":["# model.save('./saved_model/model_'+'{0:03d}'.format(ver))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPIp4MvT49M_"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cw0Fx5IM2XC0"},"outputs":[],"source":["inc_tmstep_valrate = [increments, time_step, train_val_rate,lr, gr_scale, dp_rate, min_fb_gr_b, p_cell, dp_through_rate, leaky_relu, p_relu_on, p_relu, sqrt_leak, max_fb_gr_b ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E6nMpj3JUhP8"},"outputs":[],"source":["# ========== save in npz file ============\n","import joblib\n","dt =  (w_idx, idx_to_word, sents, loss_his, inc_tmstep_valrate)\n","joblib.dump(dt, './saved_model/np_'+'{0:03d}'.format(ver)+'.pkl', compress=3)    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmNZF0ZvWI6l"},"outputs":[],"source":["with open('./saved_model/tokenizer_'+'{0:03d}'.format(ver)+'.pkl', 'wb') as handle:\n","    joblib.dump(tokenizer, handle)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCZID4a_WI9f"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1o6zD6SWJHS"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Cb_NLP_02.1_larger_fb_gr_0.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNAJj/AjpLDlOK7yGf//WBa"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}